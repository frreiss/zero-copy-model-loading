{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8270a16d",
   "metadata": {},
   "source": [
    "# benchmark.ipynb\n",
    "\n",
    "This notebook contains the text and code for the next blog post in the zero-copy model series, \n",
    "title TBD.\n",
    "\n",
    "The first post explained how to load PyTorch models for inference extremely fast by leveraging the Plasma object store's ability to load numeric data directly from shared memory.\n",
    "\n",
    "In this post, we talk in more concrete terms about how to use this zero-copy model loading for model serving. We put together a simple model serving system, then set up a microbenchmark that simulates a heavy-tailed traffic pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edbf7611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization and import code goes in this cell.\n",
    "\n",
    "# Imports: Python core, then third-party, then local.\n",
    "# Try to keep each block in alphabetical order, or the linter may get angry.\n",
    "import asyncio\n",
    "import concurrent.futures\n",
    "import requests\n",
    "import starlette\n",
    "import time\n",
    "import urllib\n",
    "from typing import Dict, Any, Callable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import ray\n",
    "from ray import serve\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "import zerocopy\n",
    "\n",
    "\n",
    "# Reduce the volume of warning messages from `transformers`\n",
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "\n",
    "def reboot_ray():\n",
    "    if ray.is_initialized():\n",
    "        ray.shutdown()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        return ray.init(num_gpus=1)\n",
    "    else:\n",
    "        return ray.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a69fefd",
   "metadata": {},
   "source": [
    "# Title of new blog post goes here\n",
    "\n",
    "*Recap of previous blog post goes here.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13eccd9",
   "metadata": {},
   "source": [
    "## Scenario\n",
    "\n",
    "The end-to-end scenario for our benchmark involves supporting an AI chatbot.\n",
    "The chatbot's conversational AI runs off of a conversation tree (**TODO:** What's the best term for this tree?). Some of the nodes of this tree invoke question answering models.\n",
    "\n",
    "Our benchmark will cover the model serving portion of the chatbot's backend. This \n",
    "model serving layer runs question answering (QA) models on behalf of the \n",
    "chatbot's conversational AI. The chatbot's conversation tree leads to 4 very different\n",
    "question answering scenarios, and each scenario has its own dedicated QA\n",
    "model. Because the chatbot speaks 3 different languages, there are three versions of\n",
    "each model deployed: one for each language. So the model serving layer runs a total of\n",
    "12 models to cover the 4 question types and 3 languages.\n",
    "\n",
    "> **TODO:** Cartoon block diagram of the end-to-end scenario. \n",
    "> Diagram should show a user interacting with a chatbot. The chatbot runs off of a conversation tree. \n",
    "> Some of the nodes of the conversation tree have question answering models hanging off of them.\n",
    "\n",
    "For our question answering models, we'll use 12 copies of `deepset/roberta-base-squad2`,\n",
    "the most popular question answering model on the [Huggingface model marketplace](https://huggingface.co/models).\n",
    "Here's some code to load that model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37dae247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load with standard method: "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d7e86ec826b4493be907dd9e64dee73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c01d7907d34546a89f715621d9506e4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/473M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fee6d232cbab425eaa53384f11fdcd43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/79.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3197ea4768c6483986057bd9ff639e2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99d404673ab44ec09fc4f10c305a500d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13436c4eb41c43d4bed2ea23097378e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.89 s ± 117 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "model_name = \"deepset/roberta-base-squad2\"\n",
    "\n",
    "# Strip out this timing code for the blog version.\n",
    "print(\"Time to load with standard method: \", end=\"\")\n",
    "%timeit -r3 transformers.pipeline(\"question-answering\", model=model_name)\n",
    "qa = transformers.pipeline(\"question-answering\", model=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260cdcae",
   "metadata": {},
   "source": [
    "The performance of this model isn't very sensitive to the specific question and context provided,\n",
    "so we define a single set of inputs and outputs for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa96aec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 4.278861524653621e-06, 'start': 483, 'end': 484, 'answer': '5'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_input = {\n",
    "    \"question\": \"What is 1 + 1?\",\n",
    "    \"context\": \n",
    "        \"\"\"Addition (usually signified by the plus symbol +) is one of the four basic operations of \n",
    "        arithmetic, the other three being subtraction, multiplication and division. The addition of two \n",
    "        whole numbers results in the total amount or sum of those values combined. The example in the\n",
    "        adjacent image shows a combination of three apples and two apples, making a total of five apples. \n",
    "        This observation is equivalent to the mathematical expression \"3 + 2 = 5\" (that is, \"3 plus 2 \n",
    "        is equal to 5\").\n",
    "        \"\"\"\n",
    "}\n",
    "\n",
    "result = qa(qa_input)\n",
    "qa_answer = result[\"answer\"]\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5494b1aa",
   "metadata": {},
   "source": [
    "## Baseline results\n",
    "\n",
    "Let's start with a baseline implementation of model serving for this model. This baseline implementation emulates running each QA model in a separate container. The server has 12 CPUs, so each container gets 1 CPU. We implement this baseline configuration with a pool of Ray actors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec60e717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=9952)\u001b[0m 2021-10-20 20:54:13,566\tINFO checkpoint_path.py:15 -- Using RayInternalKVStore for controller checkpoint and recovery.\n",
      "\u001b[2m\u001b[36m(pid=9952)\u001b[0m 2021-10-20 20:54:13,570\tINFO http_state.py:75 -- Starting HTTP proxy with name 'SERVE_CONTROLLER_ACTOR:mqlxhl:SERVE_PROXY_ACTOR-node:10.168.112.7-0' on node 'node:10.168.112.7-0' listening on '127.0.0.1:8000'\n",
      "2021-10-20 20:54:13,887\tINFO api.py:455 -- Started Serve instance in namespace '5d3a7548-5d82-493b-a43e-c71ca55ae1d3'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ray.serve.api.Client at 0x7f9104fadd00>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serve.shutdown()\n",
    "reboot_ray()\n",
    "serve.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b8a6ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=9943)\u001b[0m INFO:     Started server process [9943]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-20 20:54:14,563\tINFO api.py:243 -- Updating deployment 'qa0'. component=serve deployment=qa0\n",
      "2021-10-20 20:54:14,576\tINFO api.py:243 -- Updating deployment 'qa1'. component=serve deployment=qa1\n",
      "2021-10-20 20:54:14,591\tINFO api.py:243 -- Updating deployment 'qa2'. component=serve deployment=qa2\n",
      "2021-10-20 20:54:14,609\tINFO api.py:243 -- Updating deployment 'qa3'. component=serve deployment=qa3\n",
      "2021-10-20 20:54:14,629\tINFO api.py:243 -- Updating deployment 'qa4'. component=serve deployment=qa4\n",
      "\u001b[2m\u001b[36m(pid=9952)\u001b[0m 2021-10-20 20:54:14,633\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa0'. component=serve deployment=qa0\n",
      "\u001b[2m\u001b[36m(pid=9952)\u001b[0m 2021-10-20 20:54:14,645\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa1'. component=serve deployment=qa1\n",
      "\u001b[2m\u001b[36m(pid=9952)\u001b[0m 2021-10-20 20:54:14,659\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa2'. component=serve deployment=qa2\n",
      "\u001b[2m\u001b[36m(pid=9952)\u001b[0m 2021-10-20 20:54:14,671\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa3'. component=serve deployment=qa3\n",
      "\u001b[2m\u001b[36m(pid=9952)\u001b[0m 2021-10-20 20:54:14,717\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa4'. component=serve deployment=qa4\n",
      "2021-10-20 20:54:14,828\tINFO api.py:243 -- Updating deployment 'qa5'. component=serve deployment=qa5\n",
      "2021-10-20 20:54:14,937\tINFO api.py:243 -- Updating deployment 'qa6'. component=serve deployment=qa6\n",
      "2021-10-20 20:54:15,073\tINFO api.py:243 -- Updating deployment 'qa7'. component=serve deployment=qa7\n",
      "\u001b[2m\u001b[36m(pid=9952)\u001b[0m 2021-10-20 20:54:14,947\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa5'. component=serve deployment=qa5\n",
      "\u001b[2m\u001b[36m(pid=9952)\u001b[0m 2021-10-20 20:54:14,966\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa6'. component=serve deployment=qa6\n",
      "2021-10-20 20:54:15,103\tINFO api.py:243 -- Updating deployment 'qa8'. component=serve deployment=qa8\n",
      "2021-10-20 20:54:15,243\tINFO api.py:243 -- Updating deployment 'qa9'. component=serve deployment=qa9\n",
      "\u001b[2m\u001b[36m(pid=9952)\u001b[0m 2021-10-20 20:54:15,178\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa7'. component=serve deployment=qa7\n",
      "\u001b[2m\u001b[36m(pid=9952)\u001b[0m 2021-10-20 20:54:15,190\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa8'. component=serve deployment=qa8\n",
      "2021-10-20 20:54:15,316\tINFO api.py:243 -- Updating deployment 'qa10'. component=serve deployment=qa10\n",
      "\u001b[2m\u001b[36m(pid=9952)\u001b[0m 2021-10-20 20:54:15,326\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa9'. component=serve deployment=qa9\n",
      "\u001b[2m\u001b[36m(pid=9952)\u001b[0m 2021-10-20 20:54:15,345\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa10'. component=serve deployment=qa10\n",
      "2021-10-20 20:54:15,440\tINFO api.py:243 -- Updating deployment 'qa11'. component=serve deployment=qa11\n",
      "\u001b[2m\u001b[36m(pid=9952)\u001b[0m 2021-10-20 20:54:15,476\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa11'. component=serve deployment=qa11\n"
     ]
    }
   ],
   "source": [
    "class QAModel:\n",
    "    def __init__(self):\n",
    "        self._qa = transformers.pipeline(\"question-answering\",\n",
    "                                         model=model_name)\n",
    "\n",
    "    def __call__(self, request: starlette.requests.Request):\n",
    "        # Pull model inputs from URL query parameters.\n",
    "        # A production version of this code would sanitize these strings.\n",
    "        model_input = {\n",
    "            \"question\": request.query_params[\"question\"],\n",
    "            \"context\": request.query_params[\"context\"]\n",
    "        }\n",
    "        return self._qa(model_input)\n",
    "\n",
    "\n",
    "# Define endpoints\n",
    "NUM_QA_MODELS = 12\n",
    "deployments = [\n",
    "    serve.deployment(QAModel, f\"qa{model_num}\")\n",
    "    for model_num in range(NUM_QA_MODELS)\n",
    "]\n",
    "\n",
    "for d in deployments:\n",
    "    d.deploy(_blocking=False)\n",
    "\n",
    "# Wait a moment so log output doesn't go to the next cell's output\n",
    "time.sleep(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22fcdd6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 4.278861524653621e-06, 'start': 483, 'end': 484, 'answer': '5'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try out the deployment.\n",
    "# This web service call blocks until the asychronous deployment has completed.\n",
    "params = urllib.parse.urlencode(qa_input)\n",
    "requests.get(f\"http://127.0.0.1:8000/qa0?{params}\").json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aea4da8",
   "metadata": {},
   "source": [
    "Let's wrap this model web service in a callback function that calls the model, retrieves the result, and\n",
    "returns elapsed time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "079ad698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.575 seconds elapsed'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def call_model(model_num: int, question: str, context: str, expected_answer: str) -> float:\n",
    "    \"\"\"\n",
    "    Callack function that calls the model deployment, retrieves and \n",
    "    validates the result, and returns elapsed time.\n",
    "\n",
    "    :param model_num: Index of the model to call\n",
    "    :param question: The `question` argument to pass to the QA model\n",
    "    :param context: The `context` argument to pass to the QA model\n",
    "    :param expected_answer: The answer that the model should return\n",
    "\n",
    "    :returns: Tuple of start and end times of the web service call\n",
    "    \"\"\"\n",
    "    # For now, use the same input every time\n",
    "    params = urllib.parse.urlencode({\"question\": question, \"context\": context})\n",
    "\n",
    "    start_time = time.time()\n",
    "    result = requests.get(f\"http://127.0.0.1:8000/qa{model_num}?{params}\").json()\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Do some basic validation\n",
    "    if result[\"answer\"] != expected_answer:\n",
    "        raise ValueError(f\"Unexpected result: {result}\")\n",
    "\n",
    "    return (start_time, end_time)\n",
    "\n",
    "\n",
    "times = call_model(0, qa_input[\"question\"], qa_input[\"context\"], qa_answer)\n",
    "f\"{times[1] - times[0]:1.3f} seconds elapsed\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a925870a",
   "metadata": {},
   "source": [
    "Now we can define a simple benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfa55ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request_id</th>\n",
       "      <th>model_num</th>\n",
       "      <th>desired_start</th>\n",
       "      <th>actual_start</th>\n",
       "      <th>end</th>\n",
       "      <th>latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>0.595420</td>\n",
       "      <td>0.594253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083947</td>\n",
       "      <td>0.719541</td>\n",
       "      <td>0.635595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.167284</td>\n",
       "      <td>3.778072</td>\n",
       "      <td>3.610788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250631</td>\n",
       "      <td>3.779140</td>\n",
       "      <td>3.528509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.334094</td>\n",
       "      <td>3.780045</td>\n",
       "      <td>3.445951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.417304</td>\n",
       "      <td>3.780638</td>\n",
       "      <td>3.363334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500666</td>\n",
       "      <td>3.781295</td>\n",
       "      <td>3.280629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.584048</td>\n",
       "      <td>1.659619</td>\n",
       "      <td>1.075570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.667175</td>\n",
       "      <td>9.951593</td>\n",
       "      <td>9.284418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750496</td>\n",
       "      <td>9.952491</td>\n",
       "      <td>9.201994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833866</td>\n",
       "      <td>9.953356</td>\n",
       "      <td>9.119490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.917375</td>\n",
       "      <td>9.953959</td>\n",
       "      <td>9.036584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000690</td>\n",
       "      <td>2.819002</td>\n",
       "      <td>1.818312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>1.084971</td>\n",
       "      <td>9.956160</td>\n",
       "      <td>8.871189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>1.167278</td>\n",
       "      <td>2.820552</td>\n",
       "      <td>1.653274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250654</td>\n",
       "      <td>9.957379</td>\n",
       "      <td>8.706725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.333915</td>\n",
       "      <td>9.960870</td>\n",
       "      <td>8.626955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>1.417180</td>\n",
       "      <td>4.382726</td>\n",
       "      <td>2.965546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.500557</td>\n",
       "      <td>9.959144</td>\n",
       "      <td>8.458587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>1.583967</td>\n",
       "      <td>4.382860</td>\n",
       "      <td>2.798893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.667181</td>\n",
       "      <td>9.959780</td>\n",
       "      <td>8.292599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1.772982</td>\n",
       "      <td>9.960458</td>\n",
       "      <td>8.187476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.834719</td>\n",
       "      <td>5.535979</td>\n",
       "      <td>3.701259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1.916667</td>\n",
       "      <td>1.917380</td>\n",
       "      <td>9.961019</td>\n",
       "      <td>8.043639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000827</td>\n",
       "      <td>20.040655</td>\n",
       "      <td>18.039827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>2.083333</td>\n",
       "      <td>2.084069</td>\n",
       "      <td>20.041310</td>\n",
       "      <td>17.957241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>2.167397</td>\n",
       "      <td>20.042342</td>\n",
       "      <td>17.874945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>2.250690</td>\n",
       "      <td>5.536678</td>\n",
       "      <td>3.285987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.334062</td>\n",
       "      <td>20.043707</td>\n",
       "      <td>17.709645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>2.416667</td>\n",
       "      <td>2.417389</td>\n",
       "      <td>20.043879</td>\n",
       "      <td>17.626490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.500784</td>\n",
       "      <td>20.045838</td>\n",
       "      <td>17.545054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>2.583333</td>\n",
       "      <td>2.584122</td>\n",
       "      <td>6.697081</td>\n",
       "      <td>4.112959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.667379</td>\n",
       "      <td>20.046916</td>\n",
       "      <td>17.379538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>2.750757</td>\n",
       "      <td>3.369016</td>\n",
       "      <td>0.618259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>2.833942</td>\n",
       "      <td>20.047434</td>\n",
       "      <td>17.213492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>2.916667</td>\n",
       "      <td>2.917313</td>\n",
       "      <td>4.366679</td>\n",
       "      <td>1.449366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000836</td>\n",
       "      <td>20.049415</td>\n",
       "      <td>17.048579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>3.083333</td>\n",
       "      <td>3.084127</td>\n",
       "      <td>20.049578</td>\n",
       "      <td>16.965451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>3.167450</td>\n",
       "      <td>20.050339</td>\n",
       "      <td>16.882889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>3.250731</td>\n",
       "      <td>20.050792</td>\n",
       "      <td>16.800062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.334266</td>\n",
       "      <td>20.050668</td>\n",
       "      <td>16.716402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>3.416667</td>\n",
       "      <td>3.417484</td>\n",
       "      <td>20.051989</td>\n",
       "      <td>16.634505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500878</td>\n",
       "      <td>20.052709</td>\n",
       "      <td>16.551831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>3.583333</td>\n",
       "      <td>3.584084</td>\n",
       "      <td>20.053858</td>\n",
       "      <td>16.469774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.667574</td>\n",
       "      <td>20.054546</td>\n",
       "      <td>16.386972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>3.750790</td>\n",
       "      <td>20.054774</td>\n",
       "      <td>16.303983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>3.834003</td>\n",
       "      <td>6.697238</td>\n",
       "      <td>2.863235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>3.916667</td>\n",
       "      <td>3.917358</td>\n",
       "      <td>25.640312</td>\n",
       "      <td>21.722954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000709</td>\n",
       "      <td>25.641368</td>\n",
       "      <td>21.640659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>4.083333</td>\n",
       "      <td>4.084071</td>\n",
       "      <td>25.642101</td>\n",
       "      <td>21.558030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.167351</td>\n",
       "      <td>25.643583</td>\n",
       "      <td>21.476231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>4.250762</td>\n",
       "      <td>25.645457</td>\n",
       "      <td>21.394695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.334132</td>\n",
       "      <td>25.644856</td>\n",
       "      <td>21.310724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>4.416667</td>\n",
       "      <td>4.417527</td>\n",
       "      <td>8.475556</td>\n",
       "      <td>4.058029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500820</td>\n",
       "      <td>25.646139</td>\n",
       "      <td>21.145319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>4.583333</td>\n",
       "      <td>4.584014</td>\n",
       "      <td>8.476129</td>\n",
       "      <td>3.892115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.667519</td>\n",
       "      <td>8.477106</td>\n",
       "      <td>3.809587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>4.750772</td>\n",
       "      <td>25.646277</td>\n",
       "      <td>20.895505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>4.834465</td>\n",
       "      <td>25.647079</td>\n",
       "      <td>20.812614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>4.916667</td>\n",
       "      <td>4.917452</td>\n",
       "      <td>25.647277</td>\n",
       "      <td>20.729825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    request_id  model_num  desired_start  actual_start        end    latency\n",
       "0            0          0       0.000000      0.001167   0.595420   0.594253\n",
       "1            1          1       0.083333      0.083947   0.719541   0.635595\n",
       "2            2          0       0.166667      0.167284   3.778072   3.610788\n",
       "3            3          0       0.250000      0.250631   3.779140   3.528509\n",
       "4            4          0       0.333333      0.334094   3.780045   3.445951\n",
       "5            5          0       0.416667      0.417304   3.780638   3.363334\n",
       "6            6          0       0.500000      0.500666   3.781295   3.280629\n",
       "7            7          1       0.583333      0.584048   1.659619   1.075570\n",
       "8            8          0       0.666667      0.667175   9.951593   9.284418\n",
       "9            9          0       0.750000      0.750496   9.952491   9.201994\n",
       "10          10          0       0.833333      0.833866   9.953356   9.119490\n",
       "11          11          0       0.916667      0.917375   9.953959   9.036584\n",
       "12          12          1       1.000000      1.000690   2.819002   1.818312\n",
       "13          13          0       1.083333      1.084971   9.956160   8.871189\n",
       "14          14          1       1.166667      1.167278   2.820552   1.653274\n",
       "15          15          0       1.250000      1.250654   9.957379   8.706725\n",
       "16          16          0       1.333333      1.333915   9.960870   8.626955\n",
       "17          17          1       1.416667      1.417180   4.382726   2.965546\n",
       "18          18          0       1.500000      1.500557   9.959144   8.458587\n",
       "19          19          1       1.583333      1.583967   4.382860   2.798893\n",
       "20          20          0       1.666667      1.667181   9.959780   8.292599\n",
       "21          21          0       1.750000      1.772982   9.960458   8.187476\n",
       "22          22          1       1.833333      1.834719   5.535979   3.701259\n",
       "23          23          0       1.916667      1.917380   9.961019   8.043639\n",
       "24          24          0       2.000000      2.000827  20.040655  18.039827\n",
       "25          25          0       2.083333      2.084069  20.041310  17.957241\n",
       "26          26          0       2.166667      2.167397  20.042342  17.874945\n",
       "27          27          1       2.250000      2.250690   5.536678   3.285987\n",
       "28          28          0       2.333333      2.334062  20.043707  17.709645\n",
       "29          29          0       2.416667      2.417389  20.043879  17.626490\n",
       "30          30          0       2.500000      2.500784  20.045838  17.545054\n",
       "31          31          1       2.583333      2.584122   6.697081   4.112959\n",
       "32          32          0       2.666667      2.667379  20.046916  17.379538\n",
       "33          33          2       2.750000      2.750757   3.369016   0.618259\n",
       "34          34          0       2.833333      2.833942  20.047434  17.213492\n",
       "35          35          2       2.916667      2.917313   4.366679   1.449366\n",
       "36          36          0       3.000000      3.000836  20.049415  17.048579\n",
       "37          37          0       3.083333      3.084127  20.049578  16.965451\n",
       "38          38          0       3.166667      3.167450  20.050339  16.882889\n",
       "39          39          0       3.250000      3.250731  20.050792  16.800062\n",
       "40          40          0       3.333333      3.334266  20.050668  16.716402\n",
       "41          41          0       3.416667      3.417484  20.051989  16.634505\n",
       "42          42          0       3.500000      3.500878  20.052709  16.551831\n",
       "43          43          0       3.583333      3.584084  20.053858  16.469774\n",
       "44          44          0       3.666667      3.667574  20.054546  16.386972\n",
       "45          45          0       3.750000      3.750790  20.054774  16.303983\n",
       "46          46          1       3.833333      3.834003   6.697238   2.863235\n",
       "47          47          0       3.916667      3.917358  25.640312  21.722954\n",
       "48          48          0       4.000000      4.000709  25.641368  21.640659\n",
       "49          49          0       4.083333      4.084071  25.642101  21.558030\n",
       "50          50          0       4.166667      4.167351  25.643583  21.476231\n",
       "51          51          0       4.250000      4.250762  25.645457  21.394695\n",
       "52          52          0       4.333333      4.334132  25.644856  21.310724\n",
       "53          53          1       4.416667      4.417527   8.475556   4.058029\n",
       "54          54          0       4.500000      4.500820  25.646139  21.145319\n",
       "55          55          1       4.583333      4.584014   8.476129   3.892115\n",
       "56          56          1       4.666667      4.667519   8.477106   3.809587\n",
       "57          57          0       4.750000      4.750772  25.646277  20.895505\n",
       "58          58          0       4.833333      4.834465  25.647079  20.812614\n",
       "59          59          0       4.916667      4.917452  25.647277  20.729825"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_model_ids(lambda_: float, num_models: int, num_points: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Draw model IDs at random from a truncated Poisson distribution.\n",
    "\n",
    "    :param lambda_: Primary parameter of the distribution, which also happens to \n",
    "     be the mean value of the (untruncated) distribution.\n",
    "    :num_models: Number of models. This function will truncate the Poisson \n",
    "     distribution such that only values < num_models will be returned.\n",
    "    :param num_points: Number of random model IDs to return.\n",
    "\n",
    "    :returns: Randomly generated model IDs for a series of requests, as a\n",
    "     1-dimensional array.\n",
    "    \"\"\"\n",
    "    # Draw numbers from a truncated Poisson distribution.\n",
    "    # Start with a non-truncated distribution, then resample for\n",
    "    # any values that went over the limit. \n",
    "    rng = np.random.default_rng()\n",
    "    result = rng.poisson(lambda_, size=num_points)\n",
    "    while np.any(result >= num_models):\n",
    "        new_values = rng.poisson(lambda_, size=np.sum(result >= num_models))\n",
    "        result[result >= num_models] = new_values\n",
    "    return result\n",
    "\n",
    "\n",
    "def run_benchmark(model_callback: Callable, requests_per_sec: float, num_sec: int,\n",
    "                  lambda_: float = 0.3) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    A simple benchmark in Python.\n",
    "\n",
    "    Sends a constant-rate stream of requests to multiple models, with the division\n",
    "    of traffic among models following a truncated Poisson distribution.\n",
    "\n",
    "    Because some notebook servers (i.e. VSCode) don't play well with \n",
    "    asyncio, we use threads to manage concurrent requests.\n",
    "\n",
    "    :param model_callback: Thread-safe callback function that makes a \n",
    "     single request and returns elapsed time. Should have the signature\n",
    "     `f(model_num: int, question: str, context: str, expected_answer: str)`\n",
    "    :param request_per_sec: Constant request rate to use\n",
    "    :param num_sec: Seconds of traffic to generate at the requested rate.\n",
    "     The actual session will extend past this window until all open requests have\n",
    "     finished.\n",
    "    :param lambda_: Primary parameter of the truncated Poisson distribution\n",
    "     used to split requests among models. Approximately equal to the mean of\n",
    "     the distribution. The default value of 0.3 sends 70% of traffic to model 0.\n",
    "\n",
    "    :returns: DataFrame of benchmark results at per-request granularity\n",
    "    \"\"\"\n",
    "    # Convert benchmark paramters into a more useable internal form\n",
    "    sec_per_request = 1.0 / requests_per_sec\n",
    "    num_requests = int(num_sec * requests_per_sec)\n",
    "\n",
    "    # Preallocate the trace as a set of lists.\n",
    "    benchmark_start_time = time.time()\n",
    "    desired_start_times = [benchmark_start_time + (sec_per_request * i)\n",
    "                           for i in range(num_requests)]\n",
    "    model_nums = gen_model_ids(lambda_, NUM_QA_MODELS, num_requests)\n",
    "    actual_start_times = [None] * num_requests\n",
    "    end_times = [None] * num_requests\n",
    "\n",
    "    # Unbounded thread pool\n",
    "    thread_pool = concurrent.futures.ThreadPoolExecutor(1000)\n",
    "\n",
    "    # Map from request object to request number\n",
    "    active_requests = {}  # type: Dict[concurrent.futures.Future, int]\n",
    "\n",
    "    # Main event loop: Spawn background requests, get their responses.\n",
    "    request_num = 0\n",
    "    while request_num < num_requests or len(active_requests) > 0:\n",
    "        sec_to_next = (\n",
    "            1.0 if request_num >= num_requests\n",
    "            else desired_start_times[request_num] - time.time()\n",
    "        )\n",
    "        if sec_to_next <= 0:\n",
    "            # Time to send the next request\n",
    "            model_num = model_nums[request_num]\n",
    "            future = thread_pool.submit(\n",
    "                model_callback, model_num,\n",
    "                qa_input[\"question\"], qa_input[\"context\"], qa_answer)\n",
    "            active_requests[future] = request_num\n",
    "            request_num += 1\n",
    "        else:\n",
    "            # Block until it's time to send the next request or a previous\n",
    "            # request is done.\n",
    "            ready_set, _ = concurrent.futures.wait(\n",
    "                list(active_requests.keys()), \n",
    "                timeout=sec_to_next)\n",
    "\n",
    "            # Record timings from any open requests that have completed.\n",
    "            for future in ready_set:\n",
    "                request_id = active_requests.pop(future)\n",
    "                start_time, end_time = future.result()\n",
    "                actual_start_times[request_id] = start_time\n",
    "                end_times[request_id] = end_time\n",
    "\n",
    "    # Collate results as a DataFrame\n",
    "    result = pd.DataFrame({\n",
    "        \"request_id\": range(num_requests),\n",
    "        \"model_num\": model_nums, \n",
    "        \"desired_start\": desired_start_times, \n",
    "        \"actual_start\": actual_start_times, \n",
    "        \"end\": end_times\n",
    "    })\n",
    "\n",
    "    # Make all times relative to start of the trace\n",
    "    for key in (\"desired_start\", \"actual_start\", \"end\"):\n",
    "        result[key] -= benchmark_start_time\n",
    "    result[\"latency\"] = result[\"end\"] - result[\"actual_start\"]\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# Quick test run\n",
    "run_benchmark(call_model, 12, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a5047d",
   "metadata": {},
   "source": [
    "Let's run the benchmark with our baseline model deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79f53994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running at 2 requests/sec.\n",
      "Running at 3 requests/sec.\n",
      "Running at 4 requests/sec.\n",
      "Running at 5 requests/sec.\n",
      "Running at 6 requests/sec.\n",
      "Running at 8 requests/sec.\n",
      "Running at 10 requests/sec.\n",
      "Running at 12 requests/sec.\n",
      "Running at 14 requests/sec.\n"
     ]
    }
   ],
   "source": [
    "# Run the benchmark at multiple different request rates\n",
    "REQUEST_RATES = (2, 3, 4, 5, 6, 8, 10, 12, 14)\n",
    "RUNNING_TIME_SEC = 20\n",
    "to_concat = []\n",
    "for request_rate in REQUEST_RATES:\n",
    "    print(f\"Running at {request_rate} requests/sec.\")\n",
    "    times = run_benchmark(call_model, request_rate, RUNNING_TIME_SEC)\n",
    "    times.insert(0, \"request_rate\", request_rate)\n",
    "    to_concat.append(times)\n",
    "\n",
    "results = pd.concat(to_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e96396d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request_rate</th>\n",
       "      <th>request_id</th>\n",
       "      <th>model_num</th>\n",
       "      <th>desired_start</th>\n",
       "      <th>actual_start</th>\n",
       "      <th>end</th>\n",
       "      <th>latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>0.598512</td>\n",
       "      <td>0.597824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.100573</td>\n",
       "      <td>0.677595</td>\n",
       "      <td>0.577022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.200560</td>\n",
       "      <td>2.982452</td>\n",
       "      <td>2.781892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.300656</td>\n",
       "      <td>2.982779</td>\n",
       "      <td>2.682123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.400585</td>\n",
       "      <td>2.981026</td>\n",
       "      <td>2.580440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>10</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.501365</td>\n",
       "      <td>88.028450</td>\n",
       "      <td>68.527084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>10</td>\n",
       "      <td>196</td>\n",
       "      <td>0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>19.601294</td>\n",
       "      <td>88.030012</td>\n",
       "      <td>68.428718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>10</td>\n",
       "      <td>197</td>\n",
       "      <td>0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.701446</td>\n",
       "      <td>88.027074</td>\n",
       "      <td>68.325628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>10</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.801301</td>\n",
       "      <td>88.020692</td>\n",
       "      <td>68.219391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>10</td>\n",
       "      <td>199</td>\n",
       "      <td>2</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.901312</td>\n",
       "      <td>20.508152</td>\n",
       "      <td>0.606840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     request_rate  request_id  model_num  desired_start  actual_start  \\\n",
       "0              10           0          0            0.0      0.000687   \n",
       "1              10           1          1            0.1      0.100573   \n",
       "2              10           2          0            0.2      0.200560   \n",
       "3              10           3          0            0.3      0.300656   \n",
       "4              10           4          0            0.4      0.400585   \n",
       "..            ...         ...        ...            ...           ...   \n",
       "195            10         195          0           19.5     19.501365   \n",
       "196            10         196          0           19.6     19.601294   \n",
       "197            10         197          0           19.7     19.701446   \n",
       "198            10         198          0           19.8     19.801301   \n",
       "199            10         199          2           19.9     19.901312   \n",
       "\n",
       "           end    latency  \n",
       "0     0.598512   0.597824  \n",
       "1     0.677595   0.577022  \n",
       "2     2.982452   2.781892  \n",
       "3     2.982779   2.682123  \n",
       "4     2.981026   2.580440  \n",
       "..         ...        ...  \n",
       "195  88.028450  68.527084  \n",
       "196  88.030012  68.428718  \n",
       "197  88.027074  68.325628  \n",
       "198  88.020692  68.219391  \n",
       "199  20.508152   0.606840  \n",
       "\n",
       "[200 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[results[\"request_rate\"] == 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41097a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">latency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request_rate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.823223</td>\n",
       "      <td>0.711840</td>\n",
       "      <td>1.710964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.632496</td>\n",
       "      <td>3.559592</td>\n",
       "      <td>8.935509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.569451</td>\n",
       "      <td>4.460295</td>\n",
       "      <td>15.768425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.835998</td>\n",
       "      <td>10.222980</td>\n",
       "      <td>26.460494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17.924395</td>\n",
       "      <td>23.239724</td>\n",
       "      <td>36.017753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>28.635715</td>\n",
       "      <td>23.774603</td>\n",
       "      <td>56.035316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>34.863745</td>\n",
       "      <td>40.067194</td>\n",
       "      <td>72.095605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>45.275019</td>\n",
       "      <td>54.754834</td>\n",
       "      <td>94.860349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>53.107382</td>\n",
       "      <td>53.258820</td>\n",
       "      <td>115.447977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                latency                       \n",
       "                   mean     median         max\n",
       "request_rate                                  \n",
       "2              0.823223   0.711840    1.710964\n",
       "3              3.632496   3.559592    8.935509\n",
       "4              5.569451   4.460295   15.768425\n",
       "5             10.835998  10.222980   26.460494\n",
       "6             17.924395  23.239724   36.017753\n",
       "8             28.635715  23.774603   56.035316\n",
       "10            34.863745  40.067194   72.095605\n",
       "12            45.275019  54.754834   94.860349\n",
       "14            53.107382  53.258820  115.447977"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_results = results.groupby(\"request_rate\").aggregate({\"latency\": [\"mean\", \"median\", \"max\"]})\n",
    "agg_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9496843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Average Latency (sec)')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(agg_results.index, agg_results[\"latency\", \"mean\"])\n",
    "plt.xlabel(\"Requests per Second\")\n",
    "plt.ylabel(\"Average Latency (sec)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d457420",
   "metadata": {},
   "source": [
    "## Using zero-copy model loading\n",
    "\n",
    "Now let's redo this baseline using zero-copy model loading.\n",
    "First we'll need to convert the model into a format that can be loaded without copying\n",
    "data. The model is actually a pipeline of multiple operations, but the RoBERTa model\n",
    "at its center is orders of magnitude larger and more CPU-intensive than everything else, so we'll only apply zero-copy loading to that part.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7add2053",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=9952)\u001b[0m 2021-10-20 21:04:25,851\tINFO backend_state.py:914 -- Removing 1 replicas from deployment 'qa0'. component=serve deployment=qa0\n",
      "\u001b[2m\u001b[36m(pid=9952)\u001b[0m 2021-10-20 21:04:25,856\tINFO backend_state.py:914 -- Removing 1 replicas from deployment 'qa1'. component=serve deployment=qa1\n",
      "\u001b[2m\u001b[36m(pid=9952)\u001b[0m 2021-10-20 21:04:25,861\tINFO backend_state.py:914 -- Removing 1 replicas from deployment 'qa2'. component=serve deployment=qa2\n",
      "\u001b[2m\u001b[36m(pid=9952)\u001b[0m 2021-10-20 21:04:25,872\tINFO backend_state.py:914 -- Removing 1 replicas from deployment 'qa3'. component=serve deployment=qa3\n",
      "\u001b[2m\u001b[36m(pid=9952)\u001b[0m 2021-10-20 21:04:25,878\tINFO backend_state.py:914 -- Removing 1 replicas from deployment 'qa4'. component=serve deployment=qa4\n",
      "\u001b[2m\u001b[36m(pid=9952)\u001b[0m 2021-10-20 21:04:25,882\tINFO backend_state.py:914 -- Removing 1 replicas from deployment 'qa5'. component=serve deployment=qa5\n",
      "\u001b[2m\u001b[36m(pid=9952)\u001b[0m 2021-10-20 21:04:25,887\tINFO backend_state.py:914 -- Removing 1 replicas from deployment 'qa6'. component=serve deployment=qa6\n",
      "\u001b[2m\u001b[36m(pid=9952)\u001b[0m 2021-10-20 21:04:25,892\tINFO backend_state.py:914 -- Removing 1 replicas from deployment 'qa7'. component=serve deployment=qa7\n",
      "\u001b[2m\u001b[36m(pid=9952)\u001b[0m 2021-10-20 21:04:25,897\tINFO backend_state.py:914 -- Removing 1 replicas from deployment 'qa8'. component=serve deployment=qa8\n",
      "\u001b[2m\u001b[36m(pid=9952)\u001b[0m 2021-10-20 21:04:25,901\tINFO backend_state.py:914 -- Removing 1 replicas from deployment 'qa9'. component=serve deployment=qa9\n",
      "\u001b[2m\u001b[36m(pid=9952)\u001b[0m 2021-10-20 21:04:25,907\tINFO backend_state.py:914 -- Removing 1 replicas from deployment 'qa10'. component=serve deployment=qa10\n",
      "\u001b[2m\u001b[36m(pid=9952)\u001b[0m 2021-10-20 21:04:25,916\tINFO backend_state.py:914 -- Removing 1 replicas from deployment 'qa11'. component=serve deployment=qa11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12520)\u001b[0m 2021-10-20 21:04:29,358\tINFO checkpoint_path.py:15 -- Using RayInternalKVStore for controller checkpoint and recovery.\n",
      "\u001b[2m\u001b[36m(pid=12520)\u001b[0m 2021-10-20 21:04:29,362\tINFO http_state.py:75 -- Starting HTTP proxy with name 'SERVE_CONTROLLER_ACTOR:tRFmJV:SERVE_PROXY_ACTOR-node:10.168.112.7-0' on node 'node:10.168.112.7-0' listening on '127.0.0.1:8000'\n",
      "2021-10-20 21:04:29,712\tINFO api.py:455 -- Started Serve instance in namespace '0dae731c-037d-42fa-bc56-a7050297e30b'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ray.serve.api.Client at 0x7f91387a7460>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serve.shutdown()\n",
    "reboot_ray()\n",
    "serve.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6565396",
   "metadata": {},
   "source": [
    "## Introducing `zerocopy`\n",
    "\n",
    "We've created a Python package, `zerocopy`, with the model rewrite code from our previous post (TODO: Publish the package to PyPI).\n",
    "\n",
    "To use that package, you'll need to install it with `pip`, then import it into your script.\n",
    "\n",
    "```python\n",
    "import zerocopy\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33ab4adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=12511)\u001b[0m INFO:     Started server process [12511]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Move this code to the `zerocopy` library.\n",
    "@ray.remote\n",
    "def call_model_zero_copy(model_ref: ray.ObjectRef, args, kwargs) -> Any:\n",
    "    \"\"\"\n",
    "    Ray task that uses zero-copy model loading to reconstitute a model\n",
    "    from Plasma, then invokes the model's ``__call__()`` method.\n",
    "\n",
    "    :param model_ref: Object reference to a tuple of model skeleton\n",
    "     and model weights, as returned by :func:`extract_tensors`\n",
    "    :param args: Ordered arguments to pass to the model's :func:`__call__`\n",
    "     method\n",
    "    :param kwargs: Keyword arguments to pass to the model's :func:`__call__`\n",
    "     method\n",
    "\n",
    "    :returns: Return value from the model's :func:`__call__` method\n",
    "    \"\"\"\n",
    "    # Suppress PyTorch warnings about immutable tensors\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    model_skeleton, model_weights = model_ref\n",
    "    zerocopy.replace_tensors(model_skeleton, model_weights)\n",
    "    with torch.no_grad():\n",
    "        return model_skeleton(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e7941cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[ 3.7534, -8.7741, -9.1023, -6.6326, -8.7627, -8.6893, -9.7706, -9.6873,\n",
       "         -9.6512, -4.1902, -7.6596, -8.5491, -7.9478, -7.5671, -9.0784, -8.2897,\n",
       "         -7.5410, -5.9760, -7.2943, -6.4249, -9.3297, -8.9922, -7.9955, -8.9485,\n",
       "         -8.7506, -6.1065, -8.2273, -8.4471, -8.9334, -2.9227, -2.8201, -4.6316,\n",
       "         -5.5576, -5.7634, -5.8722, -5.9716, -6.2091, -6.0458, -5.3727, -9.8484,\n",
       "         -8.4069, -7.6116, -5.1946, -8.7245, -4.3298, -8.3712, -8.5934, -4.6927,\n",
       "         -8.6297, -5.4113, -8.5218, -6.5587, -6.0347, -9.0888, -3.9168, -3.7715,\n",
       "         -4.0178, -5.5528, -6.2156, -6.1800, -6.1387, -6.2229, -6.4473, -6.3201,\n",
       "         -6.2259, -8.2617, -8.0752, -8.5442, -7.0337, -5.3173, -7.1967, -8.6134,\n",
       "         -5.5957, -9.0524, -8.1817, -7.5553, -7.3491, -8.5218, -7.5425, -7.8877,\n",
       "         -8.3360, -8.1147, -5.0947, -5.1871, -6.5926, -6.7610, -6.7855, -6.8672,\n",
       "         -6.9245, -6.7498, -7.7118, -8.6336, -8.0724, -7.3320, -7.0676, -8.8112,\n",
       "         -4.9942, -5.8767, -9.1029, -7.2982, -6.3021, -9.7423, -7.1146, -7.1081,\n",
       "         -6.9473, -8.5740, -3.0519, -6.5594, -8.5219, -4.1875, -3.3123, -4.7947,\n",
       "         -6.0620, -6.2542, -6.3127, -6.3891, -6.4033, -5.8774, -8.3484, -8.4814,\n",
       "         -9.0725, -8.4167, -9.2634, -8.2589, -7.3816, -8.6027, -5.9291, -2.9634,\n",
       "         -7.5559, -5.7752, -5.7358, -2.7407, -9.7852, -8.8764, -8.4199, -9.4240,\n",
       "         -9.2364, -6.2053, -3.3876, -7.0878, -5.4361, -4.9418, -4.3873, -6.6898,\n",
       "         -6.8614, -6.9100, -6.7906, -6.6952, -6.9213, -7.2896, -7.4180, -5.0012,\n",
       "         -7.7606, -4.3374, -9.5112, -3.4502, -3.6575, -5.4360, -5.9422, -6.0169,\n",
       "         -6.0962, -6.1794, -6.1066, -5.3584, -9.5739]],\n",
       "       grad_fn=<CopyBackwards>), end_logits=tensor([[ 4.4085, -9.0466, -8.8865, -8.7139, -8.4380, -6.1985, -8.0720, -8.6342,\n",
       "         -8.5613, -8.2167, -3.1857, -8.5013, -9.1181, -9.5205, -8.6247, -9.3529,\n",
       "         -9.5464, -7.6825, -6.5827, -5.3342, -7.0454, -8.8780, -9.4053, -8.9716,\n",
       "         -9.1811, -5.5211, -8.8220, -7.2581, -8.8071, -3.8688, -2.2351, -4.3839,\n",
       "         -4.6088, -4.6001, -4.5076, -4.4578, -4.5339, -4.5748, -3.9645, -7.4804,\n",
       "         -9.4568, -9.2952, -5.0298, -9.1183, -8.2703, -6.1834, -8.8689, -4.8877,\n",
       "         -9.0013, -3.7470, -5.0784, -9.5459, -7.1008, -8.6576, -4.8155, -4.2922,\n",
       "         -2.7303, -4.5583, -4.8196, -4.7327, -4.6521, -4.6179, -4.7436, -4.8457,\n",
       "         -8.8704, -5.5503, -9.1086, -9.2351, -9.6451, -7.8936, -5.3242, -8.5684,\n",
       "         -5.8515, -8.7893, -9.1167, -6.6691, -4.8255, -5.0784, -9.5671, -8.4143,\n",
       "         -9.0938, -8.9134, -4.9596, -5.5421, -5.9617, -5.8093, -5.7694, -5.6697,\n",
       "         -5.1522, -4.9800, -7.5636, -6.4838, -9.3509, -9.7418, -8.4976, -9.0644,\n",
       "         -7.2498, -4.1803, -8.6530, -8.6244, -4.0320, -7.6777, -9.3713, -9.6320,\n",
       "         -8.6084, -8.9086, -4.2255, -2.6947, -5.0785, -4.4284, -2.9734, -5.2723,\n",
       "         -5.7548, -5.7846, -5.6469, -5.3465, -4.7512, -4.2537, -9.1724, -8.5388,\n",
       "         -9.1766, -9.1957, -8.9629, -9.5458, -9.0349, -7.9539, -9.7081, -5.0877,\n",
       "         -7.9361, -6.1761, -8.4385, -1.4253, -4.2468, -8.7981, -9.2489, -8.5449,\n",
       "         -9.0143, -9.6156, -5.2834, -7.8561, -4.6573, -4.8583, -3.0356, -5.0068,\n",
       "         -5.2084, -5.2549, -5.0224, -4.8224, -4.8028, -5.2435, -9.3175, -8.6061,\n",
       "         -8.7362, -2.4815, -5.2484, -3.2335, -4.3040, -5.2170, -5.4810, -5.4640,\n",
       "         -5.3760, -5.0714, -4.5941, -3.6325, -8.8697]],\n",
       "       grad_fn=<CopyBackwards>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the model directly\n",
    "inputs = qa.tokenizer(qa_input[\"question\"], qa_input[\"context\"], return_tensors=\"pt\")\n",
    "qa.model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6157e447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[ 3.7534, -8.7741, -9.1023, -6.6326, -8.7627, -8.6893, -9.7706, -9.6873,\n",
       "         -9.6512, -4.1902, -7.6596, -8.5491, -7.9478, -7.5671, -9.0784, -8.2897,\n",
       "         -7.5410, -5.9760, -7.2943, -6.4249, -9.3297, -8.9922, -7.9955, -8.9485,\n",
       "         -8.7506, -6.1065, -8.2273, -8.4471, -8.9334, -2.9227, -2.8201, -4.6316,\n",
       "         -5.5576, -5.7634, -5.8722, -5.9716, -6.2091, -6.0458, -5.3727, -9.8484,\n",
       "         -8.4069, -7.6116, -5.1946, -8.7245, -4.3298, -8.3712, -8.5934, -4.6927,\n",
       "         -8.6297, -5.4113, -8.5218, -6.5587, -6.0347, -9.0888, -3.9168, -3.7715,\n",
       "         -4.0178, -5.5528, -6.2156, -6.1800, -6.1387, -6.2229, -6.4473, -6.3201,\n",
       "         -6.2259, -8.2617, -8.0752, -8.5442, -7.0337, -5.3173, -7.1967, -8.6134,\n",
       "         -5.5957, -9.0524, -8.1817, -7.5553, -7.3491, -8.5218, -7.5425, -7.8877,\n",
       "         -8.3360, -8.1147, -5.0947, -5.1871, -6.5926, -6.7610, -6.7855, -6.8672,\n",
       "         -6.9245, -6.7498, -7.7118, -8.6336, -8.0724, -7.3320, -7.0676, -8.8112,\n",
       "         -4.9942, -5.8767, -9.1029, -7.2982, -6.3021, -9.7423, -7.1146, -7.1081,\n",
       "         -6.9473, -8.5740, -3.0519, -6.5594, -8.5219, -4.1875, -3.3123, -4.7947,\n",
       "         -6.0620, -6.2542, -6.3127, -6.3891, -6.4033, -5.8774, -8.3484, -8.4814,\n",
       "         -9.0725, -8.4167, -9.2634, -8.2589, -7.3816, -8.6027, -5.9291, -2.9634,\n",
       "         -7.5559, -5.7752, -5.7358, -2.7407, -9.7852, -8.8764, -8.4199, -9.4240,\n",
       "         -9.2364, -6.2053, -3.3876, -7.0878, -5.4361, -4.9418, -4.3873, -6.6898,\n",
       "         -6.8614, -6.9100, -6.7906, -6.6952, -6.9213, -7.2896, -7.4180, -5.0012,\n",
       "         -7.7606, -4.3374, -9.5112, -3.4502, -3.6575, -5.4360, -5.9422, -6.0169,\n",
       "         -6.0962, -6.1794, -6.1066, -5.3584, -9.5739]]), end_logits=tensor([[ 4.4085, -9.0466, -8.8865, -8.7139, -8.4380, -6.1985, -8.0720, -8.6342,\n",
       "         -8.5613, -8.2167, -3.1857, -8.5013, -9.1181, -9.5205, -8.6247, -9.3529,\n",
       "         -9.5464, -7.6825, -6.5827, -5.3342, -7.0454, -8.8780, -9.4053, -8.9716,\n",
       "         -9.1811, -5.5211, -8.8220, -7.2581, -8.8071, -3.8688, -2.2351, -4.3839,\n",
       "         -4.6088, -4.6001, -4.5076, -4.4578, -4.5339, -4.5748, -3.9645, -7.4804,\n",
       "         -9.4568, -9.2952, -5.0298, -9.1183, -8.2703, -6.1834, -8.8689, -4.8877,\n",
       "         -9.0013, -3.7470, -5.0784, -9.5459, -7.1008, -8.6576, -4.8155, -4.2922,\n",
       "         -2.7303, -4.5583, -4.8196, -4.7327, -4.6521, -4.6179, -4.7436, -4.8457,\n",
       "         -8.8704, -5.5503, -9.1086, -9.2351, -9.6451, -7.8936, -5.3242, -8.5684,\n",
       "         -5.8515, -8.7893, -9.1167, -6.6691, -4.8255, -5.0784, -9.5671, -8.4143,\n",
       "         -9.0938, -8.9134, -4.9596, -5.5421, -5.9617, -5.8093, -5.7694, -5.6697,\n",
       "         -5.1522, -4.9800, -7.5636, -6.4838, -9.3509, -9.7418, -8.4976, -9.0644,\n",
       "         -7.2498, -4.1803, -8.6530, -8.6244, -4.0320, -7.6777, -9.3713, -9.6320,\n",
       "         -8.6084, -8.9086, -4.2255, -2.6947, -5.0785, -4.4284, -2.9734, -5.2723,\n",
       "         -5.7548, -5.7846, -5.6469, -5.3465, -4.7512, -4.2537, -9.1724, -8.5388,\n",
       "         -9.1766, -9.1957, -8.9629, -9.5458, -9.0349, -7.9539, -9.7081, -5.0877,\n",
       "         -7.9361, -6.1761, -8.4385, -1.4253, -4.2468, -8.7981, -9.2489, -8.5449,\n",
       "         -9.0143, -9.6156, -5.2834, -7.8561, -4.6573, -4.8583, -3.0356, -5.0068,\n",
       "         -5.2084, -5.2549, -5.0224, -4.8224, -4.8028, -5.2435, -9.3175, -8.6061,\n",
       "         -8.7362, -2.4815, -5.2484, -3.2335, -4.3040, -5.2170, -5.4810, -5.4640,\n",
       "         -5.3760, -5.0714, -4.5941, -3.6325, -8.8697]]), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the model via `call_model`. Results should be the same as the previous cell.\n",
    "model_ref = ray.put(zerocopy.extract_tensors(qa.model))\n",
    "ray.get(call_model_zero_copy.remote(model_ref, [], inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ae691c",
   "metadata": {},
   "source": [
    "The time to invoke the model once via `call_model_zero_copy()` is almost the same as running the model locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca2416e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Time to run locally: 527 ms ± 4.48 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Time to run with zero-copy: 600 ms ± 13.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Compare timings\n",
    "print(\"       Time to run locally: \", end=\"\")\n",
    "%timeit qa.model(**inputs)\n",
    "print(\"Time to run with zero-copy: \", end=\"\")\n",
    "%timeit ray.get(call_model_zero_copy.remote(model_ref, [], inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ccc91c",
   "metadata": {},
   "source": [
    "If we run inference multiple times, `call_model_zero_copy()` can send those inference requests to separate Ray tasks that run in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2b7b275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Time to run 100 times locally: 51.5 s ± 80.1 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n",
      "Time to run 100 times with zero-copy: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13783)\u001b[0m [2021-10-20 21:08:13,906 C 13783 13846] core_worker.cc:210:  Check failed: core_worker_process The core worker process is not initialized yet or already shutdown.\n",
      "\u001b[2m\u001b[36m(pid=13783)\u001b[0m *** StackTrace Information ***\n",
      "\u001b[2m\u001b[36m(pid=13783)\u001b[0m     ray::SpdLogMessage::Flush()\n",
      "\u001b[2m\u001b[36m(pid=13783)\u001b[0m     ray::RayLog::~RayLog()\n",
      "\u001b[2m\u001b[36m(pid=13783)\u001b[0m     ray::core::CoreWorkerProcess::EnsureInitialized()\n",
      "\u001b[2m\u001b[36m(pid=13783)\u001b[0m     ray::core::CoreWorkerProcess::GetCoreWorker()\n",
      "\u001b[2m\u001b[36m(pid=13783)\u001b[0m     __pyx_pw_3ray_7_raylet_10CoreWorker_23get_worker_id()\n",
      "\u001b[2m\u001b[36m(pid=13783)\u001b[0m     method_vectorcall_NOARGS\n",
      "\u001b[2m\u001b[36m(pid=13783)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.3 s ± 41.2 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def run_local(num_repeats: int):\n",
    "    for _ in range(num_repeats):\n",
    "        qa.model(**inputs)\n",
    "\n",
    "\n",
    "def run_zero_copy(num_repeats: int):\n",
    "    futures = [call_model_zero_copy.remote(model_ref, [], inputs) for _ in range(num_repeats)]\n",
    "    ray.get(futures)\n",
    "\n",
    "\n",
    "NUM_REPEATS = 100\n",
    "print(f\"       Time to run {NUM_REPEATS} times locally: \", end=\"\")\n",
    "%timeit -r 3 run_local(NUM_REPEATS)\n",
    "print(f\"Time to run {NUM_REPEATS} times with zero-copy: \", end=\"\")\n",
    "%timeit -r 3 run_zero_copy(NUM_REPEATS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b43922b",
   "metadata": {},
   "source": [
    "Now let's define a Ray Serve endpoint that runs the model preprocessing code locally and farms out model inference \n",
    "to Ray tasks that use zero-copy model loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47b57958",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-20 21:08:42,105\tINFO api.py:243 -- Updating deployment 'qa0'. component=serve deployment=qa0\n",
      "2021-10-20 21:08:42,124\tINFO api.py:243 -- Updating deployment 'qa1'. component=serve deployment=qa1\n",
      "2021-10-20 21:08:42,144\tINFO api.py:243 -- Updating deployment 'qa2'. component=serve deployment=qa2\n",
      "\u001b[2m\u001b[36m(pid=12520)\u001b[0m 2021-10-20 21:08:42,157\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa0'. component=serve deployment=qa0\n",
      "\u001b[2m\u001b[36m(pid=12520)\u001b[0m 2021-10-20 21:08:42,170\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa1'. component=serve deployment=qa12021-10-20 21:08:42,249\tINFO api.py:243 -- Updating deployment 'qa3'. component=serve deployment=qa3\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=12520)\u001b[0m 2021-10-20 21:08:42,184\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa2'. component=serve deployment=qa2\n",
      "2021-10-20 21:08:42,420\tINFO api.py:243 -- Updating deployment 'qa4'. component=serve deployment=qa4\n",
      "\u001b[2m\u001b[36m(pid=12520)\u001b[0m 2021-10-20 21:08:42,360\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa3'. component=serve deployment=qa3\n",
      "\u001b[2m\u001b[36m(pid=12520)\u001b[0m 2021-10-20 21:08:42,396\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa4'. component=serve deployment=qa4\n",
      "2021-10-20 21:08:42,528\tINFO api.py:243 -- Updating deployment 'qa5'. component=serve deployment=qa5\n",
      "\u001b[2m\u001b[36m(pid=12520)\u001b[0m 2021-10-20 21:08:42,531\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa5'. component=serve deployment=qa5\n",
      "2021-10-20 21:08:42,570\tINFO api.py:243 -- Updating deployment 'qa6'. component=serve deployment=qa6\n",
      "2021-10-20 21:08:42,605\tINFO api.py:243 -- Updating deployment 'qa7'. component=serve deployment=qa7\n",
      "2021-10-20 21:08:42,647\tINFO api.py:243 -- Updating deployment 'qa8'. component=serve deployment=qa8\n",
      "\u001b[2m\u001b[36m(pid=12520)\u001b[0m 2021-10-20 21:08:42,651\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa6'. component=serve deployment=qa6\n",
      "\u001b[2m\u001b[36m(pid=12520)\u001b[0m 2021-10-20 21:08:42,664\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa7'. component=serve deployment=qa7\n",
      "\u001b[2m\u001b[36m(pid=12520)\u001b[0m 2021-10-20 21:08:42,678\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa8'. component=serve deployment=qa8\n",
      "2021-10-20 21:08:42,828\tINFO api.py:243 -- Updating deployment 'qa9'. component=serve deployment=qa9\n",
      "\u001b[2m\u001b[36m(pid=12520)\u001b[0m 2021-10-20 21:08:42,858\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa9'. component=serve deployment=qa9\n",
      "2021-10-20 21:08:42,925\tINFO api.py:243 -- Updating deployment 'qa10'. component=serve deployment=qa10\n",
      "2021-10-20 21:08:42,983\tINFO api.py:243 -- Updating deployment 'qa11'. component=serve deployment=qa11\n",
      "\u001b[2m\u001b[36m(pid=12520)\u001b[0m 2021-10-20 21:08:42,997\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa10'. component=serve deployment=qa10\n",
      "\u001b[2m\u001b[36m(pid=12520)\u001b[0m 2021-10-20 21:08:43,010\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa11'. component=serve deployment=qa11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(qa9 pid=12519)\u001b[0m \n"
     ]
    }
   ],
   "source": [
    "class ZeroCopyQAModel:\n",
    "    def __init__(self):\n",
    "        # TODO: Move this rewrite to the `zerocopy` library.\n",
    "        # Load the entire pipeline, then copy the model portion to Plasma.\n",
    "        self._qa = transformers.pipeline(\"question-answering\", model=model_name)\n",
    "        model_ref = ray.put(zerocopy.extract_tensors(self._qa.model))\n",
    "\n",
    "        # Replace the pipeline's model with a callback that farms out work to\n",
    "        # Ray tasks.\n",
    "        class _ModelCallback:\n",
    "            def __call__(self, *args, **kwargs):\n",
    "                return ray.get(call_model_zero_copy.remote(model_ref, args, kwargs))\n",
    "        self._qa.model = _ModelCallback()\n",
    "\n",
    "        # Use a threadpool because the model is called from pre/postprocessing code\n",
    "        # that is not asyncio-aware\n",
    "        self._threadpool = concurrent.futures.ThreadPoolExecutor()\n",
    "\n",
    "    async def __call__(self, request: starlette.requests.Request):\n",
    "        # Pull model inputs from URL query parameters.\n",
    "        # A production version of this code would sanitize these strings.\n",
    "        model_input = {\n",
    "            \"question\": request.query_params[\"question\"],\n",
    "            \"context\": request.query_params[\"context\"]\n",
    "        }\n",
    "        result = await asyncio.get_running_loop().run_in_executor(\n",
    "            self._threadpool, lambda: self._qa(model_input))\n",
    "        return result\n",
    "\n",
    "    def __del__(self):  # Ray Serve needs this callback\n",
    "        pass\n",
    "\n",
    "\n",
    "# Define endpoints\n",
    "NUM_QA_MODELS = 12\n",
    "deployments = [\n",
    "    serve.deployment(ZeroCopyQAModel, f\"qa{model_num}\",\n",
    "                     ray_actor_options={\"num_cpus\": 0.1})\n",
    "    for model_num in range(NUM_QA_MODELS)\n",
    "]\n",
    "\n",
    "for d in deployments:\n",
    "    d.deploy(_blocking=False)\n",
    "\n",
    "# Wait a moment so log output doesn't go to the next cell's output\n",
    "time.sleep(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ade7fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 4.278861524653621e-06, 'start': 483, 'end': 484, 'answer': '5'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try out the new deployment.\n",
    "# This web service call blocks until the asychronous deployment has completed.\n",
    "params = urllib.parse.urlencode(qa_input)\n",
    "requests.get(f\"http://127.0.0.1:8000/qa0?{params}\").json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c04338",
   "metadata": {},
   "source": [
    "We've deployed these models to the same URLs, so the benchmark code from before should work without\n",
    "any changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e922d3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(call_model_zero_copy pid=19553)\u001b[0m \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request_id</th>\n",
       "      <th>model_num</th>\n",
       "      <th>desired_start</th>\n",
       "      <th>actual_start</th>\n",
       "      <th>end</th>\n",
       "      <th>latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002588</td>\n",
       "      <td>0.651200</td>\n",
       "      <td>0.648612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.200472</td>\n",
       "      <td>0.910769</td>\n",
       "      <td>0.710297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.406986</td>\n",
       "      <td>2.784124</td>\n",
       "      <td>2.377137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.613067</td>\n",
       "      <td>6.290897</td>\n",
       "      <td>5.677830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.801439</td>\n",
       "      <td>8.471517</td>\n",
       "      <td>7.670078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000481</td>\n",
       "      <td>1.769227</td>\n",
       "      <td>0.768746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.200652</td>\n",
       "      <td>1.924669</td>\n",
       "      <td>0.724016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.400715</td>\n",
       "      <td>4.160921</td>\n",
       "      <td>2.760206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.600872</td>\n",
       "      <td>2.759574</td>\n",
       "      <td>1.158702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.800555</td>\n",
       "      <td>2.846194</td>\n",
       "      <td>1.045639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000585</td>\n",
       "      <td>9.684944</td>\n",
       "      <td>7.684359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.224483</td>\n",
       "      <td>7.891629</td>\n",
       "      <td>5.667145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.404585</td>\n",
       "      <td>7.947918</td>\n",
       "      <td>5.543332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.600659</td>\n",
       "      <td>6.068419</td>\n",
       "      <td>3.467759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.800697</td>\n",
       "      <td>8.125743</td>\n",
       "      <td>5.325046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000618</td>\n",
       "      <td>7.986601</td>\n",
       "      <td>4.985983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.200680</td>\n",
       "      <td>4.274852</td>\n",
       "      <td>1.074172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.400916</td>\n",
       "      <td>4.547098</td>\n",
       "      <td>1.146182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.605153</td>\n",
       "      <td>9.448886</td>\n",
       "      <td>5.843733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.800944</td>\n",
       "      <td>4.908642</td>\n",
       "      <td>1.107698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.004451</td>\n",
       "      <td>7.700053</td>\n",
       "      <td>3.695602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.200644</td>\n",
       "      <td>6.087351</td>\n",
       "      <td>1.886707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.400752</td>\n",
       "      <td>6.190218</td>\n",
       "      <td>1.789466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.600986</td>\n",
       "      <td>9.063387</td>\n",
       "      <td>4.462402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.800999</td>\n",
       "      <td>6.247806</td>\n",
       "      <td>1.446807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000806</td>\n",
       "      <td>8.862905</td>\n",
       "      <td>3.862099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.209259</td>\n",
       "      <td>10.532900</td>\n",
       "      <td>5.323641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5.403225</td>\n",
       "      <td>7.075255</td>\n",
       "      <td>1.672029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>5.606781</td>\n",
       "      <td>9.877049</td>\n",
       "      <td>4.270268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.802844</td>\n",
       "      <td>9.083606</td>\n",
       "      <td>3.280762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.002359</td>\n",
       "      <td>9.342659</td>\n",
       "      <td>3.340300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6.200911</td>\n",
       "      <td>9.508239</td>\n",
       "      <td>3.307328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.400827</td>\n",
       "      <td>10.702842</td>\n",
       "      <td>4.302016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>6.600456</td>\n",
       "      <td>8.788547</td>\n",
       "      <td>2.188090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>6.800660</td>\n",
       "      <td>8.901571</td>\n",
       "      <td>2.100910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.001101</td>\n",
       "      <td>9.977389</td>\n",
       "      <td>2.976288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>7.200817</td>\n",
       "      <td>9.053998</td>\n",
       "      <td>1.853180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.407904</td>\n",
       "      <td>10.069180</td>\n",
       "      <td>2.661277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.600812</td>\n",
       "      <td>9.018710</td>\n",
       "      <td>1.417898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>7.8</td>\n",
       "      <td>7.800668</td>\n",
       "      <td>10.134815</td>\n",
       "      <td>2.334147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.000651</td>\n",
       "      <td>9.823170</td>\n",
       "      <td>1.822519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>8.200696</td>\n",
       "      <td>9.876018</td>\n",
       "      <td>1.675322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>8.4</td>\n",
       "      <td>8.400688</td>\n",
       "      <td>10.211595</td>\n",
       "      <td>1.810907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.600859</td>\n",
       "      <td>10.050192</td>\n",
       "      <td>1.449333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>8.800884</td>\n",
       "      <td>9.816095</td>\n",
       "      <td>1.015211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.000874</td>\n",
       "      <td>10.275208</td>\n",
       "      <td>1.274334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>9.223427</td>\n",
       "      <td>10.350781</td>\n",
       "      <td>1.127354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>9.400805</td>\n",
       "      <td>10.509574</td>\n",
       "      <td>1.108769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.600666</td>\n",
       "      <td>10.629098</td>\n",
       "      <td>1.028433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>9.8</td>\n",
       "      <td>9.816270</td>\n",
       "      <td>10.606625</td>\n",
       "      <td>0.790355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    request_id  model_num  desired_start  actual_start        end   latency\n",
       "0            0          0            0.0      0.002588   0.651200  0.648612\n",
       "1            1          0            0.2      0.200472   0.910769  0.710297\n",
       "2            2          0            0.4      0.406986   2.784124  2.377137\n",
       "3            3          1            0.6      0.613067   6.290897  5.677830\n",
       "4            4          1            0.8      0.801439   8.471517  7.670078\n",
       "5            5          0            1.0      1.000481   1.769227  0.768746\n",
       "6            6          0            1.2      1.200652   1.924669  0.724016\n",
       "7            7          0            1.4      1.400715   4.160921  2.760206\n",
       "8            8          0            1.6      1.600872   2.759574  1.158702\n",
       "9            9          0            1.8      1.800555   2.846194  1.045639\n",
       "10          10          1            2.0      2.000585   9.684944  7.684359\n",
       "11          11          1            2.2      2.224483   7.891629  5.667145\n",
       "12          12          1            2.4      2.404585   7.947918  5.543332\n",
       "13          13          0            2.6      2.600659   6.068419  3.467759\n",
       "14          14          1            2.8      2.800697   8.125743  5.325046\n",
       "15          15          1            3.0      3.000618   7.986601  4.985983\n",
       "16          16          0            3.2      3.200680   4.274852  1.074172\n",
       "17          17          0            3.4      3.400916   4.547098  1.146182\n",
       "18          18          1            3.6      3.605153   9.448886  5.843733\n",
       "19          19          0            3.8      3.800944   4.908642  1.107698\n",
       "20          20          0            4.0      4.004451   7.700053  3.695602\n",
       "21          21          0            4.2      4.200644   6.087351  1.886707\n",
       "22          22          0            4.4      4.400752   6.190218  1.789466\n",
       "23          23          2            4.6      4.600986   9.063387  4.462402\n",
       "24          24          0            4.8      4.800999   6.247806  1.446807\n",
       "25          25          0            5.0      5.000806   8.862905  3.862099\n",
       "26          26          1            5.2      5.209259  10.532900  5.323641\n",
       "27          27          0            5.4      5.403225   7.075255  1.672029\n",
       "28          28          0            5.6      5.606781   9.877049  4.270268\n",
       "29          29          1            5.8      5.802844   9.083606  3.280762\n",
       "30          30          1            6.0      6.002359   9.342659  3.340300\n",
       "31          31          1            6.2      6.200911   9.508239  3.307328\n",
       "32          32          0            6.4      6.400827  10.702842  4.302016\n",
       "33          33          0            6.6      6.600456   8.788547  2.188090\n",
       "34          34          0            6.8      6.800660   8.901571  2.100910\n",
       "35          35          1            7.0      7.001101   9.977389  2.976288\n",
       "36          36          0            7.2      7.200817   9.053998  1.853180\n",
       "37          37          1            7.4      7.407904  10.069180  2.661277\n",
       "38          38          0            7.6      7.600812   9.018710  1.417898\n",
       "39          39          1            7.8      7.800668  10.134815  2.334147\n",
       "40          40          1            8.0      8.000651   9.823170  1.822519\n",
       "41          41          0            8.2      8.200696   9.876018  1.675322\n",
       "42          42          1            8.4      8.400688  10.211595  1.810907\n",
       "43          43          0            8.6      8.600859  10.050192  1.449333\n",
       "44          44          0            8.8      8.800884   9.816095  1.015211\n",
       "45          45          0            9.0      9.000874  10.275208  1.274334\n",
       "46          46          0            9.2      9.223427  10.350781  1.127354\n",
       "47          47          0            9.4      9.400805  10.509574  1.108769\n",
       "48          48          0            9.6      9.600666  10.629098  1.028433\n",
       "49          49          1            9.8      9.816270  10.606625  0.790355"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick test run\n",
    "run_benchmark(call_model, 5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2254dd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running at 2 requests/sec.\n",
      "Running at 3 requests/sec.\n",
      "Running at 4 requests/sec.\n",
      "Running at 5 requests/sec.\n",
      "Running at 6 requests/sec.\n",
      "Running at 8 requests/sec.\n",
      "Running at 10 requests/sec.\n",
      "Running at 12 requests/sec.\n",
      "\u001b[2m\u001b[36m(call_model_zero_copy pid=21680)\u001b[0m \n",
      "Running at 14 requests/sec.\n",
      "\u001b[2m\u001b[36m(call_model_zero_copy pid=21859)\u001b[0m \n"
     ]
    }
   ],
   "source": [
    "# Run the benchmark at multiple different request rates\n",
    "to_concat = []\n",
    "for request_rate in REQUEST_RATES:\n",
    "    print(f\"Running at {request_rate} requests/sec.\")\n",
    "    times = run_benchmark(call_model, request_rate, RUNNING_TIME_SEC)\n",
    "    times.insert(0, \"request_rate\", request_rate)\n",
    "    to_concat.append(times)\n",
    "\n",
    "results_zerocopy = pd.concat(to_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24f129d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">latency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request_rate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.620998</td>\n",
       "      <td>0.627903</td>\n",
       "      <td>0.700807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.614318</td>\n",
       "      <td>0.614274</td>\n",
       "      <td>0.647115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.761776</td>\n",
       "      <td>0.609324</td>\n",
       "      <td>2.563932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.910136</td>\n",
       "      <td>0.660313</td>\n",
       "      <td>2.830024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.156761</td>\n",
       "      <td>0.880779</td>\n",
       "      <td>3.985181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.188385</td>\n",
       "      <td>0.953722</td>\n",
       "      <td>3.547060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.392834</td>\n",
       "      <td>1.153224</td>\n",
       "      <td>4.321831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.575299</td>\n",
       "      <td>1.462212</td>\n",
       "      <td>4.366010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.673118</td>\n",
       "      <td>2.923379</td>\n",
       "      <td>4.338705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               latency                    \n",
       "                  mean    median       max\n",
       "request_rate                              \n",
       "2             0.620998  0.627903  0.700807\n",
       "3             0.614318  0.614274  0.647115\n",
       "4             0.761776  0.609324  2.563932\n",
       "5             0.910136  0.660313  2.830024\n",
       "6             1.156761  0.880779  3.985181\n",
       "8             1.188385  0.953722  3.547060\n",
       "10            1.392834  1.153224  4.321831\n",
       "12            1.575299  1.462212  4.366010\n",
       "14            2.673118  2.923379  4.338705"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_results_zerocopy = results_zerocopy.groupby(\"request_rate\").aggregate({\"latency\": [\"mean\", \"median\", \"max\"]})\n",
    "agg_results_zerocopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "381a02cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f9138676bb0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the two sets of results against each other.\n",
    "plt.rcParams.update({\"font.size\": 16})\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.scatter(agg_results.index, agg_results[\"latency\", \"mean\"],\n",
    "            label=\"baseline\")\n",
    "plt.scatter(agg_results_zerocopy.index, agg_results_zerocopy[\"latency\", \"mean\"],\n",
    "            label=\"zero-copy\")\n",
    "plt.xlabel(\"Requests per Second\")\n",
    "plt.ylabel(\"Average Latency (sec)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cac27d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old code defined an actor\n",
    "\n",
    "# class ModelCallback:\n",
    "#     def __init__(self, model_ref: ray.ObjectRef):\n",
    "#         self._model_ref = model_ref\n",
    "\n",
    "#     def __call__(self, *args: Any, **kwargs: Any) -> Any:\n",
    "#         return ray.get(call_model.remote(self._model_ref, args, kwargs))\n",
    "\n",
    "# @ray.remote\n",
    "# class QAModelZeroCopyActor:\n",
    "#     def __init__(self):\n",
    "#         self._qa = transformers.pipeline(\"question-answering\", model=model_name)\n",
    "#         self._model_ref = ray.put(zerocopy.extract_tensors(self._qa.model))\n",
    "#         self._qa.model = ModelCallback(self._model_ref)\n",
    "\n",
    "#     def run_inference(self, input_: Dict[str, str]) -> Dict[str, Any]:\n",
    "#         return self._qa(input_)\n",
    "\n",
    "# zero_copy_actors = [QAModelZeroCopyActor.options(max_concurrency=8).remote() \n",
    "#                     for _ in range(NUM_QA_MODELS)]\n",
    "# ray.get(zero_copy_actors[0].run_inference.remote(qa_input))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "afa7e0f34d224467fd24b0cfa9c212efa127bdf53fe1c4e3ddf54198f34a39e3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
