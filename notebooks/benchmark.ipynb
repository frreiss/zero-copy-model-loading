{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8270a16d",
   "metadata": {},
   "source": [
    "# benchmark.ipynb\n",
    "\n",
    "This notebook contains the text and code for the next blog post in the zero-copy model series, \n",
    "title TBD.\n",
    "\n",
    "The first post explained how to load PyTorch models for inference extremely fast by leveraging the Plasma object store's ability to load numeric data directly from shared memory.\n",
    "\n",
    "In this post, we talk in more concrete terms about how to use this zero-copy model loading for model serving. We put together a simple model serving system, then set up a microbenchmark that simulates a heavy-tailed traffic pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edbf7611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization and import code goes in this cell.\n",
    "\n",
    "# Imports: Python core, then third-party, then local.\n",
    "# Try to keep each block in alphabetical order, or the linter may get angry.\n",
    "import asyncio\n",
    "import concurrent.futures\n",
    "import requests\n",
    "import starlette\n",
    "import time\n",
    "import urllib\n",
    "from typing import Dict, Any, Callable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import ray\n",
    "from ray import serve\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "import zerocopy\n",
    "\n",
    "\n",
    "# Reduce the volume of warning messages from `transformers`\n",
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "\n",
    "def reboot_ray():\n",
    "    if ray.is_initialized():\n",
    "        ray.shutdown()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        return ray.init(num_gpus=1)\n",
    "    else:\n",
    "        return ray.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a69fefd",
   "metadata": {},
   "source": [
    "# Title of new blog post goes here\n",
    "\n",
    "*Recap of previous blog post goes here.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13eccd9",
   "metadata": {},
   "source": [
    "## Scenario\n",
    "\n",
    "The end-to-end scenario for our benchmark involves supporting an AI chatbot.\n",
    "The chatbot's conversational AI runs off of a conversation tree (**TODO:** What's the best term for this tree?). Some of the nodes of this tree invoke question answering models.\n",
    "\n",
    "Our benchmark will cover the model serving portion of the chatbot's backend. This \n",
    "model serving layer runs question answering (QA) models on behalf of the \n",
    "chatbot's conversational AI. The chatbot's conversation tree leads to 4 very different\n",
    "question answering scenarios, and each scenario has its own dedicated QA\n",
    "model. Because the chatbot speaks 3 different languages, there are three versions of\n",
    "each model deployed: one for each language. So the model serving layer runs a total of\n",
    "12 models to cover the 4 question types and 3 languages.\n",
    "\n",
    "> **TODO:** Cartoon block diagram of the end-to-end scenario. \n",
    "> Diagram should show a user interacting with a chatbot. The chatbot runs off of a conversation tree. \n",
    "> Some of the nodes of the conversation tree have question answering models hanging off of them.\n",
    "\n",
    "For our question answering models, we'll use 12 copies of `deepset/roberta-base-squad2`,\n",
    "the most popular question answering model on the [Huggingface model marketplace](https://huggingface.co/models).\n",
    "Here's some code to load that model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37dae247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load with standard method: "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce99a5e68e64a159d07115de3ea8c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48a8d0bb25634c1aa10b69ee56ec6b5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/473M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d7e68204c7459bac07bc87e2b0495a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/79.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cddc3e8e7bf434ea08b03c5e0f9943e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7760547076e640d0b8bb6f085f3aada3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "769a7a0073d742e1a3cbaa27012bb23a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.81 s ± 138 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "model_name = \"deepset/roberta-base-squad2\"\n",
    "\n",
    "# Strip out this timing code for the blog version.\n",
    "print(\"Time to load with standard method: \", end=\"\")\n",
    "%timeit -r3 transformers.pipeline(\"question-answering\", model=model_name)\n",
    "qa = transformers.pipeline(\"question-answering\", model=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260cdcae",
   "metadata": {},
   "source": [
    "The performance of this model isn't very sensitive to the specific question and context provided,\n",
    "so we define a single set of inputs and outputs for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa96aec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 4.278897904441692e-06, 'start': 483, 'end': 484, 'answer': '5'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_input = {\n",
    "    \"question\": \"What is 1 + 1?\",\n",
    "    \"context\": \n",
    "        \"\"\"Addition (usually signified by the plus symbol +) is one of the four basic operations of \n",
    "        arithmetic, the other three being subtraction, multiplication and division. The addition of two \n",
    "        whole numbers results in the total amount or sum of those values combined. The example in the\n",
    "        adjacent image shows a combination of three apples and two apples, making a total of five apples. \n",
    "        This observation is equivalent to the mathematical expression \"3 + 2 = 5\" (that is, \"3 plus 2 \n",
    "        is equal to 5\").\n",
    "        \"\"\"\n",
    "}\n",
    "\n",
    "result = qa(qa_input)\n",
    "qa_answer = result[\"answer\"]\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5494b1aa",
   "metadata": {},
   "source": [
    "## Baseline results\n",
    "\n",
    "Let's start with a baseline implementation of model serving for this model. This baseline implementation emulates running each QA model in a separate container. The server has 12 CPUs, so each container gets 1 CPU. We implement this baseline configuration with a pool of Ray actors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec60e717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=9370)\u001b[0m 2021-10-21 15:58:26,933\tINFO checkpoint_path.py:15 -- Using RayInternalKVStore for controller checkpoint and recovery.\n",
      "\u001b[2m\u001b[36m(pid=9370)\u001b[0m 2021-10-21 15:58:26,938\tINFO http_state.py:75 -- Starting HTTP proxy with name 'SERVE_CONTROLLER_ACTOR:NUwwWO:SERVE_PROXY_ACTOR-node:10.168.112.18-0' on node 'node:10.168.112.18-0' listening on '127.0.0.1:8000'\n",
      "2021-10-21 15:58:27,243\tINFO api.py:455 -- Started Serve instance in namespace '088fb46a-f98b-4099-b2f1-5d99f19f9243'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ray.serve.api.Client at 0x7f180d0e2b80>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serve.shutdown()\n",
    "reboot_ray()\n",
    "serve.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b8a6ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=9354)\u001b[0m INFO:     Started server process [9354]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-21 15:58:27,762\tINFO api.py:243 -- Updating deployment 'qa0'. component=serve deployment=qa0\n",
      "2021-10-21 15:58:27,773\tINFO api.py:243 -- Updating deployment 'qa1'. component=serve deployment=qa1\n",
      "2021-10-21 15:58:27,787\tINFO api.py:243 -- Updating deployment 'qa2'. component=serve deployment=qa2\n",
      "\u001b[2m\u001b[36m(pid=9370)\u001b[0m 2021-10-21 15:58:27,791\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa0'. component=serve deployment=qa0\n",
      "\u001b[2m\u001b[36m(pid=9370)\u001b[0m 2021-10-21 15:58:27,802\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa1'. component=serve deployment=qa1\n",
      "\u001b[2m\u001b[36m(pid=9370)\u001b[0m 2021-10-21 15:58:27,816\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa2'. component=serve deployment=qa2\n",
      "2021-10-21 15:58:27,908\tINFO api.py:243 -- Updating deployment 'qa3'. component=serve deployment=qa3\n",
      "\u001b[2m\u001b[36m(pid=9370)\u001b[0m 2021-10-21 15:58:27,950\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa3'. component=serve deployment=qa3\n",
      "2021-10-21 15:58:28,082\tINFO api.py:243 -- Updating deployment 'qa4'. component=serve deployment=qa4\n",
      "2021-10-21 15:58:28,157\tINFO api.py:243 -- Updating deployment 'qa5'. component=serve deployment=qa5\n",
      "\u001b[2m\u001b[36m(pid=9370)\u001b[0m 2021-10-21 15:58:28,122\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa4'. component=serve deployment=qa42021-10-21 15:58:28,193\tINFO api.py:243 -- Updating deployment 'qa6'. component=serve deployment=qa6\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=9370)\u001b[0m 2021-10-21 15:58:28,133\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa5'. component=serve deployment=qa5\n",
      "2021-10-21 15:58:28,266\tINFO api.py:243 -- Updating deployment 'qa7'. component=serve deployment=qa7\n",
      "\u001b[2m\u001b[36m(pid=9370)\u001b[0m 2021-10-21 15:58:28,271\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa6'. component=serve deployment=qa6\n",
      "\u001b[2m\u001b[36m(pid=9370)\u001b[0m 2021-10-21 15:58:28,283\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa7'. component=serve deployment=qa7\n",
      "2021-10-21 15:58:28,428\tINFO api.py:243 -- Updating deployment 'qa8'. component=serve deployment=qa8\n",
      "\u001b[2m\u001b[36m(pid=9370)\u001b[0m 2021-10-21 15:58:28,548\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa8'. component=serve deployment=qa8\n",
      "2021-10-21 15:58:28,658\tINFO api.py:243 -- Updating deployment 'qa9'. component=serve deployment=qa9\n",
      "2021-10-21 15:58:28,699\tINFO api.py:243 -- Updating deployment 'qa10'. component=serve deployment=qa10\n",
      "\u001b[2m\u001b[36m(pid=9370)\u001b[0m 2021-10-21 15:58:28,706\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa9'. component=serve deployment=qa9\n",
      "\u001b[2m\u001b[36m(pid=9370)\u001b[0m 2021-10-21 15:58:28,752\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa10'. component=serve deployment=qa10\n",
      "2021-10-21 15:58:28,865\tINFO api.py:243 -- Updating deployment 'qa11'. component=serve deployment=qa11\n",
      "\u001b[2m\u001b[36m(pid=9370)\u001b[0m 2021-10-21 15:58:28,895\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa11'. component=serve deployment=qa11\n"
     ]
    }
   ],
   "source": [
    "class QAModel:\n",
    "    def __init__(self):\n",
    "        self._qa = transformers.pipeline(\"question-answering\",\n",
    "                                         model=model_name)\n",
    "\n",
    "    def __call__(self, request: starlette.requests.Request):\n",
    "        # Pull model inputs from URL query parameters.\n",
    "        # A production version of this code would sanitize these strings.\n",
    "        model_input = {\n",
    "            \"question\": request.query_params[\"question\"],\n",
    "            \"context\": request.query_params[\"context\"]\n",
    "        }\n",
    "        return self._qa(model_input)\n",
    "\n",
    "\n",
    "# Define endpoints\n",
    "NUM_QA_MODELS = 12\n",
    "deployments = [\n",
    "    serve.deployment(QAModel, f\"qa{model_num}\")\n",
    "    for model_num in range(NUM_QA_MODELS)\n",
    "]\n",
    "\n",
    "for d in deployments:\n",
    "    d.deploy(_blocking=False)\n",
    "\n",
    "# Wait a moment so log output doesn't go to the next cell's output\n",
    "time.sleep(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22fcdd6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 4.278897904441692e-06, 'start': 483, 'end': 484, 'answer': '5'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try out the deployment.\n",
    "# This web service call blocks until the asychronous deployment has completed.\n",
    "params = urllib.parse.urlencode(qa_input)\n",
    "requests.get(f\"http://127.0.0.1:8000/qa0?{params}\").json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aea4da8",
   "metadata": {},
   "source": [
    "Let's wrap this model web service in a callback function that calls the model, retrieves the result, and\n",
    "returns elapsed time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "079ad698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.599 seconds elapsed'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def call_model(model_num: int, question: str, context: str, expected_answer: str) -> float:\n",
    "    \"\"\"\n",
    "    Callack function that calls the model deployment, retrieves and \n",
    "    validates the result, and returns elapsed time.\n",
    "\n",
    "    :param model_num: Index of the model to call\n",
    "    :param question: The `question` argument to pass to the QA model\n",
    "    :param context: The `context` argument to pass to the QA model\n",
    "    :param expected_answer: The answer that the model should return\n",
    "\n",
    "    :returns: Tuple of start and end times of the web service call\n",
    "    \"\"\"\n",
    "    # For now, use the same input every time\n",
    "    params = urllib.parse.urlencode({\"question\": question, \"context\": context})\n",
    "\n",
    "    start_time = time.time()\n",
    "    result = requests.get(f\"http://127.0.0.1:8000/qa{model_num}?{params}\").json()\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Do some basic validation\n",
    "    if result[\"answer\"] != expected_answer:\n",
    "        raise ValueError(f\"Unexpected result: {result}\")\n",
    "\n",
    "    return (start_time, end_time)\n",
    "\n",
    "\n",
    "times = call_model(0, qa_input[\"question\"], qa_input[\"context\"], qa_answer)\n",
    "f\"{times[1] - times[0]:1.3f} seconds elapsed\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a925870a",
   "metadata": {},
   "source": [
    "Now we can define a simple benchmark.\n",
    "\n",
    "Our benchmark generates a trace of requests, then plays back the trace and measures the \n",
    "latency of each request. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e92a1f5-3624-4f22-8a95-0b9d9c2f32d6",
   "metadata": {},
   "source": [
    "The request rate changes each second, with the rate of a particular 1-second window drawn from the Poisson\n",
    "distribution. Here's the code to generate the start times for the trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "110ace1f-9c9d-4b55-a50b-9c20d2d9fdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_start_times(requests_per_sec: float, num_sec: int,\n",
    "                    seed: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generate a trace of inference request start times. Divides the trace\n",
    "    into 1-second intervals. Each interval gets a number of requests drawn\n",
    "    from a Poissson distribution. These requests are evenly spread through the\n",
    "    interval.\n",
    "\n",
    "    :param requests_per_sec: Average requests per second overall\n",
    "    :param num_sec: Number of seconds of trace to generate\n",
    "    :param seed: Seed for the random number generator\n",
    "\n",
    "    :returns: Numpy array of timestamps (starting from 0) for the requests\n",
    "     in the trace\n",
    "    \"\"\"\n",
    "    trace = []\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # Compute the number of requests in each 1-second window.\n",
    "    req_per_window = rng.poisson(requests_per_sec, size=num_sec)\n",
    "\n",
    "    for window_num in range(num_sec):\n",
    "        num_requests = req_per_window[window_num]\n",
    "        if num_requests > 0:\n",
    "            request_interval = 1.0 / num_requests\n",
    "            for i in range(num_requests):\n",
    "                trace.append(window_num + request_interval * i)\n",
    "\n",
    "    return np.array(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c681f9-e06e-4da8-a6e8-08ae5e54fa85",
   "metadata": {},
   "source": [
    "Each request goes to a randomly-selected model. The choice of models is\n",
    "weighted according to a truncated Poisson distribution. Here's the code to generate\n",
    "the list of model IDs for the requests in the trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "451f1281-6c46-45e9-b397-5d8898717e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_model_ids(lambda_: float, num_models: int, num_points: int,\n",
    "                  seed: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Draw model IDs at random from a truncated Poisson distribution.\n",
    "\n",
    "    :param lambda_: Primary parameter of the distribution, which also happens to \n",
    "     be the mean value of the (untruncated) distribution.\n",
    "    :num_models: Number of models. This function will truncate the Poisson \n",
    "     distribution such that only values < num_models will be returned.\n",
    "    :param num_points: Number of random model IDs to return.\n",
    "    :param seed: Seed for the random number generator\n",
    "\n",
    "    :returns: Randomly generated model IDs for a series of requests, as a\n",
    "     1-dimensional array.\n",
    "    \"\"\"\n",
    "    # Draw numbers from a truncated Poisson distribution.\n",
    "    # Start with a non-truncated distribution, then resample for\n",
    "    # any values that went over the limit. \n",
    "    rng = np.random.default_rng(seed)\n",
    "    result = rng.poisson(lambda_, size=num_points)\n",
    "    while np.any(result >= num_models):\n",
    "        new_values = rng.poisson(lambda_, size=np.sum(result >= num_models))\n",
    "        result[result >= num_models] = new_values\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61453629-426e-4b09-8430-4b2c11b71a64",
   "metadata": {},
   "source": [
    "The benchmark itself generates and then plays back the trace, measuring the end-to-end latency of each request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfa55ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request_id</th>\n",
       "      <th>model_num</th>\n",
       "      <th>desired_start</th>\n",
       "      <th>actual_start</th>\n",
       "      <th>end</th>\n",
       "      <th>latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>3.506917</td>\n",
       "      <td>3.504002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.067744</td>\n",
       "      <td>4.101444</td>\n",
       "      <td>4.033699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.134026</td>\n",
       "      <td>0.946959</td>\n",
       "      <td>0.812932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200799</td>\n",
       "      <td>0.994547</td>\n",
       "      <td>0.793748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.268134</td>\n",
       "      <td>4.625826</td>\n",
       "      <td>4.357691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>4.615385</td>\n",
       "      <td>4.616436</td>\n",
       "      <td>24.369826</td>\n",
       "      <td>19.753389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>4.692308</td>\n",
       "      <td>4.693212</td>\n",
       "      <td>26.502025</td>\n",
       "      <td>21.808814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>4.769231</td>\n",
       "      <td>4.770035</td>\n",
       "      <td>26.502197</td>\n",
       "      <td>21.732162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>4.846154</td>\n",
       "      <td>4.847086</td>\n",
       "      <td>26.503609</td>\n",
       "      <td>21.656524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>4.923077</td>\n",
       "      <td>4.923958</td>\n",
       "      <td>26.503335</td>\n",
       "      <td>21.579377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    request_id  model_num  desired_start  actual_start        end    latency\n",
       "0            0          1       0.000000      0.002915   3.506917   3.504002\n",
       "1            1          1       0.066667      0.067744   4.101444   4.033699\n",
       "2            2          0       0.133333      0.134026   0.946959   0.812932\n",
       "3            3          2       0.200000      0.200799   0.994547   0.793748\n",
       "4            4          0       0.266667      0.268134   4.625826   4.357691\n",
       "..         ...        ...            ...           ...        ...        ...\n",
       "57          57          0       4.615385      4.616436  24.369826  19.753389\n",
       "58          58          0       4.692308      4.693212  26.502025  21.808814\n",
       "59          59          0       4.769231      4.770035  26.502197  21.732162\n",
       "60          60          0       4.846154      4.847086  26.503609  21.656524\n",
       "61          61          0       4.923077      4.923958  26.503335  21.579377\n",
       "\n",
       "[62 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run_benchmark(model_callback: Callable, requests_per_sec: float, \n",
    "                  num_sec: int, model_lambda: float = 0.3,\n",
    "                  seed: int = 42) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    A simple benchmark in Python.\n",
    "\n",
    "    Sends a stream of requests to multiple models, with the rate varying\n",
    "    according to a Poisson distribution and division of traffic among models\n",
    "    following a truncated Poisson distribution.\n",
    "\n",
    "    :param model_callback: Thread-safe callback function that makes a \n",
    "     single request and returns elapsed time. Should have the signature\n",
    "     `f(model_num: int, question: str, context: str, expected_answer: str)`\n",
    "    :param request_per_sec: Mean of the Poisson distribution that determines\n",
    "     the number of requests in each 1-second window.\n",
    "    :param num_sec: Seconds of traffic to generate at the requested rate.\n",
    "     The actual session will extend past this window until all open requests\n",
    "     have finished.\n",
    "    :param model_lambda: Primary parameter of the truncated Poisson\n",
    "     distribution used to split requests among models. Approximately \n",
    "     equal to the mean of the distribution. The default value of 0.3 sends\n",
    "     70% of traffic to model 0.\n",
    "    :param seed: Seed for the random number generator\n",
    "\n",
    "    :returns: DataFrame of benchmark results at per-request granularity\n",
    "    \"\"\"\n",
    "    # Preallocate the trace as a set of lists.\n",
    "    benchmark_start_time = time.time()\n",
    "    desired_start_times = (\n",
    "        gen_start_times(requests_per_sec, num_sec, seed)\n",
    "        + benchmark_start_time)\n",
    "    num_requests = desired_start_times.shape[0]\n",
    "    model_nums = gen_model_ids(model_lambda, NUM_QA_MODELS, num_requests,\n",
    "                               seed)\n",
    "    actual_start_times = [None] * num_requests\n",
    "    end_times = [None] * num_requests\n",
    "\n",
    "    # Because some notebook servers (i.e. VSCode) don't play well with\n",
    "    # asyncio, we use threads to manage concurrent requests.\n",
    "    thread_pool = concurrent.futures.ThreadPoolExecutor(1000)\n",
    "\n",
    "    # Map from request object to request number\n",
    "    active_requests = {}  # type: Dict[concurrent.futures.Future, int]\n",
    "\n",
    "    # Main event loop: Spawn background requests, get their responses.\n",
    "    request_num = 0\n",
    "    while request_num < num_requests or len(active_requests) > 0:\n",
    "        sec_to_next = (\n",
    "            1.0 if request_num >= num_requests\n",
    "            else desired_start_times[request_num] - time.time()\n",
    "        )\n",
    "        if sec_to_next <= 0:\n",
    "            # Time to send the next request\n",
    "            model_num = model_nums[request_num]\n",
    "            future = thread_pool.submit(\n",
    "                model_callback, model_num,\n",
    "                qa_input[\"question\"], qa_input[\"context\"], qa_answer)\n",
    "            active_requests[future] = request_num\n",
    "            request_num += 1\n",
    "        else:\n",
    "            # Block until it's time to send the next request or a previous\n",
    "            # request is done.\n",
    "            ready_set, _ = concurrent.futures.wait(\n",
    "                list(active_requests.keys()), \n",
    "                timeout=sec_to_next)\n",
    "\n",
    "            # Record timings from any open requests that have completed.\n",
    "            for future in ready_set:\n",
    "                request_id = active_requests.pop(future)\n",
    "                start_time, end_time = future.result()\n",
    "                actual_start_times[request_id] = start_time\n",
    "                end_times[request_id] = end_time\n",
    "\n",
    "    # Collate results as a DataFrame\n",
    "    result = pd.DataFrame({\n",
    "        \"request_id\": range(num_requests),\n",
    "        \"model_num\": model_nums, \n",
    "        \"desired_start\": desired_start_times, \n",
    "        \"actual_start\": actual_start_times, \n",
    "        \"end\": end_times\n",
    "    })\n",
    "\n",
    "    # Make all times relative to start of the trace\n",
    "    for key in (\"desired_start\", \"actual_start\", \"end\"):\n",
    "        result[key] -= benchmark_start_time\n",
    "    result[\"latency\"] = result[\"end\"] - result[\"actual_start\"]\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# Quick test run\n",
    "run_benchmark(call_model, 12, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a5047d",
   "metadata": {},
   "source": [
    "Let's run the benchmark with our baseline model deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79f53994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running at 2 requests/sec.\n",
      "Running at 3 requests/sec.\n",
      "Running at 4 requests/sec.\n",
      "Running at 5 requests/sec.\n",
      "Running at 6 requests/sec.\n",
      "Running at 8 requests/sec.\n",
      "Running at 10 requests/sec.\n",
      "Running at 12 requests/sec.\n",
      "Running at 14 requests/sec.\n"
     ]
    }
   ],
   "source": [
    "# Run the benchmark at multiple different request rates\n",
    "REQUEST_RATES = (2, 3, 4, 5, 6, 8, 10, 12, 14)\n",
    "RUNNING_TIME_SEC = 60\n",
    "to_concat = []\n",
    "for request_rate in REQUEST_RATES:\n",
    "    print(f\"Running at {request_rate} requests/sec.\")\n",
    "    times = run_benchmark(call_model, request_rate, RUNNING_TIME_SEC)\n",
    "    times.insert(0, \"request_rate\", request_rate)\n",
    "    to_concat.append(times)\n",
    "\n",
    "results = pd.concat(to_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e96396d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request_rate</th>\n",
       "      <th>request_id</th>\n",
       "      <th>model_num</th>\n",
       "      <th>desired_start</th>\n",
       "      <th>actual_start</th>\n",
       "      <th>end</th>\n",
       "      <th>latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>0.568458</td>\n",
       "      <td>0.566492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.111595</td>\n",
       "      <td>1.678182</td>\n",
       "      <td>1.566586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.154438</td>\n",
       "      <td>0.702630</td>\n",
       "      <td>0.548191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.231591</td>\n",
       "      <td>0.810946</td>\n",
       "      <td>0.579355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.308548</td>\n",
       "      <td>2.305786</td>\n",
       "      <td>1.997238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>10</td>\n",
       "      <td>580</td>\n",
       "      <td>0</td>\n",
       "      <td>59.375000</td>\n",
       "      <td>59.378269</td>\n",
       "      <td>201.091771</td>\n",
       "      <td>141.713502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>10</td>\n",
       "      <td>581</td>\n",
       "      <td>0</td>\n",
       "      <td>59.500000</td>\n",
       "      <td>59.504591</td>\n",
       "      <td>203.569588</td>\n",
       "      <td>144.064997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>10</td>\n",
       "      <td>582</td>\n",
       "      <td>0</td>\n",
       "      <td>59.625000</td>\n",
       "      <td>59.628264</td>\n",
       "      <td>207.490647</td>\n",
       "      <td>147.862383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>10</td>\n",
       "      <td>583</td>\n",
       "      <td>0</td>\n",
       "      <td>59.750000</td>\n",
       "      <td>59.753405</td>\n",
       "      <td>222.888129</td>\n",
       "      <td>163.134724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>10</td>\n",
       "      <td>584</td>\n",
       "      <td>0</td>\n",
       "      <td>59.875000</td>\n",
       "      <td>59.884267</td>\n",
       "      <td>228.917674</td>\n",
       "      <td>169.033407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>585 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     request_rate  request_id  model_num  desired_start  actual_start  \\\n",
       "0              10           0          1       0.000000      0.001966   \n",
       "1              10           1          1       0.076923      0.111595   \n",
       "2              10           2          0       0.153846      0.154438   \n",
       "3              10           3          2       0.230769      0.231591   \n",
       "4              10           4          0       0.307692      0.308548   \n",
       "..            ...         ...        ...            ...           ...   \n",
       "580            10         580          0      59.375000     59.378269   \n",
       "581            10         581          0      59.500000     59.504591   \n",
       "582            10         582          0      59.625000     59.628264   \n",
       "583            10         583          0      59.750000     59.753405   \n",
       "584            10         584          0      59.875000     59.884267   \n",
       "\n",
       "            end     latency  \n",
       "0      0.568458    0.566492  \n",
       "1      1.678182    1.566586  \n",
       "2      0.702630    0.548191  \n",
       "3      0.810946    0.579355  \n",
       "4      2.305786    1.997238  \n",
       "..          ...         ...  \n",
       "580  201.091771  141.713502  \n",
       "581  203.569588  144.064997  \n",
       "582  207.490647  147.862383  \n",
       "583  222.888129  163.134724  \n",
       "584  228.917674  169.033407  \n",
       "\n",
       "[585 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[results[\"request_rate\"] == 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41097a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">latency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request_rate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.943503</td>\n",
       "      <td>0.722774</td>\n",
       "      <td>2.496944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.090333</td>\n",
       "      <td>9.696497</td>\n",
       "      <td>28.089105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.219100</td>\n",
       "      <td>34.700127</td>\n",
       "      <td>62.580132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.530135</td>\n",
       "      <td>37.311874</td>\n",
       "      <td>68.970814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>38.946640</td>\n",
       "      <td>36.225717</td>\n",
       "      <td>100.096296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>70.287506</td>\n",
       "      <td>63.009967</td>\n",
       "      <td>179.713536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>89.931625</td>\n",
       "      <td>75.302254</td>\n",
       "      <td>231.171960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>187.808023</td>\n",
       "      <td>110.576004</td>\n",
       "      <td>495.661652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>357.260642</td>\n",
       "      <td>207.327656</td>\n",
       "      <td>901.306118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 latency                        \n",
       "                    mean      median         max\n",
       "request_rate                                    \n",
       "2               0.943503    0.722774    2.496944\n",
       "3              11.090333    9.696497   28.089105\n",
       "4              28.219100   34.700127   62.580132\n",
       "5              30.530135   37.311874   68.970814\n",
       "6              38.946640   36.225717  100.096296\n",
       "8              70.287506   63.009967  179.713536\n",
       "10             89.931625   75.302254  231.171960\n",
       "12            187.808023  110.576004  495.661652\n",
       "14            357.260642  207.327656  901.306118"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_results = results.groupby(\"request_rate\").aggregate({\"latency\": [\"mean\", \"median\", \"max\"]})\n",
    "agg_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9496843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Average Latency (sec)')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(agg_results.index, agg_results[\"latency\", \"mean\"])\n",
    "plt.xlabel(\"Average Requests per Second\")\n",
    "plt.ylabel(\"Average Latency (sec)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d457420",
   "metadata": {},
   "source": [
    "## Using zero-copy model loading\n",
    "\n",
    "Now let's redo this baseline using zero-copy model loading.\n",
    "First we'll need to convert the model into a format that can be loaded without copying\n",
    "data. The model is actually a pipeline of multiple operations, but the RoBERTa model\n",
    "at its center is orders of magnitude larger and more CPU-intensive than everything else, so we'll only apply zero-copy loading to that part.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7add2053",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=9370)\u001b[0m 2021-10-21 16:39:07,777\tINFO backend_state.py:914 -- Removing 1 replicas from deployment 'qa0'. component=serve deployment=qa0\n",
      "\u001b[2m\u001b[36m(pid=9370)\u001b[0m 2021-10-21 16:39:07,781\tINFO backend_state.py:914 -- Removing 1 replicas from deployment 'qa1'. component=serve deployment=qa1\n",
      "\u001b[2m\u001b[36m(pid=9370)\u001b[0m 2021-10-21 16:39:07,785\tINFO backend_state.py:914 -- Removing 1 replicas from deployment 'qa2'. component=serve deployment=qa2\n",
      "\u001b[2m\u001b[36m(pid=9370)\u001b[0m 2021-10-21 16:39:07,790\tINFO backend_state.py:914 -- Removing 1 replicas from deployment 'qa3'. component=serve deployment=qa3\n",
      "\u001b[2m\u001b[36m(pid=9370)\u001b[0m 2021-10-21 16:39:07,795\tINFO backend_state.py:914 -- Removing 1 replicas from deployment 'qa4'. component=serve deployment=qa4\n",
      "\u001b[2m\u001b[36m(pid=9370)\u001b[0m 2021-10-21 16:39:07,800\tINFO backend_state.py:914 -- Removing 1 replicas from deployment 'qa5'. component=serve deployment=qa5\n",
      "\u001b[2m\u001b[36m(pid=9370)\u001b[0m 2021-10-21 16:39:07,806\tINFO backend_state.py:914 -- Removing 1 replicas from deployment 'qa6'. component=serve deployment=qa6\n",
      "\u001b[2m\u001b[36m(pid=9370)\u001b[0m 2021-10-21 16:39:07,811\tINFO backend_state.py:914 -- Removing 1 replicas from deployment 'qa7'. component=serve deployment=qa7\n",
      "\u001b[2m\u001b[36m(pid=9370)\u001b[0m 2021-10-21 16:39:07,820\tINFO backend_state.py:914 -- Removing 1 replicas from deployment 'qa8'. component=serve deployment=qa8\n",
      "\u001b[2m\u001b[36m(pid=9370)\u001b[0m 2021-10-21 16:39:07,827\tINFO backend_state.py:914 -- Removing 1 replicas from deployment 'qa9'. component=serve deployment=qa9\n",
      "\u001b[2m\u001b[36m(pid=9370)\u001b[0m 2021-10-21 16:39:07,835\tINFO backend_state.py:914 -- Removing 1 replicas from deployment 'qa10'. component=serve deployment=qa10\n",
      "\u001b[2m\u001b[36m(pid=9370)\u001b[0m 2021-10-21 16:39:07,841\tINFO backend_state.py:914 -- Removing 1 replicas from deployment 'qa11'. component=serve deployment=qa11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14113)\u001b[0m 2021-10-21 16:39:11,181\tINFO checkpoint_path.py:15 -- Using RayInternalKVStore for controller checkpoint and recovery.\n",
      "\u001b[2m\u001b[36m(pid=14113)\u001b[0m 2021-10-21 16:39:11,185\tINFO http_state.py:75 -- Starting HTTP proxy with name 'SERVE_CONTROLLER_ACTOR:CHSnKA:SERVE_PROXY_ACTOR-node:10.168.112.18-0' on node 'node:10.168.112.18-0' listening on '127.0.0.1:8000'\n",
      "2021-10-21 16:39:11,491\tINFO api.py:455 -- Started Serve instance in namespace '3fb5b49f-c594-45d3-b20a-529a23087ae2'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ray.serve.api.Client at 0x7f1824e157c0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serve.shutdown()\n",
    "reboot_ray()\n",
    "serve.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6565396",
   "metadata": {},
   "source": [
    "## Introducing `zerocopy`\n",
    "\n",
    "We've created a Python package, `zerocopy`, with the model rewrite code from our previous post (TODO: Publish the package to PyPI).\n",
    "\n",
    "To use that package, you'll need to install it with `pip`, then import it into your script.\n",
    "\n",
    "```python\n",
    "import zerocopy\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33ab4adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=14111)\u001b[0m INFO:     Started server process [14111]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Move this code to the `zerocopy` library.\n",
    "@ray.remote\n",
    "def call_model_zero_copy(model_ref: ray.ObjectRef, args, kwargs) -> Any:\n",
    "    \"\"\"\n",
    "    Ray task that uses zero-copy model loading to reconstitute a model\n",
    "    from Plasma, then invokes the model's ``__call__()`` method.\n",
    "\n",
    "    :param model_ref: Object reference to a tuple of model skeleton\n",
    "     and model weights, as returned by :func:`extract_tensors`\n",
    "    :param args: Ordered arguments to pass to the model's :func:`__call__`\n",
    "     method\n",
    "    :param kwargs: Keyword arguments to pass to the model's :func:`__call__`\n",
    "     method\n",
    "\n",
    "    :returns: Return value from the model's :func:`__call__` method\n",
    "    \"\"\"\n",
    "    # Suppress PyTorch warnings about immutable tensors\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    model_skeleton, model_weights = model_ref\n",
    "    zerocopy.replace_tensors(model_skeleton, model_weights)\n",
    "    with torch.no_grad():\n",
    "        return model_skeleton(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e7941cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[ 3.7534, -8.7741, -9.1023, -6.6326, -8.7627, -8.6893, -9.7706, -9.6873,\n",
       "         -9.6512, -4.1902, -7.6596, -8.5491, -7.9478, -7.5671, -9.0784, -8.2897,\n",
       "         -7.5410, -5.9760, -7.2943, -6.4249, -9.3297, -8.9922, -7.9955, -8.9485,\n",
       "         -8.7506, -6.1065, -8.2273, -8.4471, -8.9334, -2.9227, -2.8201, -4.6316,\n",
       "         -5.5576, -5.7634, -5.8722, -5.9716, -6.2091, -6.0458, -5.3727, -9.8484,\n",
       "         -8.4069, -7.6116, -5.1946, -8.7245, -4.3298, -8.3712, -8.5934, -4.6927,\n",
       "         -8.6297, -5.4113, -8.5218, -6.5587, -6.0347, -9.0888, -3.9168, -3.7715,\n",
       "         -4.0178, -5.5528, -6.2156, -6.1800, -6.1387, -6.2229, -6.4473, -6.3201,\n",
       "         -6.2259, -8.2617, -8.0752, -8.5442, -7.0337, -5.3173, -7.1967, -8.6134,\n",
       "         -5.5957, -9.0524, -8.1817, -7.5553, -7.3491, -8.5218, -7.5425, -7.8877,\n",
       "         -8.3360, -8.1147, -5.0947, -5.1871, -6.5926, -6.7610, -6.7855, -6.8672,\n",
       "         -6.9245, -6.7498, -7.7118, -8.6336, -8.0724, -7.3320, -7.0676, -8.8112,\n",
       "         -4.9942, -5.8767, -9.1029, -7.2982, -6.3021, -9.7423, -7.1145, -7.1081,\n",
       "         -6.9473, -8.5740, -3.0519, -6.5595, -8.5219, -4.1875, -3.3123, -4.7947,\n",
       "         -6.0620, -6.2542, -6.3127, -6.3890, -6.4033, -5.8774, -8.3484, -8.4814,\n",
       "         -9.0725, -8.4167, -9.2634, -8.2589, -7.3816, -8.6027, -5.9291, -2.9634,\n",
       "         -7.5559, -5.7752, -5.7358, -2.7408, -9.7852, -8.8763, -8.4199, -9.4240,\n",
       "         -9.2364, -6.2053, -3.3876, -7.0878, -5.4361, -4.9418, -4.3873, -6.6898,\n",
       "         -6.8614, -6.9100, -6.7906, -6.6952, -6.9213, -7.2896, -7.4180, -5.0012,\n",
       "         -7.7606, -4.3374, -9.5112, -3.4501, -3.6575, -5.4360, -5.9422, -6.0169,\n",
       "         -6.0962, -6.1794, -6.1066, -5.3584, -9.5739]],\n",
       "       grad_fn=<CloneBackward0>), end_logits=tensor([[ 4.4085, -9.0466, -8.8865, -8.7139, -8.4380, -6.1985, -8.0720, -8.6342,\n",
       "         -8.5613, -8.2167, -3.1857, -8.5013, -9.1181, -9.5205, -8.6247, -9.3529,\n",
       "         -9.5464, -7.6825, -6.5827, -5.3342, -7.0454, -8.8780, -9.4053, -8.9716,\n",
       "         -9.1811, -5.5211, -8.8220, -7.2581, -8.8071, -3.8688, -2.2351, -4.3839,\n",
       "         -4.6088, -4.6001, -4.5076, -4.4578, -4.5339, -4.5748, -3.9645, -7.4804,\n",
       "         -9.4569, -9.2952, -5.0298, -9.1183, -8.2703, -6.1834, -8.8689, -4.8877,\n",
       "         -9.0013, -3.7470, -5.0784, -9.5459, -7.1008, -8.6576, -4.8155, -4.2922,\n",
       "         -2.7303, -4.5583, -4.8196, -4.7327, -4.6521, -4.6179, -4.7436, -4.8457,\n",
       "         -8.8704, -5.5503, -9.1086, -9.2351, -9.6451, -7.8936, -5.3242, -8.5684,\n",
       "         -5.8515, -8.7893, -9.1167, -6.6691, -4.8255, -5.0784, -9.5671, -8.4143,\n",
       "         -9.0938, -8.9134, -4.9596, -5.5421, -5.9617, -5.8092, -5.7694, -5.6697,\n",
       "         -5.1522, -4.9800, -7.5636, -6.4838, -9.3509, -9.7418, -8.4976, -9.0644,\n",
       "         -7.2498, -4.1803, -8.6530, -8.6244, -4.0320, -7.6777, -9.3713, -9.6320,\n",
       "         -8.6084, -8.9086, -4.2255, -2.6947, -5.0785, -4.4284, -2.9733, -5.2723,\n",
       "         -5.7548, -5.7846, -5.6469, -5.3465, -4.7512, -4.2537, -9.1724, -8.5388,\n",
       "         -9.1766, -9.1957, -8.9629, -9.5458, -9.0349, -7.9539, -9.7081, -5.0877,\n",
       "         -7.9361, -6.1761, -8.4385, -1.4253, -4.2468, -8.7981, -9.2489, -8.5449,\n",
       "         -9.0143, -9.6156, -5.2834, -7.8561, -4.6573, -4.8583, -3.0356, -5.0068,\n",
       "         -5.2084, -5.2549, -5.0224, -4.8224, -4.8028, -5.2435, -9.3175, -8.6061,\n",
       "         -8.7362, -2.4815, -5.2484, -3.2335, -4.3040, -5.2170, -5.4810, -5.4640,\n",
       "         -5.3760, -5.0714, -4.5941, -3.6325, -8.8697]],\n",
       "       grad_fn=<CloneBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the model directly\n",
    "inputs = qa.tokenizer(qa_input[\"question\"], qa_input[\"context\"], return_tensors=\"pt\")\n",
    "qa.model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6157e447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[ 3.7534, -8.7741, -9.1023, -6.6326, -8.7627, -8.6893, -9.7706, -9.6873,\n",
       "         -9.6512, -4.1902, -7.6596, -8.5491, -7.9478, -7.5671, -9.0784, -8.2897,\n",
       "         -7.5410, -5.9760, -7.2943, -6.4249, -9.3297, -8.9922, -7.9955, -8.9485,\n",
       "         -8.7506, -6.1065, -8.2273, -8.4471, -8.9334, -2.9227, -2.8201, -4.6316,\n",
       "         -5.5576, -5.7634, -5.8722, -5.9716, -6.2091, -6.0458, -5.3727, -9.8484,\n",
       "         -8.4069, -7.6116, -5.1946, -8.7245, -4.3298, -8.3712, -8.5934, -4.6927,\n",
       "         -8.6297, -5.4113, -8.5218, -6.5587, -6.0347, -9.0888, -3.9168, -3.7715,\n",
       "         -4.0178, -5.5528, -6.2156, -6.1800, -6.1387, -6.2229, -6.4473, -6.3201,\n",
       "         -6.2259, -8.2617, -8.0752, -8.5442, -7.0337, -5.3173, -7.1967, -8.6134,\n",
       "         -5.5957, -9.0524, -8.1817, -7.5553, -7.3491, -8.5218, -7.5425, -7.8877,\n",
       "         -8.3360, -8.1147, -5.0947, -5.1871, -6.5926, -6.7610, -6.7855, -6.8672,\n",
       "         -6.9245, -6.7498, -7.7118, -8.6336, -8.0724, -7.3320, -7.0676, -8.8112,\n",
       "         -4.9942, -5.8767, -9.1029, -7.2982, -6.3021, -9.7423, -7.1145, -7.1081,\n",
       "         -6.9473, -8.5740, -3.0519, -6.5595, -8.5219, -4.1875, -3.3123, -4.7947,\n",
       "         -6.0620, -6.2542, -6.3127, -6.3890, -6.4033, -5.8774, -8.3484, -8.4814,\n",
       "         -9.0725, -8.4167, -9.2634, -8.2589, -7.3816, -8.6027, -5.9291, -2.9634,\n",
       "         -7.5559, -5.7752, -5.7358, -2.7408, -9.7852, -8.8763, -8.4199, -9.4240,\n",
       "         -9.2364, -6.2053, -3.3876, -7.0878, -5.4361, -4.9418, -4.3873, -6.6898,\n",
       "         -6.8614, -6.9100, -6.7906, -6.6952, -6.9213, -7.2896, -7.4180, -5.0012,\n",
       "         -7.7606, -4.3374, -9.5112, -3.4501, -3.6575, -5.4360, -5.9422, -6.0169,\n",
       "         -6.0962, -6.1794, -6.1066, -5.3584, -9.5739]]), end_logits=tensor([[ 4.4085, -9.0466, -8.8865, -8.7139, -8.4380, -6.1985, -8.0720, -8.6342,\n",
       "         -8.5613, -8.2167, -3.1857, -8.5013, -9.1181, -9.5205, -8.6247, -9.3529,\n",
       "         -9.5464, -7.6825, -6.5827, -5.3342, -7.0454, -8.8780, -9.4053, -8.9716,\n",
       "         -9.1811, -5.5211, -8.8220, -7.2581, -8.8071, -3.8688, -2.2351, -4.3839,\n",
       "         -4.6088, -4.6001, -4.5076, -4.4578, -4.5339, -4.5748, -3.9645, -7.4804,\n",
       "         -9.4569, -9.2952, -5.0298, -9.1183, -8.2703, -6.1834, -8.8689, -4.8877,\n",
       "         -9.0013, -3.7470, -5.0784, -9.5459, -7.1008, -8.6576, -4.8155, -4.2922,\n",
       "         -2.7303, -4.5583, -4.8196, -4.7327, -4.6521, -4.6179, -4.7436, -4.8457,\n",
       "         -8.8704, -5.5503, -9.1086, -9.2351, -9.6451, -7.8936, -5.3242, -8.5684,\n",
       "         -5.8515, -8.7893, -9.1167, -6.6691, -4.8255, -5.0784, -9.5671, -8.4143,\n",
       "         -9.0938, -8.9134, -4.9596, -5.5421, -5.9617, -5.8092, -5.7694, -5.6697,\n",
       "         -5.1522, -4.9800, -7.5636, -6.4838, -9.3509, -9.7418, -8.4976, -9.0644,\n",
       "         -7.2498, -4.1803, -8.6530, -8.6244, -4.0320, -7.6777, -9.3713, -9.6320,\n",
       "         -8.6084, -8.9086, -4.2255, -2.6947, -5.0785, -4.4284, -2.9733, -5.2723,\n",
       "         -5.7548, -5.7846, -5.6469, -5.3465, -4.7512, -4.2537, -9.1724, -8.5388,\n",
       "         -9.1766, -9.1957, -8.9629, -9.5458, -9.0349, -7.9539, -9.7081, -5.0877,\n",
       "         -7.9361, -6.1761, -8.4385, -1.4253, -4.2468, -8.7981, -9.2489, -8.5449,\n",
       "         -9.0143, -9.6156, -5.2834, -7.8561, -4.6573, -4.8583, -3.0356, -5.0068,\n",
       "         -5.2084, -5.2549, -5.0224, -4.8224, -4.8028, -5.2435, -9.3175, -8.6061,\n",
       "         -8.7362, -2.4815, -5.2484, -3.2335, -4.3040, -5.2170, -5.4810, -5.4640,\n",
       "         -5.3760, -5.0714, -4.5941, -3.6325, -8.8697]]), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the model via `call_model`. Results should be the same as the previous cell.\n",
    "model_ref = ray.put(zerocopy.extract_tensors(qa.model))\n",
    "ray.get(call_model_zero_copy.remote(model_ref, [], inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ae691c",
   "metadata": {},
   "source": [
    "The time to invoke the model once via `call_model_zero_copy()` is almost the same as running the model locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca2416e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Time to run locally: 508 ms ± 3.22 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Time to run with zero-copy: 586 ms ± 17.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Compare timings\n",
    "print(\"       Time to run locally: \", end=\"\")\n",
    "%timeit qa.model(**inputs)\n",
    "print(\"Time to run with zero-copy: \", end=\"\")\n",
    "%timeit ray.get(call_model_zero_copy.remote(model_ref, [], inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ccc91c",
   "metadata": {},
   "source": [
    "If we run inference multiple times, `call_model_zero_copy()` can send those inference requests to separate Ray tasks that run in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2b7b275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Time to run 100 times locally: 50.6 s ± 126 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n",
      "Time to run 100 times with zero-copy: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15060)\u001b[0m [2021-10-21 16:42:52,374 C 15060 15125] core_worker.cc:210:  Check failed: core_worker_process The core worker process is not initialized yet or already shutdown.\n",
      "\u001b[2m\u001b[36m(pid=15060)\u001b[0m *** StackTrace Information ***\n",
      "\u001b[2m\u001b[36m(pid=15060)\u001b[0m     ray::SpdLogMessage::Flush()\n",
      "\u001b[2m\u001b[36m(pid=15060)\u001b[0m     ray::RayLog::~RayLog()\n",
      "\u001b[2m\u001b[36m(pid=15060)\u001b[0m     ray::core::CoreWorkerProcess::EnsureInitialized()\n",
      "\u001b[2m\u001b[36m(pid=15060)\u001b[0m     ray::core::CoreWorkerProcess::GetCoreWorker()\n",
      "\u001b[2m\u001b[36m(pid=15060)\u001b[0m     __pyx_pw_3ray_7_raylet_10CoreWorker_23get_worker_id()\n",
      "\u001b[2m\u001b[36m(pid=15060)\u001b[0m     method_vectorcall_NOARGS\n",
      "\u001b[2m\u001b[36m(pid=15060)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15059)\u001b[0m [2021-10-21 16:42:52,421 C 15059 15119] core_worker.cc:210:  Check failed: core_worker_process The core worker process is not initialized yet or already shutdown.\n",
      "\u001b[2m\u001b[36m(pid=15059)\u001b[0m *** StackTrace Information ***\n",
      "\u001b[2m\u001b[36m(pid=15059)\u001b[0m     ray::SpdLogMessage::Flush()\n",
      "\u001b[2m\u001b[36m(pid=15059)\u001b[0m     ray::RayLog::~RayLog()\n",
      "\u001b[2m\u001b[36m(pid=15059)\u001b[0m     ray::core::CoreWorkerProcess::EnsureInitialized()\n",
      "\u001b[2m\u001b[36m(pid=15059)\u001b[0m     ray::core::CoreWorkerProcess::GetCoreWorker()\n",
      "\u001b[2m\u001b[36m(pid=15059)\u001b[0m     __pyx_pw_3ray_7_raylet_10CoreWorker_23get_worker_id()\n",
      "\u001b[2m\u001b[36m(pid=15059)\u001b[0m     method_vectorcall_NOARGS\n",
      "\u001b[2m\u001b[36m(pid=15059)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.39 s ± 53.2 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def run_local(num_repeats: int):\n",
    "    for _ in range(num_repeats):\n",
    "        qa.model(**inputs)\n",
    "\n",
    "\n",
    "def run_zero_copy(num_repeats: int):\n",
    "    futures = [call_model_zero_copy.remote(model_ref, [], inputs) for _ in range(num_repeats)]\n",
    "    ray.get(futures)\n",
    "\n",
    "\n",
    "NUM_REPEATS = 100\n",
    "print(f\"       Time to run {NUM_REPEATS} times locally: \", end=\"\")\n",
    "%timeit -r 3 run_local(NUM_REPEATS)\n",
    "print(f\"Time to run {NUM_REPEATS} times with zero-copy: \", end=\"\")\n",
    "%timeit -r 3 run_zero_copy(NUM_REPEATS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b43922b",
   "metadata": {},
   "source": [
    "Now let's define a Ray Serve endpoint that runs the model preprocessing code locally and farms out model inference \n",
    "to Ray tasks that use zero-copy model loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47b57958",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-21 16:43:20,435\tINFO api.py:243 -- Updating deployment 'qa0'. component=serve deployment=qa0\n",
      "2021-10-21 16:43:20,456\tINFO api.py:243 -- Updating deployment 'qa1'. component=serve deployment=qa1\n",
      "2021-10-21 16:43:20,481\tINFO api.py:243 -- Updating deployment 'qa2'. component=serve deployment=qa2\n",
      "2021-10-21 16:43:20,508\tINFO api.py:243 -- Updating deployment 'qa3'. component=serve deployment=qa3\n",
      "\u001b[2m\u001b[36m(pid=14113)\u001b[0m 2021-10-21 16:43:20,510\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa0'. component=serve deployment=qa0\n",
      "\u001b[2m\u001b[36m(pid=14113)\u001b[0m 2021-10-21 16:43:20,523\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa1'. component=serve deployment=qa1\n",
      "\u001b[2m\u001b[36m(pid=14113)\u001b[0m 2021-10-21 16:43:20,537\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa2'. component=serve deployment=qa2\n",
      "\u001b[2m\u001b[36m(pid=14113)\u001b[0m 2021-10-21 16:43:20,550\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa3'. component=serve deployment=qa3\n",
      "2021-10-21 16:43:20,585\tINFO api.py:243 -- Updating deployment 'qa4'. component=serve deployment=qa4\n",
      "2021-10-21 16:43:20,618\tINFO api.py:243 -- Updating deployment 'qa5'. component=serve deployment=qa5\n",
      "2021-10-21 16:43:20,699\tINFO api.py:243 -- Updating deployment 'qa6'. component=serve deployment=qa6\n",
      "\u001b[2m\u001b[36m(pid=14113)\u001b[0m 2021-10-21 16:43:20,712\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa4'. component=serve deployment=qa4\n",
      "\u001b[2m\u001b[36m(pid=14113)\u001b[0m 2021-10-21 16:43:20,724\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa5'. component=serve deployment=qa5\n",
      "\u001b[2m\u001b[36m(pid=14113)\u001b[0m 2021-10-21 16:43:20,762\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa6'. component=serve deployment=qa6\n",
      "2021-10-21 16:43:20,816\tINFO api.py:243 -- Updating deployment 'qa7'. component=serve deployment=qa7\n",
      "2021-10-21 16:43:20,868\tINFO api.py:243 -- Updating deployment 'qa8'. component=serve deployment=qa8\n",
      "2021-10-21 16:43:20,984\tINFO api.py:243 -- Updating deployment 'qa9'. component=serve deployment=qa9\n",
      "\u001b[2m\u001b[36m(pid=14113)\u001b[0m 2021-10-21 16:43:20,938\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa7'. component=serve deployment=qa7\n",
      "\u001b[2m\u001b[36m(pid=14113)\u001b[0m 2021-10-21 16:43:20,951\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa8'. component=serve deployment=qa8\n",
      "\u001b[2m\u001b[36m(pid=14113)\u001b[0m 2021-10-21 16:43:20,967\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa9'. component=serve deployment=qa9\n",
      "2021-10-21 16:43:21,038\tINFO api.py:243 -- Updating deployment 'qa10'. component=serve deployment=qa10\n",
      "2021-10-21 16:43:21,098\tINFO api.py:243 -- Updating deployment 'qa11'. component=serve deployment=qa11\n",
      "\u001b[2m\u001b[36m(pid=14113)\u001b[0m 2021-10-21 16:43:21,104\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa10'. component=serve deployment=qa10\n",
      "\u001b[2m\u001b[36m(pid=14113)\u001b[0m 2021-10-21 16:43:21,119\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa11'. component=serve deployment=qa11\n"
     ]
    }
   ],
   "source": [
    "class ZeroCopyQAModel:\n",
    "    def __init__(self):\n",
    "        # TODO: Move this rewrite to the `zerocopy` library.\n",
    "        # Load the entire pipeline, then copy the model portion to Plasma.\n",
    "        self._qa = transformers.pipeline(\"question-answering\", model=model_name)\n",
    "        model_ref = ray.put(zerocopy.extract_tensors(self._qa.model))\n",
    "\n",
    "        # Replace the pipeline's model with a callback that farms out work to\n",
    "        # Ray tasks.\n",
    "        class _ModelCallback:\n",
    "            def __call__(self, *args, **kwargs):\n",
    "                return ray.get(call_model_zero_copy.remote(model_ref, args, kwargs))\n",
    "        self._qa.model = _ModelCallback()\n",
    "\n",
    "        # Use a threadpool because the model is called from pre/postprocessing code\n",
    "        # that is not asyncio-aware\n",
    "        self._threadpool = concurrent.futures.ThreadPoolExecutor()\n",
    "\n",
    "    async def __call__(self, request: starlette.requests.Request):\n",
    "        # Pull model inputs from URL query parameters.\n",
    "        # A production version of this code would sanitize these strings.\n",
    "        model_input = {\n",
    "            \"question\": request.query_params[\"question\"],\n",
    "            \"context\": request.query_params[\"context\"]\n",
    "        }\n",
    "        result = await asyncio.get_running_loop().run_in_executor(\n",
    "            self._threadpool, lambda: self._qa(model_input))\n",
    "        return result\n",
    "\n",
    "    def __del__(self):  # Ray Serve needs this callback\n",
    "        pass\n",
    "\n",
    "\n",
    "# Define endpoints\n",
    "NUM_QA_MODELS = 12\n",
    "deployments = [\n",
    "    serve.deployment(ZeroCopyQAModel, f\"qa{model_num}\",\n",
    "                     ray_actor_options={\"num_cpus\": 0.1})\n",
    "    for model_num in range(NUM_QA_MODELS)\n",
    "]\n",
    "\n",
    "for d in deployments:\n",
    "    d.deploy(_blocking=False)\n",
    "\n",
    "# Wait a moment so log output doesn't go to the next cell's output\n",
    "time.sleep(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ade7fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 4.278897904441692e-06, 'start': 483, 'end': 484, 'answer': '5'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try out the new deployment.\n",
    "# This web service call blocks until the asychronous deployment has completed.\n",
    "params = urllib.parse.urlencode(qa_input)\n",
    "requests.get(f\"http://127.0.0.1:8000/qa0?{params}\").json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c04338",
   "metadata": {},
   "source": [
    "We've deployed these models to the same URLs, so the benchmark code from before should work without\n",
    "any changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e922d3ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request_id</th>\n",
       "      <th>model_num</th>\n",
       "      <th>desired_start</th>\n",
       "      <th>actual_start</th>\n",
       "      <th>end</th>\n",
       "      <th>latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002127</td>\n",
       "      <td>8.810216</td>\n",
       "      <td>8.808089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125644</td>\n",
       "      <td>5.568401</td>\n",
       "      <td>5.442757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250727</td>\n",
       "      <td>0.883433</td>\n",
       "      <td>0.632706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375813</td>\n",
       "      <td>1.060598</td>\n",
       "      <td>0.684785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500820</td>\n",
       "      <td>3.530440</td>\n",
       "      <td>3.029620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625932</td>\n",
       "      <td>1.752965</td>\n",
       "      <td>1.127034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750948</td>\n",
       "      <td>1.684968</td>\n",
       "      <td>0.934019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875745</td>\n",
       "      <td>5.625919</td>\n",
       "      <td>4.750174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000563</td>\n",
       "      <td>6.665009</td>\n",
       "      <td>5.664446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>1.143384</td>\n",
       "      <td>4.986574</td>\n",
       "      <td>3.843189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>1.286681</td>\n",
       "      <td>2.635607</td>\n",
       "      <td>1.348926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>1.429374</td>\n",
       "      <td>2.413720</td>\n",
       "      <td>0.984346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>1.572204</td>\n",
       "      <td>6.664782</td>\n",
       "      <td>5.092578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>1.714898</td>\n",
       "      <td>10.016176</td>\n",
       "      <td>8.301279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>1.857826</td>\n",
       "      <td>5.526038</td>\n",
       "      <td>3.668213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000810</td>\n",
       "      <td>6.421016</td>\n",
       "      <td>4.420206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>2.143770</td>\n",
       "      <td>3.811646</td>\n",
       "      <td>1.667875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>2.286733</td>\n",
       "      <td>3.691473</td>\n",
       "      <td>1.404739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>2.429216</td>\n",
       "      <td>7.274391</td>\n",
       "      <td>4.845175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>2.589417</td>\n",
       "      <td>6.823339</td>\n",
       "      <td>4.233922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>2.716499</td>\n",
       "      <td>7.731170</td>\n",
       "      <td>5.014671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>2.858207</td>\n",
       "      <td>4.615724</td>\n",
       "      <td>1.757517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.023470</td>\n",
       "      <td>8.680306</td>\n",
       "      <td>5.656836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.518737</td>\n",
       "      <td>7.939113</td>\n",
       "      <td>4.420377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000997</td>\n",
       "      <td>8.562115</td>\n",
       "      <td>4.561118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.168122</td>\n",
       "      <td>8.480814</td>\n",
       "      <td>4.312692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.334307</td>\n",
       "      <td>6.604528</td>\n",
       "      <td>2.270221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.501085</td>\n",
       "      <td>6.522038</td>\n",
       "      <td>2.020954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.667616</td>\n",
       "      <td>6.412309</td>\n",
       "      <td>1.744693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>4.842389</td>\n",
       "      <td>7.382991</td>\n",
       "      <td>2.540601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000804</td>\n",
       "      <td>7.769338</td>\n",
       "      <td>2.768534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>5.336984</td>\n",
       "      <td>7.268365</td>\n",
       "      <td>1.931381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>5.667656</td>\n",
       "      <td>8.159489</td>\n",
       "      <td>2.491833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000898</td>\n",
       "      <td>7.329239</td>\n",
       "      <td>1.328341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>6.125857</td>\n",
       "      <td>7.467838</td>\n",
       "      <td>1.341980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>6.251094</td>\n",
       "      <td>7.733754</td>\n",
       "      <td>1.482660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>6.375000</td>\n",
       "      <td>6.375952</td>\n",
       "      <td>8.226023</td>\n",
       "      <td>1.850070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>6.500981</td>\n",
       "      <td>8.385189</td>\n",
       "      <td>1.884207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>6.625000</td>\n",
       "      <td>6.626028</td>\n",
       "      <td>8.379320</td>\n",
       "      <td>1.753292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>6.751028</td>\n",
       "      <td>8.293038</td>\n",
       "      <td>1.542010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>6.875000</td>\n",
       "      <td>6.895382</td>\n",
       "      <td>8.784251</td>\n",
       "      <td>1.888869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000741</td>\n",
       "      <td>8.599088</td>\n",
       "      <td>1.598347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>7.334169</td>\n",
       "      <td>8.909353</td>\n",
       "      <td>1.575184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>7.674819</td>\n",
       "      <td>8.940068</td>\n",
       "      <td>1.265249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.001090</td>\n",
       "      <td>8.960201</td>\n",
       "      <td>0.959110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>8.142857</td>\n",
       "      <td>8.143768</td>\n",
       "      <td>9.143039</td>\n",
       "      <td>0.999271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>8.285714</td>\n",
       "      <td>8.335751</td>\n",
       "      <td>9.318199</td>\n",
       "      <td>0.982448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>8.428571</td>\n",
       "      <td>8.462869</td>\n",
       "      <td>9.288953</td>\n",
       "      <td>0.826084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>8.571429</td>\n",
       "      <td>8.572356</td>\n",
       "      <td>9.276237</td>\n",
       "      <td>0.703882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>8.714286</td>\n",
       "      <td>8.715183</td>\n",
       "      <td>9.447085</td>\n",
       "      <td>0.731902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>8.857143</td>\n",
       "      <td>8.857673</td>\n",
       "      <td>9.754819</td>\n",
       "      <td>0.897146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000728</td>\n",
       "      <td>9.676941</td>\n",
       "      <td>0.676213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>9.125000</td>\n",
       "      <td>9.125816</td>\n",
       "      <td>9.984389</td>\n",
       "      <td>0.858573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>9.250000</td>\n",
       "      <td>9.250784</td>\n",
       "      <td>10.090744</td>\n",
       "      <td>0.839960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>9.375000</td>\n",
       "      <td>9.375592</td>\n",
       "      <td>10.106704</td>\n",
       "      <td>0.731113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>9.500685</td>\n",
       "      <td>10.266972</td>\n",
       "      <td>0.766287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>9.625000</td>\n",
       "      <td>9.655735</td>\n",
       "      <td>10.384636</td>\n",
       "      <td>0.728900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>9.750000</td>\n",
       "      <td>9.750644</td>\n",
       "      <td>10.528229</td>\n",
       "      <td>0.777585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>9.875000</td>\n",
       "      <td>9.875675</td>\n",
       "      <td>10.543310</td>\n",
       "      <td>0.667635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    request_id  model_num  desired_start  actual_start        end   latency\n",
       "0            0          1       0.000000      0.002127   8.810216  8.808089\n",
       "1            1          1       0.125000      0.125644   5.568401  5.442757\n",
       "2            2          0       0.250000      0.250727   0.883433  0.632706\n",
       "3            3          2       0.375000      0.375813   1.060598  0.684785\n",
       "4            4          0       0.500000      0.500820   3.530440  3.029620\n",
       "5            5          0       0.625000      0.625932   1.752965  1.127034\n",
       "6            6          0       0.750000      0.750948   1.684968  0.934019\n",
       "7            7          1       0.875000      0.875745   5.625919  4.750174\n",
       "8            8          1       1.000000      1.000563   6.665009  5.664446\n",
       "9            9          0       1.142857      1.143384   4.986574  3.843189\n",
       "10          10          0       1.285714      1.286681   2.635607  1.348926\n",
       "11          11          0       1.428571      1.429374   2.413720  0.984346\n",
       "12          12          1       1.571429      1.572204   6.664782  5.092578\n",
       "13          13          1       1.714286      1.714898  10.016176  8.301279\n",
       "14          14          2       1.857143      1.857826   5.526038  3.668213\n",
       "15          15          0       2.000000      2.000810   6.421016  4.420206\n",
       "16          16          0       2.142857      2.143770   3.811646  1.667875\n",
       "17          17          0       2.285714      2.286733   3.691473  1.404739\n",
       "18          18          0       2.428571      2.429216   7.274391  4.845175\n",
       "19          19          0       2.571429      2.589417   6.823339  4.233922\n",
       "20          20          1       2.714286      2.716499   7.731170  5.014671\n",
       "21          21          0       2.857143      2.858207   4.615724  1.757517\n",
       "22          22          0       3.000000      3.023470   8.680306  5.656836\n",
       "23          23          0       3.500000      3.518737   7.939113  4.420377\n",
       "24          24          0       4.000000      4.000997   8.562115  4.561118\n",
       "25          25          0       4.166667      4.168122   8.480814  4.312692\n",
       "26          26          0       4.333333      4.334307   6.604528  2.270221\n",
       "27          27          0       4.500000      4.501085   6.522038  2.020954\n",
       "28          28          0       4.666667      4.667616   6.412309  1.744693\n",
       "29          29          0       4.833333      4.842389   7.382991  2.540601\n",
       "30          30          1       5.000000      5.000804   7.769338  2.768534\n",
       "31          31          0       5.333333      5.336984   7.268365  1.931381\n",
       "32          32          1       5.666667      5.667656   8.159489  2.491833\n",
       "33          33          0       6.000000      6.000898   7.329239  1.328341\n",
       "34          34          0       6.125000      6.125857   7.467838  1.341980\n",
       "35          35          0       6.250000      6.251094   7.733754  1.482660\n",
       "36          36          0       6.375000      6.375952   8.226023  1.850070\n",
       "37          37          0       6.500000      6.500981   8.385189  1.884207\n",
       "38          38          0       6.625000      6.626028   8.379320  1.753292\n",
       "39          39          1       6.750000      6.751028   8.293038  1.542010\n",
       "40          40          0       6.875000      6.895382   8.784251  1.888869\n",
       "41          41          1       7.000000      7.000741   8.599088  1.598347\n",
       "42          42          0       7.333333      7.334169   8.909353  1.575184\n",
       "43          43          0       7.666667      7.674819   8.940068  1.265249\n",
       "44          44          0       8.000000      8.001090   8.960201  0.959110\n",
       "45          45          0       8.142857      8.143768   9.143039  0.999271\n",
       "46          46          0       8.285714      8.335751   9.318199  0.982448\n",
       "47          47          0       8.428571      8.462869   9.288953  0.826084\n",
       "48          48          1       8.571429      8.572356   9.276237  0.703882\n",
       "49          49          0       8.714286      8.715183   9.447085  0.731902\n",
       "50          50          0       8.857143      8.857673   9.754819  0.897146\n",
       "51          51          0       9.000000      9.000728   9.676941  0.676213\n",
       "52          52          0       9.125000      9.125816   9.984389  0.858573\n",
       "53          53          0       9.250000      9.250784  10.090744  0.839960\n",
       "54          54          0       9.375000      9.375592  10.106704  0.731113\n",
       "55          55          0       9.500000      9.500685  10.266972  0.766287\n",
       "56          56          1       9.625000      9.655735  10.384636  0.728900\n",
       "57          57          0       9.750000      9.750644  10.528229  0.777585\n",
       "58          58          0       9.875000      9.875675  10.543310  0.667635"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick test run\n",
    "run_benchmark(call_model, 5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2254dd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running at 2 requests/sec.\n",
      "Running at 3 requests/sec.\n",
      "Running at 4 requests/sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=22500)\u001b[0m [2021-10-21 16:45:51,605 C 22500 22544] core_worker.cc:210:  Check failed: core_worker_process The core worker process is not initialized yet or already shutdown.\n",
      "\u001b[2m\u001b[36m(pid=22500)\u001b[0m *** StackTrace Information ***\n",
      "\u001b[2m\u001b[36m(pid=22500)\u001b[0m     ray::SpdLogMessage::Flush()\n",
      "\u001b[2m\u001b[36m(pid=22500)\u001b[0m     ray::RayLog::~RayLog()\n",
      "\u001b[2m\u001b[36m(pid=22500)\u001b[0m     ray::core::CoreWorkerProcess::EnsureInitialized()\n",
      "\u001b[2m\u001b[36m(pid=22500)\u001b[0m     ray::core::CoreWorkerProcess::GetCoreWorker()\n",
      "\u001b[2m\u001b[36m(pid=22500)\u001b[0m     __pyx_pw_3ray_7_raylet_10CoreWorker_23get_worker_id()\n",
      "\u001b[2m\u001b[36m(pid=22500)\u001b[0m     method_vectorcall_NOARGS\n",
      "\u001b[2m\u001b[36m(pid=22500)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(call_model_zero_copy pid=22998)\u001b[0m \n",
      "\u001b[2m\u001b[36m(call_model_zero_copy pid=23042)\u001b[0m \n",
      "Running at 5 requests/sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=23973)\u001b[0m [2021-10-21 16:47:06,690 C 23973 24020] core_worker.cc:210:  Check failed: core_worker_process The core worker process is not initialized yet or already shutdown.\n",
      "\u001b[2m\u001b[36m(pid=23973)\u001b[0m *** StackTrace Information ***\n",
      "\u001b[2m\u001b[36m(pid=23973)\u001b[0m     ray::SpdLogMessage::Flush()\n",
      "\u001b[2m\u001b[36m(pid=23973)\u001b[0m     ray::RayLog::~RayLog()\n",
      "\u001b[2m\u001b[36m(pid=23973)\u001b[0m     ray::core::CoreWorkerProcess::EnsureInitialized()\n",
      "\u001b[2m\u001b[36m(pid=23973)\u001b[0m     ray::core::CoreWorkerProcess::GetCoreWorker()\n",
      "\u001b[2m\u001b[36m(pid=23973)\u001b[0m     __pyx_pw_3ray_7_raylet_10CoreWorker_23get_worker_id()\n",
      "\u001b[2m\u001b[36m(pid=23973)\u001b[0m     method_vectorcall_NOARGS\n",
      "\u001b[2m\u001b[36m(pid=23973)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running at 6 requests/sec.\n",
      "\u001b[2m\u001b[36m(call_model_zero_copy pid=25994)\u001b[0m \n",
      "Running at 8 requests/sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26524)\u001b[0m [2021-10-21 16:49:04,310 C 26524 26668] core_worker.cc:210:  Check failed: core_worker_process The core worker process is not initialized yet or already shutdown.\n",
      "\u001b[2m\u001b[36m(pid=26524)\u001b[0m *** StackTrace Information ***\n",
      "\u001b[2m\u001b[36m(pid=26524)\u001b[0m     ray::SpdLogMessage::Flush()\n",
      "\u001b[2m\u001b[36m(pid=26524)\u001b[0m     ray::RayLog::~RayLog()\n",
      "\u001b[2m\u001b[36m(pid=26524)\u001b[0m     ray::core::CoreWorkerProcess::EnsureInitialized()\n",
      "\u001b[2m\u001b[36m(pid=26524)\u001b[0m     ray::core::CoreWorkerProcess::GetCoreWorker()\n",
      "\u001b[2m\u001b[36m(pid=26524)\u001b[0m     __pyx_pw_3ray_7_raylet_10CoreWorker_23get_worker_id()\n",
      "\u001b[2m\u001b[36m(pid=26524)\u001b[0m     method_vectorcall_NOARGS\n",
      "\u001b[2m\u001b[36m(pid=26524)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26526)\u001b[0m [2021-10-21 16:49:04,371 C 26526 26662] core_worker.cc:210:  Check failed: core_worker_process The core worker process is not initialized yet or already shutdown.\n",
      "\u001b[2m\u001b[36m(pid=26526)\u001b[0m *** StackTrace Information ***\n",
      "\u001b[2m\u001b[36m(pid=26526)\u001b[0m     ray::SpdLogMessage::Flush()\n",
      "\u001b[2m\u001b[36m(pid=26526)\u001b[0m     ray::RayLog::~RayLog()\n",
      "\u001b[2m\u001b[36m(pid=26526)\u001b[0m     ray::core::CoreWorkerProcess::EnsureInitialized()\n",
      "\u001b[2m\u001b[36m(pid=26526)\u001b[0m     ray::core::CoreWorkerProcess::GetCoreWorker()\n",
      "\u001b[2m\u001b[36m(pid=26526)\u001b[0m     __pyx_pw_3ray_7_raylet_10CoreWorker_23get_worker_id()\n",
      "\u001b[2m\u001b[36m(pid=26526)\u001b[0m     method_vectorcall_NOARGS\n",
      "\u001b[2m\u001b[36m(pid=26526)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=26525)\u001b[0m [2021-10-21 16:49:04,420 C 26525 26674] core_worker.cc:210:  Check failed: core_worker_process The core worker process is not initialized yet or already shutdown.\n",
      "\u001b[2m\u001b[36m(pid=26525)\u001b[0m *** StackTrace Information ***\n",
      "\u001b[2m\u001b[36m(pid=26525)\u001b[0m     ray::SpdLogMessage::Flush()\n",
      "\u001b[2m\u001b[36m(pid=26525)\u001b[0m     ray::RayLog::~RayLog()\n",
      "\u001b[2m\u001b[36m(pid=26525)\u001b[0m     ray::core::CoreWorkerProcess::EnsureInitialized()\n",
      "\u001b[2m\u001b[36m(pid=26525)\u001b[0m     ray::core::CoreWorkerProcess::GetCoreWorker()\n",
      "\u001b[2m\u001b[36m(pid=26525)\u001b[0m     __pyx_pw_3ray_7_raylet_10CoreWorker_23get_worker_id()\n",
      "\u001b[2m\u001b[36m(pid=26525)\u001b[0m     method_vectorcall_NOARGS\n",
      "\u001b[2m\u001b[36m(pid=26525)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(call_model_zero_copy pid=27042)\u001b[0m \n",
      "Running at 10 requests/sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=27724)\u001b[0m [2021-10-21 16:49:56,332 C 27724 27778] core_worker.cc:210:  Check failed: core_worker_process The core worker process is not initialized yet or already shutdown.\n",
      "\u001b[2m\u001b[36m(pid=27724)\u001b[0m *** StackTrace Information ***\n",
      "\u001b[2m\u001b[36m(pid=27724)\u001b[0m     ray::SpdLogMessage::Flush()\n",
      "\u001b[2m\u001b[36m(pid=27724)\u001b[0m     ray::RayLog::~RayLog()\n",
      "\u001b[2m\u001b[36m(pid=27724)\u001b[0m     ray::core::CoreWorkerProcess::EnsureInitialized()\n",
      "\u001b[2m\u001b[36m(pid=27724)\u001b[0m     ray::core::CoreWorkerProcess::GetCoreWorker()\n",
      "\u001b[2m\u001b[36m(pid=27724)\u001b[0m     __pyx_pw_3ray_7_raylet_10CoreWorker_23get_worker_id()\n",
      "\u001b[2m\u001b[36m(pid=27724)\u001b[0m     method_vectorcall_NOARGS\n",
      "\u001b[2m\u001b[36m(pid=27724)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=28452)\u001b[0m [2021-10-21 16:50:44,207 C 28452 28558] core_worker.cc:210:  Check failed: core_worker_process The core worker process is not initialized yet or already shutdown.\n",
      "\u001b[2m\u001b[36m(pid=28452)\u001b[0m *** StackTrace Information ***\n",
      "\u001b[2m\u001b[36m(pid=28452)\u001b[0m     ray::SpdLogMessage::Flush()\n",
      "\u001b[2m\u001b[36m(pid=28452)\u001b[0m     ray::RayLog::~RayLog()\n",
      "\u001b[2m\u001b[36m(pid=28452)\u001b[0m     ray::core::CoreWorkerProcess::EnsureInitialized()\n",
      "\u001b[2m\u001b[36m(pid=28452)\u001b[0m     ray::core::CoreWorkerProcess::GetCoreWorker()\n",
      "\u001b[2m\u001b[36m(pid=28452)\u001b[0m     __pyx_pw_3ray_7_raylet_10CoreWorker_23get_worker_id()\n",
      "\u001b[2m\u001b[36m(pid=28452)\u001b[0m     method_vectorcall_NOARGS\n",
      "\u001b[2m\u001b[36m(pid=28452)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=28451)\u001b[0m [2021-10-21 16:50:44,368 C 28451 28542] core_worker.cc:210:  Check failed: core_worker_process The core worker process is not initialized yet or already shutdown.\n",
      "\u001b[2m\u001b[36m(pid=28451)\u001b[0m *** StackTrace Information ***\n",
      "\u001b[2m\u001b[36m(pid=28451)\u001b[0m     ray::SpdLogMessage::Flush()\n",
      "\u001b[2m\u001b[36m(pid=28451)\u001b[0m     ray::RayLog::~RayLog()\n",
      "\u001b[2m\u001b[36m(pid=28451)\u001b[0m     ray::core::CoreWorkerProcess::EnsureInitialized()\n",
      "\u001b[2m\u001b[36m(pid=28451)\u001b[0m     ray::core::CoreWorkerProcess::GetCoreWorker()\n",
      "\u001b[2m\u001b[36m(pid=28451)\u001b[0m     __pyx_pw_3ray_7_raylet_10CoreWorker_23get_worker_id()\n",
      "\u001b[2m\u001b[36m(pid=28451)\u001b[0m     method_vectorcall_NOARGS\n",
      "\u001b[2m\u001b[36m(pid=28451)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running at 12 requests/sec.\n",
      "Running at 14 requests/sec.\n"
     ]
    }
   ],
   "source": [
    "# Run the benchmark at multiple different request rates\n",
    "to_concat = []\n",
    "for request_rate in REQUEST_RATES:\n",
    "    print(f\"Running at {request_rate} requests/sec.\")\n",
    "    times = run_benchmark(call_model, request_rate, RUNNING_TIME_SEC)\n",
    "    times.insert(0, \"request_rate\", request_rate)\n",
    "    to_concat.append(times)\n",
    "\n",
    "results_zerocopy = pd.concat(to_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24f129d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">latency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request_rate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.045062</td>\n",
       "      <td>0.633906</td>\n",
       "      <td>3.231509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.091599</td>\n",
       "      <td>0.686782</td>\n",
       "      <td>3.092044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.236102</td>\n",
       "      <td>0.827861</td>\n",
       "      <td>3.833799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.378944</td>\n",
       "      <td>0.951470</td>\n",
       "      <td>4.210237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.388363</td>\n",
       "      <td>0.946236</td>\n",
       "      <td>5.028314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.502072</td>\n",
       "      <td>1.175381</td>\n",
       "      <td>4.842030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.748741</td>\n",
       "      <td>1.433759</td>\n",
       "      <td>5.539057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.821735</td>\n",
       "      <td>1.497654</td>\n",
       "      <td>4.901823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.075294</td>\n",
       "      <td>3.308455</td>\n",
       "      <td>5.638475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               latency                    \n",
       "                  mean    median       max\n",
       "request_rate                              \n",
       "2             1.045062  0.633906  3.231509\n",
       "3             1.091599  0.686782  3.092044\n",
       "4             1.236102  0.827861  3.833799\n",
       "5             1.378944  0.951470  4.210237\n",
       "6             1.388363  0.946236  5.028314\n",
       "8             1.502072  1.175381  4.842030\n",
       "10            1.748741  1.433759  5.539057\n",
       "12            1.821735  1.497654  4.901823\n",
       "14            3.075294  3.308455  5.638475"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_results_zerocopy = results_zerocopy.groupby(\"request_rate\").aggregate({\n",
    "    \"latency\": [\"mean\", \"median\", \"max\"]})\n",
    "agg_results_zerocopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "381a02cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f182de02a60>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the two sets of results against each other.\n",
    "plt.rcParams.update({\"font.size\": 16})\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(agg_results.index, agg_results[\"latency\", \"mean\"],\n",
    "         \"-o\", label=\"Without zero-copy loading\")\n",
    "plt.plot(agg_results_zerocopy.index, \n",
    "         agg_results_zerocopy[\"latency\", \"mean\"],\n",
    "         \"-o\", label=\"With zero-copy loading\")\n",
    "plt.xlabel(\"Average Requests per Second\")\n",
    "plt.ylabel(\"Average Request Latency (sec)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cac27d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old code defined an actor\n",
    "\n",
    "# class ModelCallback:\n",
    "#     def __init__(self, model_ref: ray.ObjectRef):\n",
    "#         self._model_ref = model_ref\n",
    "\n",
    "#     def __call__(self, *args: Any, **kwargs: Any) -> Any:\n",
    "#         return ray.get(call_model.remote(self._model_ref, args, kwargs))\n",
    "\n",
    "# @ray.remote\n",
    "# class QAModelZeroCopyActor:\n",
    "#     def __init__(self):\n",
    "#         self._qa = transformers.pipeline(\"question-answering\", model=model_name)\n",
    "#         self._model_ref = ray.put(zerocopy.extract_tensors(self._qa.model))\n",
    "#         self._qa.model = ModelCallback(self._model_ref)\n",
    "\n",
    "#     def run_inference(self, input_: Dict[str, str]) -> Dict[str, Any]:\n",
    "#         return self._qa(input_)\n",
    "\n",
    "# zero_copy_actors = [QAModelZeroCopyActor.options(max_concurrency=8).remote() \n",
    "#                     for _ in range(NUM_QA_MODELS)]\n",
    "# ray.get(zero_copy_actors[0].run_inference.remote(qa_input))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "afa7e0f34d224467fd24b0cfa9c212efa127bdf53fe1c4e3ddf54198f34a39e3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
