{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# benchmark.ipynb\n",
    "\n",
    "This notebook contains the text and code for the next blog post in the zero-copy model series, \n",
    "title TBD.\n",
    "\n",
    "The first post explained how to load PyTorch models for inference extremely fast by leveraging the Plasma object store's ability to load numeric data directly from shared memory.\n",
    "\n",
    "In this post, we talk in more concrete terms about how to use this zero-copy model loading for model serving. We put together a simple model serving system, then set up a microbenchmark that simulates a heavy-tailed traffic pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization and import code goes in this cell.\n",
    "\n",
    "# Imports: Python core, then third-party, then local.\n",
    "# Try to keep each block in alphabetical order, or the linter may get angry.\n",
    "import asyncio\n",
    "import concurrent.futures\n",
    "import copy\n",
    "import os\n",
    "import requests\n",
    "import sys\n",
    "import starlette\n",
    "import threading\n",
    "import time\n",
    "import urllib\n",
    "from typing import Dict, Any, Union, List, Callable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import ray\n",
    "from ray import serve\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "import zerocopy\n",
    "\n",
    "\n",
    "# Reduce the volume of warning messages from `transformers`\n",
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "def reboot_ray():\n",
    "    if ray.is_initialized():\n",
    "        ray.shutdown()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        return ray.init(num_gpus=1)\n",
    "    else:\n",
    "        return ray.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title of new blog post goes here\n",
    "\n",
    "*Recap of previous blog post goes here.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario\n",
    "\n",
    "The end-to-end scenario for our benchmark involves supporting an AI chatbot.\n",
    "The chatbot's conversational AI runs off of a conversation tree (**TODO:** What's the best term for this tree?). Some of the nodes of this tree invoke question answering models.\n",
    "\n",
    "Our benchmark will cover the model serving portion of the chatbot's backend. This \n",
    "model serving layer runs question answering (QA) models on behalf of the \n",
    "chatbot's conversational AI. The chatbot's conversation tree leads to 4 very different\n",
    "question answering scenarios, and each scenario has its own dedicated QA\n",
    "model. Because the chatbot speaks 3 different languages, there are three versions of\n",
    "each model deployed: one for each language. So the model serving layer runs a total of\n",
    "12 models to cover the 4 question types and 3 languages.\n",
    "\n",
    "> **TODO:** Cartoon block diagram of the end-to-end scenario. \n",
    "> Diagram should show a user interacting with a chatbot. The chatbot runs off of a conversation tree. \n",
    "> Some of the nodes of the conversation tree have question answering models hanging off of them.\n",
    "\n",
    "For our question answering models, we'll use 12 copies of `deepset/roberta-base-squad2`,\n",
    "the most popular question answering model on the [Huggingface model marketplace](https://huggingface.co/models).\n",
    "Here's some code to load that model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load with standard method: 5.68 s ± 32.8 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "model_name = \"deepset/roberta-base-squad2\"\n",
    "\n",
    "# Strip out this timing code for the blog version.\n",
    "print(\"Time to load with standard method: \", end=\"\")\n",
    "%timeit -r3 transformers.pipeline(\"question-answering\", model=model_name)\n",
    "qa = transformers.pipeline(\"question-answering\", model=model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of this model isn't very sensitive to the specific question and context provided,\n",
    "so we define a single set of inputs and outputs for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 4.278851065464551e-06, 'start': 483, 'end': 484, 'answer': '5'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_input = {\n",
    "    \"question\": \"What is 1 + 1?\",\n",
    "    \"context\": \n",
    "        \"\"\"Addition (usually signified by the plus symbol +) is one of the four basic operations of \n",
    "        arithmetic, the other three being subtraction, multiplication and division. The addition of two \n",
    "        whole numbers results in the total amount or sum of those values combined. The example in the\n",
    "        adjacent image shows a combination of three apples and two apples, making a total of five apples. \n",
    "        This observation is equivalent to the mathematical expression \"3 + 2 = 5\" (that is, \"3 plus 2 \n",
    "        is equal to 5\").\n",
    "        \"\"\"\n",
    "}\n",
    "\n",
    "result = qa(qa_input)\n",
    "qa_answer = result[\"answer\"]\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline results\n",
    "\n",
    "Let's start with a baseline implementation of model serving for this model. This baseline implementation emulates running each QA model in a separate container. The server has 12 CPUs, so each container gets 1 CPU. We implement this baseline configuration with a pool of Ray actors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=8026)\u001b[0m 2021-10-20 15:35:22,101\tINFO checkpoint_path.py:15 -- Using RayInternalKVStore for controller checkpoint and recovery.\n",
      "\u001b[2m\u001b[36m(pid=8026)\u001b[0m 2021-10-20 15:35:22,105\tINFO http_state.py:75 -- Starting HTTP proxy with name 'SERVE_CONTROLLER_ACTOR:DJypMV:SERVE_PROXY_ACTOR-node:192.168.0.238-0' on node 'node:192.168.0.238-0' listening on '127.0.0.1:8000'\n",
      "2021-10-20 15:35:22,357\tINFO api.py:455 -- Started Serve instance in namespace '37239ce0-8e04-4b0e-9bde-b2a4d6a85078'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ray.serve.api.Client at 0x7ff780377bb0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serve.shutdown()\n",
    "reboot_ray()\n",
    "serve.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=8022)\u001b[0m INFO:     Started server process [8022]\n",
      "2021-10-20 15:35:22,385\tINFO api.py:243 -- Updating deployment 'qa0'. component=serve deployment=qa0\n",
      "2021-10-20 15:35:22,395\tINFO api.py:243 -- Updating deployment 'qa1'. component=serve deployment=qa1\n",
      "2021-10-20 15:35:22,406\tINFO api.py:243 -- Updating deployment 'qa2'. component=serve deployment=qa2\n",
      "2021-10-20 15:35:22,419\tINFO api.py:243 -- Updating deployment 'qa3'. component=serve deployment=qa3\n",
      "2021-10-20 15:35:22,433\tINFO api.py:243 -- Updating deployment 'qa4'. component=serve deployment=qa4\n",
      "\u001b[2m\u001b[36m(pid=8026)\u001b[0m 2021-10-20 15:35:22,435\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa0'. component=serve deployment=qa0\n",
      "\u001b[2m\u001b[36m(pid=8026)\u001b[0m 2021-10-20 15:35:22,445\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa1'. component=serve deployment=qa1\n",
      "\u001b[2m\u001b[36m(pid=8026)\u001b[0m 2021-10-20 15:35:22,455\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa2'. component=serve deployment=qa2\n",
      "\u001b[2m\u001b[36m(pid=8026)\u001b[0m 2021-10-20 15:35:22,466\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa3'. component=serve deployment=qa3\n",
      "2021-10-20 15:35:22,506\tINFO api.py:243 -- Updating deployment 'qa5'. component=serve deployment=qa5\n",
      "2021-10-20 15:35:22,527\tINFO api.py:243 -- Updating deployment 'qa6'. component=serve deployment=qa6\n",
      "2021-10-20 15:35:22,560\tINFO api.py:243 -- Updating deployment 'qa7'. component=serve deployment=qa7\n",
      "\u001b[2m\u001b[36m(pid=8026)\u001b[0m 2021-10-20 15:35:22,476\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa4'. component=serve deployment=qa4\n",
      "2021-10-20 15:35:22,591\tINFO api.py:243 -- Updating deployment 'qa8'. component=serve deployment=qa8\n",
      "2021-10-20 15:35:22,680\tINFO api.py:243 -- Updating deployment 'qa9'. component=serve deployment=qa9\n",
      "\u001b[2m\u001b[36m(pid=8026)\u001b[0m 2021-10-20 15:35:22,595\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa5'. component=serve deployment=qa5\n",
      "\u001b[2m\u001b[36m(pid=8026)\u001b[0m 2021-10-20 15:35:22,606\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa6'. component=serve deployment=qa6\n",
      "\u001b[2m\u001b[36m(pid=8026)\u001b[0m 2021-10-20 15:35:22,617\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa7'. component=serve deployment=qa7\n",
      "\u001b[2m\u001b[36m(pid=8026)\u001b[0m 2021-10-20 15:35:22,629\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa8'. component=serve deployment=qa8\n",
      "2021-10-20 15:35:22,729\tINFO api.py:243 -- Updating deployment 'qa10'. component=serve deployment=qa10\n",
      "2021-10-20 15:35:22,780\tINFO api.py:243 -- Updating deployment 'qa11'. component=serve deployment=qa11\n",
      "\u001b[2m\u001b[36m(pid=8026)\u001b[0m 2021-10-20 15:35:22,786\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa9'. component=serve deployment=qa9\n",
      "\u001b[2m\u001b[36m(pid=8026)\u001b[0m 2021-10-20 15:35:22,801\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa10'. component=serve deployment=qa10\n",
      "\u001b[2m\u001b[36m(pid=8026)\u001b[0m 2021-10-20 15:35:22,817\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa11'. component=serve deployment=qa11\n"
     ]
    }
   ],
   "source": [
    "class QAModel:\n",
    "    def __init__(self):\n",
    "        self._qa = transformers.pipeline(\"question-answering\", model=model_name)\n",
    "\n",
    "    def __call__(self, request: starlette.requests.Request):\n",
    "        # Pull model inputs from URL query parameters.\n",
    "        # A production version of this code would sanitize these strings.\n",
    "        model_input = {\n",
    "            \"question\": request.query_params[\"question\"],\n",
    "            \"context\": request.query_params[\"context\"]\n",
    "        }\n",
    "        return self._qa(model_input)\n",
    "    \n",
    "\n",
    "# Define endpoints\n",
    "NUM_QA_MODELS = 12\n",
    "deployments = [\n",
    "    serve.deployment(QAModel, f\"qa{model_num}\")\n",
    "    for model_num in range(NUM_QA_MODELS)\n",
    "]\n",
    "\n",
    "for d in deployments:\n",
    "    d.deploy(_blocking = False)\n",
    "\n",
    "# Wait a moment so log output doesn't go to the next cell's output\n",
    "time.sleep(1.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 4.278851065464551e-06, 'start': 483, 'end': 484, 'answer': '5'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try out the deployment.\n",
    "# This web service call blocks until the asychronous deployment has completed.\n",
    "params = urllib.parse.urlencode(qa_input)\n",
    "requests.get(f\"http://127.0.0.1:8000/qa0?{params}\").json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's wrap this model web service in a callback function that calls the model, retrieves the result, and\n",
    "returns elapsed time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.381 seconds elapsed'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def call_model(model_num: int, question: str, context: str, expected_answer: str) -> float:\n",
    "    \"\"\"\n",
    "    Callack function that calls the model deployment, retrieves and \n",
    "    validates the result, and returns elapsed time.\n",
    "\n",
    "    :param model_num: Index of the model to call\n",
    "    :param question: The `question` argument to pass to the QA model\n",
    "    :param context: The `context` argument to pass to the QA model\n",
    "    :param expected_answer: The answer that the model should return\n",
    "\n",
    "    :returns: Tuple of start and end times of the web service call\n",
    "    \"\"\"\n",
    "    # For now, use the same input every time\n",
    "    params = urllib.parse.urlencode({\"question\": question, \"context\": context})\n",
    "\n",
    "    start_time = time.time()\n",
    "    result = requests.get(f\"http://127.0.0.1:8000/qa{model_num}?{params}\").json()\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Do some basic validation\n",
    "    if result[\"answer\"] != expected_answer:\n",
    "        raise ValueError(f\"Unexpected result: {result}\")\n",
    "\n",
    "    return (start_time, end_time)\n",
    "    \n",
    "times = call_model(0, qa_input[\"question\"], qa_input[\"context\"], qa_answer)\n",
    "f\"{times[1] - times[0]:1.3f} seconds elapsed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define a simple benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request_id</th>\n",
       "      <th>model_num</th>\n",
       "      <th>desired_start</th>\n",
       "      <th>actual_start</th>\n",
       "      <th>end</th>\n",
       "      <th>latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>0.380416</td>\n",
       "      <td>0.379527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.085285</td>\n",
       "      <td>0.760673</td>\n",
       "      <td>0.675388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.171067</td>\n",
       "      <td>1.511640</td>\n",
       "      <td>1.340573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.254611</td>\n",
       "      <td>0.655191</td>\n",
       "      <td>0.400580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.338350</td>\n",
       "      <td>1.512051</td>\n",
       "      <td>1.173701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.417922</td>\n",
       "      <td>3.024044</td>\n",
       "      <td>2.606122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.504010</td>\n",
       "      <td>3.025021</td>\n",
       "      <td>2.521011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.584484</td>\n",
       "      <td>3.025605</td>\n",
       "      <td>2.441121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.667049</td>\n",
       "      <td>3.026004</td>\n",
       "      <td>2.358955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.754944</td>\n",
       "      <td>5.266271</td>\n",
       "      <td>4.511327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.835693</td>\n",
       "      <td>5.266731</td>\n",
       "      <td>4.431038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.918103</td>\n",
       "      <td>5.267181</td>\n",
       "      <td>4.349078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.005088</td>\n",
       "      <td>1.391473</td>\n",
       "      <td>0.386385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>1.088445</td>\n",
       "      <td>5.267821</td>\n",
       "      <td>4.179376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>1.171883</td>\n",
       "      <td>5.268422</td>\n",
       "      <td>4.096539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.255304</td>\n",
       "      <td>5.268560</td>\n",
       "      <td>4.013256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.336194</td>\n",
       "      <td>1.738688</td>\n",
       "      <td>0.402494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>1.421019</td>\n",
       "      <td>1.811178</td>\n",
       "      <td>0.390159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.501151</td>\n",
       "      <td>2.187042</td>\n",
       "      <td>0.685891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>1.584665</td>\n",
       "      <td>6.014958</td>\n",
       "      <td>4.430293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.670709</td>\n",
       "      <td>6.015357</td>\n",
       "      <td>4.344648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1.751811</td>\n",
       "      <td>7.505722</td>\n",
       "      <td>5.753911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.835330</td>\n",
       "      <td>7.506122</td>\n",
       "      <td>5.670792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1.916667</td>\n",
       "      <td>1.920719</td>\n",
       "      <td>7.506484</td>\n",
       "      <td>5.585765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000393</td>\n",
       "      <td>19.404881</td>\n",
       "      <td>17.404488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>2.083333</td>\n",
       "      <td>2.085121</td>\n",
       "      <td>19.405886</td>\n",
       "      <td>17.320765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>2.168375</td>\n",
       "      <td>19.406390</td>\n",
       "      <td>17.238015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>2.252565</td>\n",
       "      <td>19.406844</td>\n",
       "      <td>17.154279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.335482</td>\n",
       "      <td>19.407325</td>\n",
       "      <td>17.071843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>2.416667</td>\n",
       "      <td>2.420698</td>\n",
       "      <td>2.808478</td>\n",
       "      <td>0.387780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.502032</td>\n",
       "      <td>19.407819</td>\n",
       "      <td>16.905787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2.583333</td>\n",
       "      <td>2.585041</td>\n",
       "      <td>19.408217</td>\n",
       "      <td>16.823176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.670738</td>\n",
       "      <td>19.408679</td>\n",
       "      <td>16.737941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>2.752293</td>\n",
       "      <td>19.409054</td>\n",
       "      <td>16.656761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>2.836316</td>\n",
       "      <td>19.409421</td>\n",
       "      <td>16.573105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>2.916667</td>\n",
       "      <td>2.921357</td>\n",
       "      <td>19.410060</td>\n",
       "      <td>16.488703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.002199</td>\n",
       "      <td>19.410449</td>\n",
       "      <td>16.408250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>3.083333</td>\n",
       "      <td>3.086886</td>\n",
       "      <td>19.410831</td>\n",
       "      <td>16.323945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>3.167080</td>\n",
       "      <td>19.410976</td>\n",
       "      <td>16.243896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>3.252405</td>\n",
       "      <td>19.411688</td>\n",
       "      <td>16.159283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.338216</td>\n",
       "      <td>19.412059</td>\n",
       "      <td>16.073843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>3.416667</td>\n",
       "      <td>3.420667</td>\n",
       "      <td>19.412973</td>\n",
       "      <td>15.992306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.502574</td>\n",
       "      <td>19.414125</td>\n",
       "      <td>15.911551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>3.583333</td>\n",
       "      <td>3.586081</td>\n",
       "      <td>19.413731</td>\n",
       "      <td>15.827650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.667634</td>\n",
       "      <td>19.414045</td>\n",
       "      <td>15.746411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>3.752777</td>\n",
       "      <td>19.414303</td>\n",
       "      <td>15.661526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>3.836525</td>\n",
       "      <td>19.415421</td>\n",
       "      <td>15.578896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>3.916667</td>\n",
       "      <td>3.920662</td>\n",
       "      <td>19.416330</td>\n",
       "      <td>15.495668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.001777</td>\n",
       "      <td>19.417469</td>\n",
       "      <td>15.415692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>4.083333</td>\n",
       "      <td>4.086869</td>\n",
       "      <td>19.417148</td>\n",
       "      <td>15.330279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.168013</td>\n",
       "      <td>19.417281</td>\n",
       "      <td>15.249268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>4.253019</td>\n",
       "      <td>19.417007</td>\n",
       "      <td>15.163988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.337916</td>\n",
       "      <td>19.417898</td>\n",
       "      <td>15.079982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>4.416667</td>\n",
       "      <td>4.420913</td>\n",
       "      <td>4.803557</td>\n",
       "      <td>0.382644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.503384</td>\n",
       "      <td>5.181911</td>\n",
       "      <td>0.678527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>4.583333</td>\n",
       "      <td>4.586157</td>\n",
       "      <td>19.417979</td>\n",
       "      <td>14.831822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.668150</td>\n",
       "      <td>19.418053</td>\n",
       "      <td>14.749903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>4.751816</td>\n",
       "      <td>19.418128</td>\n",
       "      <td>14.666312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>4.835055</td>\n",
       "      <td>19.418203</td>\n",
       "      <td>14.583148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>4.916667</td>\n",
       "      <td>4.920665</td>\n",
       "      <td>19.418359</td>\n",
       "      <td>14.497694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    request_id  model_num  desired_start  actual_start        end    latency\n",
       "0            0          0       0.000000      0.000889   0.380416   0.379527\n",
       "1            1          0       0.083333      0.085285   0.760673   0.675388\n",
       "2            2          0       0.166667      0.171067   1.511640   1.340573\n",
       "3            3          1       0.250000      0.254611   0.655191   0.400580\n",
       "4            4          0       0.333333      0.338350   1.512051   1.173701\n",
       "5            5          0       0.416667      0.417922   3.024044   2.606122\n",
       "6            6          0       0.500000      0.504010   3.025021   2.521011\n",
       "7            7          0       0.583333      0.584484   3.025605   2.441121\n",
       "8            8          0       0.666667      0.667049   3.026004   2.358955\n",
       "9            9          0       0.750000      0.754944   5.266271   4.511327\n",
       "10          10          0       0.833333      0.835693   5.266731   4.431038\n",
       "11          11          0       0.916667      0.918103   5.267181   4.349078\n",
       "12          12          1       1.000000      1.005088   1.391473   0.386385\n",
       "13          13          0       1.083333      1.088445   5.267821   4.179376\n",
       "14          14          0       1.166667      1.171883   5.268422   4.096539\n",
       "15          15          0       1.250000      1.255304   5.268560   4.013256\n",
       "16          16          2       1.333333      1.336194   1.738688   0.402494\n",
       "17          17          1       1.416667      1.421019   1.811178   0.390159\n",
       "18          18          1       1.500000      1.501151   2.187042   0.685891\n",
       "19          19          0       1.583333      1.584665   6.014958   4.430293\n",
       "20          20          0       1.666667      1.670709   6.015357   4.344648\n",
       "21          21          0       1.750000      1.751811   7.505722   5.753911\n",
       "22          22          0       1.833333      1.835330   7.506122   5.670792\n",
       "23          23          0       1.916667      1.920719   7.506484   5.585765\n",
       "24          24          0       2.000000      2.000393  19.404881  17.404488\n",
       "25          25          0       2.083333      2.085121  19.405886  17.320765\n",
       "26          26          0       2.166667      2.168375  19.406390  17.238015\n",
       "27          27          0       2.250000      2.252565  19.406844  17.154279\n",
       "28          28          0       2.333333      2.335482  19.407325  17.071843\n",
       "29          29          1       2.416667      2.420698   2.808478   0.387780\n",
       "30          30          0       2.500000      2.502032  19.407819  16.905787\n",
       "31          31          0       2.583333      2.585041  19.408217  16.823176\n",
       "32          32          0       2.666667      2.670738  19.408679  16.737941\n",
       "33          33          0       2.750000      2.752293  19.409054  16.656761\n",
       "34          34          0       2.833333      2.836316  19.409421  16.573105\n",
       "35          35          0       2.916667      2.921357  19.410060  16.488703\n",
       "36          36          0       3.000000      3.002199  19.410449  16.408250\n",
       "37          37          0       3.083333      3.086886  19.410831  16.323945\n",
       "38          38          0       3.166667      3.167080  19.410976  16.243896\n",
       "39          39          0       3.250000      3.252405  19.411688  16.159283\n",
       "40          40          0       3.333333      3.338216  19.412059  16.073843\n",
       "41          41          0       3.416667      3.420667  19.412973  15.992306\n",
       "42          42          0       3.500000      3.502574  19.414125  15.911551\n",
       "43          43          0       3.583333      3.586081  19.413731  15.827650\n",
       "44          44          0       3.666667      3.667634  19.414045  15.746411\n",
       "45          45          0       3.750000      3.752777  19.414303  15.661526\n",
       "46          46          0       3.833333      3.836525  19.415421  15.578896\n",
       "47          47          0       3.916667      3.920662  19.416330  15.495668\n",
       "48          48          0       4.000000      4.001777  19.417469  15.415692\n",
       "49          49          0       4.083333      4.086869  19.417148  15.330279\n",
       "50          50          0       4.166667      4.168013  19.417281  15.249268\n",
       "51          51          0       4.250000      4.253019  19.417007  15.163988\n",
       "52          52          0       4.333333      4.337916  19.417898  15.079982\n",
       "53          53          1       4.416667      4.420913   4.803557   0.382644\n",
       "54          54          1       4.500000      4.503384   5.181911   0.678527\n",
       "55          55          0       4.583333      4.586157  19.417979  14.831822\n",
       "56          56          0       4.666667      4.668150  19.418053  14.749903\n",
       "57          57          0       4.750000      4.751816  19.418128  14.666312\n",
       "58          58          0       4.833333      4.835055  19.418203  14.583148\n",
       "59          59          0       4.916667      4.920665  19.418359  14.497694"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_model_ids(lambda_: float, num_models: int, num_points: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Draw model IDs at random from a truncated Poisson distribution.\n",
    "\n",
    "    :param lambda_: Primary parameter of the distribution, which also happens to \n",
    "     be the mean value of the (untruncated) distribution.\n",
    "    :num_models: Number of models. This function will truncate the Poisson \n",
    "     distribution such that only values < num_models will be returned.\n",
    "    :param num_points: Number of random model IDs to return.\n",
    "\n",
    "    :returns: Randomly generated model IDs for a series of requests, as a\n",
    "     1-dimensional array.\n",
    "    \"\"\"\n",
    "    # Draw numbers from a truncated Poisson distribution.\n",
    "    # Start with a non-truncated distribution, then resample for\n",
    "    # any values that went over the limit. \n",
    "    rng = np.random.default_rng()\n",
    "    result = rng.poisson(lambda_, size=num_points)\n",
    "    while np.any(result >= num_models):\n",
    "        new_values = rng.poisson(lambda_, size=np.sum(result >= num_models))\n",
    "        result[result >= num_models] = new_values\n",
    "    return result\n",
    "\n",
    "\n",
    "def run_benchmark(model_callback: Callable, requests_per_sec: float, num_sec: int,\n",
    "                  lambda_: float = 0.3) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    A simple benchmark in Python.\n",
    "\n",
    "    Sends a constant-rate stream of requests to multiple models, with the division\n",
    "    of traffic among models following a truncated Poisson distribution.\n",
    "\n",
    "    Because some notebook servers (i.e. VSCode) don't play well with \n",
    "    asyncio, we use threads to manage concurrent requests.\n",
    "\n",
    "    :param model_callback: Thread-safe callback function that makes a \n",
    "     single request and returns elapsed time. Should have the signature\n",
    "     `f(model_num: int, question: str, context: str, expected_answer: str)`\n",
    "    :param request_per_sec: Constant request rate to use\n",
    "    :param num_sec: Seconds of traffic to generate at the requested rate.\n",
    "     The actual session will extend past this window until all open requests have\n",
    "     finished.\n",
    "    :param lambda_: Primary parameter of the truncated Poisson distribution\n",
    "     used to split requests among models. Approximately equal to the mean of\n",
    "     the distribution. The default value of 0.3 sends 70% of traffic to model 0.\n",
    "\n",
    "    :returns: DataFrame of benchmark results at per-request granularity\n",
    "    \"\"\"\n",
    "    # Convert benchmark paramters into a more useable internal form\n",
    "    sec_per_request = 1.0 / requests_per_sec\n",
    "    num_requests = int(num_sec * requests_per_sec)\n",
    "\n",
    "    # Preallocate the trace as a set of lists.\n",
    "    benchmark_start_time = time.time()\n",
    "    desired_start_times = [benchmark_start_time + (sec_per_request * i)\n",
    "                           for i in range(num_requests)]\n",
    "    model_nums = gen_model_ids(lambda_, NUM_QA_MODELS, num_requests)\n",
    "    actual_start_times = [None] * num_requests\n",
    "    end_times = [None] * num_requests\n",
    "\n",
    "    # Unbounded thread pool\n",
    "    thread_pool = concurrent.futures.ThreadPoolExecutor(100)\n",
    "\n",
    "    # Map from request object to request number\n",
    "    active_requests = {}  # type: Dict[concurrent.futures.Future, int]\n",
    "\n",
    "    # Main event loop: Spawn background requests, get their responses.\n",
    "    request_num = 0\n",
    "    while request_num < num_requests or len(active_requests) > 0:\n",
    "        sec_to_next = (\n",
    "            1.0 if request_num >= num_requests\n",
    "            else desired_start_times[request_num] - time.time()\n",
    "        )\n",
    "        if sec_to_next <= 0:\n",
    "            # Time to send the next request\n",
    "            model_num = model_nums[request_num]\n",
    "            future = thread_pool.submit(model_callback, model_num,\n",
    "                qa_input[\"question\"], qa_input[\"context\"], qa_answer)\n",
    "            active_requests[future] = request_num\n",
    "            request_num += 1\n",
    "        else:\n",
    "            # Block until it's time to send the next request or a previous\n",
    "            # request is done.\n",
    "            ready_set, _ = concurrent.futures.wait(\n",
    "                list(active_requests.keys()), \n",
    "                timeout=sec_to_next)\n",
    "            \n",
    "            # Record timings from any open requests that have completed.\n",
    "            for future in ready_set:\n",
    "                request_id = active_requests.pop(future)\n",
    "                start_time, end_time = future.result()\n",
    "                actual_start_times[request_id] = start_time\n",
    "                end_times[request_id] = end_time\n",
    "    \n",
    "    # Collate results as a DataFrame\n",
    "    result = pd.DataFrame({\n",
    "        \"request_id\": range(num_requests),\n",
    "        \"model_num\": model_nums, \n",
    "        \"desired_start\": desired_start_times, \n",
    "        \"actual_start\": actual_start_times, \n",
    "        \"end\": end_times\n",
    "    })\n",
    "\n",
    "    # Make all times relative to start of the trace\n",
    "    for key in (\"desired_start\", \"actual_start\", \"end\"):\n",
    "        result[key] -= benchmark_start_time\n",
    "    result[\"latency\"] = result[\"end\"] - result[\"actual_start\"]\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# Quick test run\n",
    "run_benchmark(call_model, 12, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the benchmark with our baseline model deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running at 2 requests/sec.\n",
      "Running at 3 requests/sec.\n",
      "Running at 4 requests/sec.\n",
      "Running at 5 requests/sec.\n",
      "Running at 6 requests/sec.\n",
      "Running at 8 requests/sec.\n",
      "Running at 10 requests/sec.\n",
      "Running at 12 requests/sec.\n",
      "Running at 14 requests/sec.\n"
     ]
    }
   ],
   "source": [
    "# Run the benchmark at multiple different request rates\n",
    "REQUEST_RATES = (2, 3, 4, 5, 6, 8, 10, 12, 14)\n",
    "RUNNING_TIME_SEC = 60\n",
    "to_concat = []\n",
    "for request_rate in REQUEST_RATES:\n",
    "    print(f\"Running at {request_rate} requests/sec.\")\n",
    "    times = run_benchmark(call_model, request_rate, RUNNING_TIME_SEC)\n",
    "    times.insert(0, \"request_rate\", request_rate)\n",
    "    to_concat.append(times)\n",
    "\n",
    "results = pd.concat(to_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request_rate</th>\n",
       "      <th>request_id</th>\n",
       "      <th>model_num</th>\n",
       "      <th>desired_start</th>\n",
       "      <th>actual_start</th>\n",
       "      <th>end</th>\n",
       "      <th>latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000927</td>\n",
       "      <td>0.383460</td>\n",
       "      <td>0.382533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.108800</td>\n",
       "      <td>0.496008</td>\n",
       "      <td>0.387208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.209062</td>\n",
       "      <td>1.644135</td>\n",
       "      <td>1.435073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.309994</td>\n",
       "      <td>1.644962</td>\n",
       "      <td>1.334968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.403176</td>\n",
       "      <td>1.644874</td>\n",
       "      <td>1.241698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>10</td>\n",
       "      <td>595</td>\n",
       "      <td>1</td>\n",
       "      <td>59.5</td>\n",
       "      <td>134.508849</td>\n",
       "      <td>136.428379</td>\n",
       "      <td>1.919530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>10</td>\n",
       "      <td>596</td>\n",
       "      <td>0</td>\n",
       "      <td>59.6</td>\n",
       "      <td>134.793927</td>\n",
       "      <td>166.483747</td>\n",
       "      <td>31.689820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>10</td>\n",
       "      <td>597</td>\n",
       "      <td>1</td>\n",
       "      <td>59.7</td>\n",
       "      <td>134.795372</td>\n",
       "      <td>136.428884</td>\n",
       "      <td>1.633512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>10</td>\n",
       "      <td>598</td>\n",
       "      <td>0</td>\n",
       "      <td>59.8</td>\n",
       "      <td>134.797381</td>\n",
       "      <td>166.483577</td>\n",
       "      <td>31.686196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>10</td>\n",
       "      <td>599</td>\n",
       "      <td>1</td>\n",
       "      <td>59.9</td>\n",
       "      <td>134.799677</td>\n",
       "      <td>136.428801</td>\n",
       "      <td>1.629124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     request_rate  request_id  model_num  desired_start  actual_start  \\\n",
       "0              10           0          1            0.0      0.000927   \n",
       "1              10           1          0            0.1      0.108800   \n",
       "2              10           2          0            0.2      0.209062   \n",
       "3              10           3          0            0.3      0.309994   \n",
       "4              10           4          0            0.4      0.403176   \n",
       "..            ...         ...        ...            ...           ...   \n",
       "595            10         595          1           59.5    134.508849   \n",
       "596            10         596          0           59.6    134.793927   \n",
       "597            10         597          1           59.7    134.795372   \n",
       "598            10         598          0           59.8    134.797381   \n",
       "599            10         599          1           59.9    134.799677   \n",
       "\n",
       "            end    latency  \n",
       "0      0.383460   0.382533  \n",
       "1      0.496008   0.387208  \n",
       "2      1.644135   1.435073  \n",
       "3      1.644962   1.334968  \n",
       "4      1.644874   1.241698  \n",
       "..          ...        ...  \n",
       "595  136.428379   1.919530  \n",
       "596  166.483747  31.689820  \n",
       "597  136.428884   1.633512  \n",
       "598  166.483577  31.686196  \n",
       "599  136.428801   1.629124  \n",
       "\n",
       "[600 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[results[\"request_rate\"] == 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">latency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request_rate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.378963</td>\n",
       "      <td>0.378709</td>\n",
       "      <td>0.392184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.502493</td>\n",
       "      <td>0.428341</td>\n",
       "      <td>1.266293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.386708</td>\n",
       "      <td>6.125747</td>\n",
       "      <td>13.288982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11.340788</td>\n",
       "      <td>10.285691</td>\n",
       "      <td>34.484218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16.823012</td>\n",
       "      <td>18.197466</td>\n",
       "      <td>38.485654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22.718499</td>\n",
       "      <td>30.476950</td>\n",
       "      <td>38.834132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24.275940</td>\n",
       "      <td>33.093005</td>\n",
       "      <td>39.717516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>26.953165</td>\n",
       "      <td>36.462422</td>\n",
       "      <td>45.481582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>26.097682</td>\n",
       "      <td>34.631747</td>\n",
       "      <td>45.427171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                latency                      \n",
       "                   mean     median        max\n",
       "request_rate                                 \n",
       "2              0.378963   0.378709   0.392184\n",
       "3              0.502493   0.428341   1.266293\n",
       "4              5.386708   6.125747  13.288982\n",
       "5             11.340788  10.285691  34.484218\n",
       "6             16.823012  18.197466  38.485654\n",
       "8             22.718499  30.476950  38.834132\n",
       "10            24.275940  33.093005  39.717516\n",
       "12            26.953165  36.462422  45.481582\n",
       "14            26.097682  34.631747  45.427171"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_results = results.groupby(\"request_rate\").aggregate({\"latency\": [\"mean\", \"median\", \"max\"]})\n",
    "agg_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Average Latency (sec)')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(agg_results.index, agg_results[\"latency\", \"mean\"])\n",
    "plt.xlabel(\"Requests per Second\")\n",
    "plt.ylabel(\"Average Latency (sec)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using zero-copy model loading\n",
    "\n",
    "Now let's redo this baseline using zero-copy model loading.\n",
    "First we'll need to convert the model into a format that can be loaded without copying\n",
    "data. The model is actually a pipeline of multiple operations, but the RoBERTa model\n",
    "at its center is orders of magnitude larger and more CPU-intensive than everything else, so we'll only apply zero-copy loading to that part.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=8026)\u001b[0m 2021-10-20 15:54:24,073\tINFO backend_state.py:914 -- Removing 1 replicas from deployment 'qa0'. component=serve deployment=qa0\n",
      "\u001b[2m\u001b[36m(pid=8026)\u001b[0m 2021-10-20 15:54:24,076\tINFO backend_state.py:914 -- Removing 1 replicas from deployment 'qa1'. component=serve deployment=qa1\n",
      "\u001b[2m\u001b[36m(pid=8026)\u001b[0m 2021-10-20 15:54:24,079\tINFO backend_state.py:914 -- Removing 1 replicas from deployment 'qa2'. component=serve deployment=qa2\n",
      "\u001b[2m\u001b[36m(pid=8026)\u001b[0m 2021-10-20 15:54:24,081\tINFO backend_state.py:914 -- Removing 1 replicas from deployment 'qa3'. component=serve deployment=qa3\n",
      "\u001b[2m\u001b[36m(pid=8026)\u001b[0m 2021-10-20 15:54:24,084\tINFO backend_state.py:914 -- Removing 1 replicas from deployment 'qa4'. component=serve deployment=qa4\n",
      "\u001b[2m\u001b[36m(pid=8026)\u001b[0m 2021-10-20 15:54:24,087\tINFO backend_state.py:914 -- Removing 1 replicas from deployment 'qa5'. component=serve deployment=qa5\n",
      "\u001b[2m\u001b[36m(pid=8026)\u001b[0m 2021-10-20 15:54:24,090\tINFO backend_state.py:914 -- Removing 1 replicas from deployment 'qa6'. component=serve deployment=qa6\n",
      "\u001b[2m\u001b[36m(pid=8026)\u001b[0m 2021-10-20 15:54:24,094\tINFO backend_state.py:914 -- Removing 1 replicas from deployment 'qa7'. component=serve deployment=qa7\n",
      "\u001b[2m\u001b[36m(pid=8026)\u001b[0m 2021-10-20 15:54:24,098\tINFO backend_state.py:914 -- Removing 1 replicas from deployment 'qa8'. component=serve deployment=qa8\n",
      "\u001b[2m\u001b[36m(pid=8026)\u001b[0m 2021-10-20 15:54:24,103\tINFO backend_state.py:914 -- Removing 1 replicas from deployment 'qa9'. component=serve deployment=qa9\n",
      "\u001b[2m\u001b[36m(pid=8026)\u001b[0m 2021-10-20 15:54:24,107\tINFO backend_state.py:914 -- Removing 1 replicas from deployment 'qa10'. component=serve deployment=qa10\n",
      "\u001b[2m\u001b[36m(pid=8026)\u001b[0m 2021-10-20 15:54:24,112\tINFO backend_state.py:914 -- Removing 1 replicas from deployment 'qa11'. component=serve deployment=qa11\n",
      "\u001b[2m\u001b[36m(pid=8113)\u001b[0m 2021-10-20 15:54:28,130\tINFO checkpoint_path.py:15 -- Using RayInternalKVStore for controller checkpoint and recovery.\n",
      "\u001b[2m\u001b[36m(pid=8113)\u001b[0m 2021-10-20 15:54:28,134\tINFO http_state.py:75 -- Starting HTTP proxy with name 'SERVE_CONTROLLER_ACTOR:xaeDOH:SERVE_PROXY_ACTOR-node:192.168.0.238-0' on node 'node:192.168.0.238-0' listening on '127.0.0.1:8000'\n",
      "2021-10-20 15:54:28,382\tINFO api.py:455 -- Started Serve instance in namespace 'dfb9e54a-65e6-4b38-8aac-dd782ac2a7fe'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ray.serve.api.Client at 0x7ff6d07283a0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serve.shutdown()\n",
    "reboot_ray()\n",
    "serve.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing `zerocopy`\n",
    "\n",
    "We've created a Python package, `zerocopy`, with the model rewrite code from our previous post (TODO: Publish the package to PyPI).\n",
    "\n",
    "To use that package, you'll need to install it with `pip`, then import it into your script.\n",
    "\n",
    "```python\n",
    "import zerocopy\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Move this code to the `zerocopy` library.\n",
    "@ray.remote\n",
    "def call_model_zero_copy(model_ref: ray.ObjectRef, args, kwargs) -> Any:\n",
    "    \"\"\"\n",
    "    Ray task that uses zero-copy model loading to reconstitute a model\n",
    "    from Plasma, then invokes the model's ``__call__()`` method.\n",
    "\n",
    "    :param model_ref: Object reference to a tuple of model skeleton\n",
    "     and model weights, as returned by :func:`extract_tensors`\n",
    "    :param args: Ordered arguments to pass to the model's :func:`__call__`\n",
    "     method\n",
    "    :param kwargs: Keyword arguments to pass to the model's :func:`__call__`\n",
    "     method\n",
    "\n",
    "    :returns: Return value from the model's :func:`__call__` method\n",
    "    \"\"\"\n",
    "    # Suppress PyTorch warnings about immutable tensors\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    model_skeleton, model_weights = model_ref\n",
    "    zerocopy.replace_tensors(model_skeleton, model_weights)\n",
    "    with torch.no_grad():\n",
    "        return model_skeleton(*args, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=8111)\u001b[0m INFO:     Started server process [8111]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[ 3.7534, -8.7741, -9.1023, -6.6326, -8.7627, -8.6893, -9.7706, -9.6873,\n",
       "         -9.6512, -4.1902, -7.6596, -8.5491, -7.9478, -7.5671, -9.0784, -8.2897,\n",
       "         -7.5410, -5.9760, -7.2943, -6.4250, -9.3297, -8.9922, -7.9955, -8.9485,\n",
       "         -8.7506, -6.1065, -8.2273, -8.4471, -8.9334, -2.9227, -2.8201, -4.6316,\n",
       "         -5.5576, -5.7634, -5.8722, -5.9716, -6.2091, -6.0458, -5.3727, -9.8484,\n",
       "         -8.4069, -7.6116, -5.1946, -8.7245, -4.3298, -8.3712, -8.5934, -4.6927,\n",
       "         -8.6297, -5.4113, -8.5218, -6.5587, -6.0347, -9.0888, -3.9168, -3.7715,\n",
       "         -4.0178, -5.5528, -6.2156, -6.1800, -6.1387, -6.2229, -6.4473, -6.3201,\n",
       "         -6.2259, -8.2617, -8.0752, -8.5442, -7.0337, -5.3173, -7.1967, -8.6134,\n",
       "         -5.5957, -9.0524, -8.1817, -7.5553, -7.3492, -8.5218, -7.5425, -7.8877,\n",
       "         -8.3360, -8.1147, -5.0947, -5.1871, -6.5926, -6.7610, -6.7855, -6.8672,\n",
       "         -6.9245, -6.7498, -7.7118, -8.6336, -8.0725, -7.3320, -7.0676, -8.8112,\n",
       "         -4.9942, -5.8767, -9.1029, -7.2982, -6.3021, -9.7423, -7.1146, -7.1081,\n",
       "         -6.9473, -8.5740, -3.0519, -6.5594, -8.5219, -4.1875, -3.3123, -4.7947,\n",
       "         -6.0620, -6.2542, -6.3127, -6.3890, -6.4033, -5.8774, -8.3484, -8.4814,\n",
       "         -9.0725, -8.4167, -9.2634, -8.2589, -7.3816, -8.6027, -5.9291, -2.9634,\n",
       "         -7.5559, -5.7752, -5.7358, -2.7408, -9.7852, -8.8763, -8.4199, -9.4240,\n",
       "         -9.2364, -6.2053, -3.3876, -7.0878, -5.4361, -4.9418, -4.3873, -6.6898,\n",
       "         -6.8614, -6.9100, -6.7906, -6.6952, -6.9213, -7.2896, -7.4180, -5.0012,\n",
       "         -7.7606, -4.3374, -9.5112, -3.4502, -3.6575, -5.4360, -5.9422, -6.0169,\n",
       "         -6.0962, -6.1794, -6.1066, -5.3584, -9.5739]],\n",
       "       grad_fn=<CopyBackwards>), end_logits=tensor([[ 4.4085, -9.0466, -8.8865, -8.7139, -8.4380, -6.1985, -8.0720, -8.6342,\n",
       "         -8.5613, -8.2167, -3.1857, -8.5013, -9.1181, -9.5205, -8.6247, -9.3529,\n",
       "         -9.5464, -7.6825, -6.5827, -5.3342, -7.0454, -8.8780, -9.4053, -8.9716,\n",
       "         -9.1811, -5.5211, -8.8220, -7.2581, -8.8071, -3.8688, -2.2351, -4.3839,\n",
       "         -4.6088, -4.6001, -4.5076, -4.4578, -4.5339, -4.5748, -3.9645, -7.4804,\n",
       "         -9.4568, -9.2952, -5.0298, -9.1183, -8.2703, -6.1834, -8.8689, -4.8877,\n",
       "         -9.0013, -3.7470, -5.0784, -9.5459, -7.1008, -8.6576, -4.8155, -4.2921,\n",
       "         -2.7303, -4.5583, -4.8196, -4.7327, -4.6521, -4.6179, -4.7436, -4.8457,\n",
       "         -8.8704, -5.5503, -9.1086, -9.2351, -9.6451, -7.8936, -5.3242, -8.5684,\n",
       "         -5.8515, -8.7893, -9.1167, -6.6691, -4.8255, -5.0784, -9.5671, -8.4143,\n",
       "         -9.0938, -8.9134, -4.9596, -5.5421, -5.9617, -5.8093, -5.7694, -5.6697,\n",
       "         -5.1522, -4.9800, -7.5636, -6.4838, -9.3509, -9.7418, -8.4976, -9.0644,\n",
       "         -7.2498, -4.1803, -8.6530, -8.6244, -4.0320, -7.6777, -9.3713, -9.6320,\n",
       "         -8.6084, -8.9086, -4.2255, -2.6947, -5.0785, -4.4284, -2.9734, -5.2723,\n",
       "         -5.7548, -5.7846, -5.6469, -5.3465, -4.7512, -4.2537, -9.1724, -8.5388,\n",
       "         -9.1766, -9.1957, -8.9629, -9.5458, -9.0349, -7.9539, -9.7081, -5.0877,\n",
       "         -7.9361, -6.1761, -8.4385, -1.4253, -4.2468, -8.7981, -9.2489, -8.5449,\n",
       "         -9.0143, -9.6156, -5.2834, -7.8561, -4.6573, -4.8583, -3.0356, -5.0068,\n",
       "         -5.2084, -5.2549, -5.0224, -4.8224, -4.8028, -5.2435, -9.3175, -8.6061,\n",
       "         -8.7362, -2.4815, -5.2484, -3.2335, -4.3040, -5.2170, -5.4810, -5.4640,\n",
       "         -5.3760, -5.0714, -4.5941, -3.6325, -8.8697]],\n",
       "       grad_fn=<CopyBackwards>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the model directly\n",
    "inputs = qa.tokenizer(qa_input[\"question\"], qa_input[\"context\"], return_tensors=\"pt\")\n",
    "qa.model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[ 3.7534, -8.7741, -9.1023, -6.6326, -8.7627, -8.6893, -9.7706, -9.6873,\n",
       "         -9.6512, -4.1902, -7.6596, -8.5491, -7.9478, -7.5671, -9.0784, -8.2897,\n",
       "         -7.5410, -5.9760, -7.2943, -6.4250, -9.3297, -8.9922, -7.9955, -8.9485,\n",
       "         -8.7506, -6.1065, -8.2273, -8.4471, -8.9334, -2.9227, -2.8201, -4.6316,\n",
       "         -5.5576, -5.7634, -5.8722, -5.9716, -6.2091, -6.0458, -5.3727, -9.8484,\n",
       "         -8.4069, -7.6116, -5.1946, -8.7245, -4.3298, -8.3712, -8.5934, -4.6927,\n",
       "         -8.6297, -5.4113, -8.5218, -6.5587, -6.0347, -9.0888, -3.9168, -3.7715,\n",
       "         -4.0178, -5.5528, -6.2156, -6.1800, -6.1387, -6.2229, -6.4473, -6.3201,\n",
       "         -6.2259, -8.2617, -8.0752, -8.5442, -7.0337, -5.3173, -7.1967, -8.6134,\n",
       "         -5.5957, -9.0524, -8.1817, -7.5553, -7.3492, -8.5218, -7.5425, -7.8877,\n",
       "         -8.3360, -8.1147, -5.0947, -5.1871, -6.5926, -6.7610, -6.7855, -6.8672,\n",
       "         -6.9245, -6.7498, -7.7118, -8.6336, -8.0725, -7.3320, -7.0676, -8.8112,\n",
       "         -4.9942, -5.8767, -9.1029, -7.2982, -6.3021, -9.7423, -7.1146, -7.1081,\n",
       "         -6.9473, -8.5740, -3.0519, -6.5594, -8.5219, -4.1875, -3.3123, -4.7947,\n",
       "         -6.0620, -6.2542, -6.3127, -6.3890, -6.4033, -5.8774, -8.3484, -8.4814,\n",
       "         -9.0725, -8.4167, -9.2634, -8.2589, -7.3816, -8.6027, -5.9291, -2.9634,\n",
       "         -7.5559, -5.7752, -5.7358, -2.7408, -9.7852, -8.8763, -8.4199, -9.4240,\n",
       "         -9.2364, -6.2053, -3.3876, -7.0878, -5.4361, -4.9418, -4.3873, -6.6898,\n",
       "         -6.8614, -6.9100, -6.7906, -6.6952, -6.9213, -7.2896, -7.4180, -5.0012,\n",
       "         -7.7606, -4.3374, -9.5112, -3.4502, -3.6575, -5.4360, -5.9422, -6.0169,\n",
       "         -6.0962, -6.1794, -6.1066, -5.3584, -9.5739]]), end_logits=tensor([[ 4.4085, -9.0466, -8.8865, -8.7139, -8.4380, -6.1985, -8.0720, -8.6342,\n",
       "         -8.5613, -8.2167, -3.1857, -8.5013, -9.1181, -9.5205, -8.6247, -9.3529,\n",
       "         -9.5464, -7.6825, -6.5827, -5.3342, -7.0454, -8.8780, -9.4053, -8.9716,\n",
       "         -9.1811, -5.5211, -8.8220, -7.2581, -8.8071, -3.8688, -2.2351, -4.3839,\n",
       "         -4.6088, -4.6001, -4.5076, -4.4578, -4.5339, -4.5748, -3.9645, -7.4804,\n",
       "         -9.4568, -9.2952, -5.0298, -9.1183, -8.2703, -6.1834, -8.8689, -4.8877,\n",
       "         -9.0013, -3.7470, -5.0784, -9.5459, -7.1008, -8.6576, -4.8155, -4.2921,\n",
       "         -2.7303, -4.5583, -4.8196, -4.7327, -4.6521, -4.6179, -4.7436, -4.8457,\n",
       "         -8.8704, -5.5503, -9.1086, -9.2351, -9.6451, -7.8936, -5.3242, -8.5684,\n",
       "         -5.8515, -8.7893, -9.1167, -6.6691, -4.8255, -5.0784, -9.5671, -8.4143,\n",
       "         -9.0938, -8.9134, -4.9596, -5.5421, -5.9617, -5.8093, -5.7694, -5.6697,\n",
       "         -5.1522, -4.9800, -7.5636, -6.4838, -9.3509, -9.7418, -8.4976, -9.0644,\n",
       "         -7.2498, -4.1803, -8.6530, -8.6244, -4.0320, -7.6777, -9.3713, -9.6320,\n",
       "         -8.6084, -8.9086, -4.2255, -2.6947, -5.0785, -4.4284, -2.9734, -5.2723,\n",
       "         -5.7548, -5.7846, -5.6469, -5.3465, -4.7512, -4.2537, -9.1724, -8.5388,\n",
       "         -9.1766, -9.1957, -8.9629, -9.5458, -9.0349, -7.9539, -9.7081, -5.0877,\n",
       "         -7.9361, -6.1761, -8.4385, -1.4253, -4.2468, -8.7981, -9.2489, -8.5449,\n",
       "         -9.0143, -9.6156, -5.2834, -7.8561, -4.6573, -4.8583, -3.0356, -5.0068,\n",
       "         -5.2084, -5.2549, -5.0224, -4.8224, -4.8028, -5.2435, -9.3175, -8.6061,\n",
       "         -8.7362, -2.4815, -5.2484, -3.2335, -4.3040, -5.2170, -5.4810, -5.4640,\n",
       "         -5.3760, -5.0714, -4.5941, -3.6325, -8.8697]]), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the model via `call_model`. Results should be the same as the previous cell.\n",
    "model_ref = ray.put(zerocopy.extract_tensors(qa.model))\n",
    "ray.get(call_model_zero_copy.remote(model_ref, [], inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time to invoke the model once via `call_model_zero_copy()` is almost the same as running the model locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Time to run locally: 368 ms ± 10.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Time to run with zero-copy: 375 ms ± 11.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Compare timings\n",
    "print(\"       Time to run locally: \", end=\"\")\n",
    "%timeit qa.model(**inputs)\n",
    "print(\"Time to run with zero-copy: \", end=\"\")\n",
    "%timeit ray.get(call_model_zero_copy.remote(model_ref, [], inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we run inference multiple times, `call_model_zero_copy()` can send those inference requests to separate Ray tasks that run in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Time to run 100 times locally: 37.5 s ± 13.9 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n",
      "Time to run 100 times with zero-copy: \u001b[2m\u001b[36m(call_model_zero_copy pid=8102)\u001b[0m \n",
      "7.1 s ± 73.7 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def run_local(num_repeats: int):\n",
    "    for _ in range(num_repeats):\n",
    "        qa.model(**inputs)\n",
    "\n",
    "def run_zero_copy(num_repeats: int):\n",
    "    futures = [call_model_zero_copy.remote(model_ref, [], inputs) for _ in range(num_repeats)]\n",
    "    ray.get(futures)\n",
    "\n",
    "NUM_REPEATS = 100\n",
    "print(f\"       Time to run {NUM_REPEATS} times locally: \", end=\"\")\n",
    "%timeit -r 3 run_local(NUM_REPEATS)\n",
    "print(f\"Time to run {NUM_REPEATS} times with zero-copy: \", end=\"\")\n",
    "%timeit -r 3 run_zero_copy(NUM_REPEATS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define a Ray Serve endpoint that runs the model preprocessing code locally and farms out model inference \n",
    "to Ray tasks that use zero-copy model loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-20 15:57:36,114\tINFO api.py:243 -- Updating deployment 'qa0'. component=serve deployment=qa0\n",
      "2021-10-20 15:57:36,131\tINFO api.py:243 -- Updating deployment 'qa1'. component=serve deployment=qa1\n",
      "2021-10-20 15:57:36,156\tINFO api.py:243 -- Updating deployment 'qa2'. component=serve deployment=qa2\n",
      "\u001b[2m\u001b[36m(pid=8113)\u001b[0m 2021-10-20 15:57:36,155\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa0'. component=serve deployment=qa0\n",
      "\u001b[2m\u001b[36m(pid=8113)\u001b[0m 2021-10-20 15:57:36,168\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa1'. component=serve deployment=qa1\n",
      "\u001b[2m\u001b[36m(pid=8113)\u001b[0m 2021-10-20 15:57:36,181\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa2'. component=serve deployment=qa2\n",
      "2021-10-20 15:57:36,210\tINFO api.py:243 -- Updating deployment 'qa3'. component=serve deployment=qa3\n",
      "2021-10-20 15:57:36,244\tINFO api.py:243 -- Updating deployment 'qa4'. component=serve deployment=qa4\n",
      "2021-10-20 15:57:36,272\tINFO api.py:243 -- Updating deployment 'qa5'. component=serve deployment=qa5\n",
      "2021-10-20 15:57:36,306\tINFO api.py:243 -- Updating deployment 'qa6'. component=serve deployment=qa6\n",
      "2021-10-20 15:57:36,397\tINFO api.py:243 -- Updating deployment 'qa7'. component=serve deployment=qa7\n",
      "\u001b[2m\u001b[36m(pid=8113)\u001b[0m 2021-10-20 15:57:36,308\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa3'. component=serve deployment=qa3\n",
      "\u001b[2m\u001b[36m(pid=8113)\u001b[0m 2021-10-20 15:57:36,321\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa4'. component=serve deployment=qa4\n",
      "\u001b[2m\u001b[36m(pid=8113)\u001b[0m 2021-10-20 15:57:36,334\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa5'. component=serve deployment=qa5\n",
      "\u001b[2m\u001b[36m(pid=8113)\u001b[0m 2021-10-20 15:57:36,349\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa6'. component=serve deployment=qa6\n",
      "2021-10-20 15:57:36,445\tINFO api.py:243 -- Updating deployment 'qa8'. component=serve deployment=qa8\n",
      "2021-10-20 15:57:36,486\tINFO api.py:243 -- Updating deployment 'qa9'. component=serve deployment=qa9\n",
      "\u001b[2m\u001b[36m(pid=8113)\u001b[0m 2021-10-20 15:57:36,489\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa7'. component=serve deployment=qa7\n",
      "\u001b[2m\u001b[36m(pid=8113)\u001b[0m 2021-10-20 15:57:36,501\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa8'. component=serve deployment=qa8\n",
      "\u001b[2m\u001b[36m(pid=8113)\u001b[0m 2021-10-20 15:57:36,515\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa9'. component=serve deployment=qa9\n",
      "2021-10-20 15:57:36,582\tINFO api.py:243 -- Updating deployment 'qa10'. component=serve deployment=qa10\n",
      "2021-10-20 15:57:36,641\tINFO api.py:243 -- Updating deployment 'qa11'. component=serve deployment=qa11\n",
      "\u001b[2m\u001b[36m(pid=8113)\u001b[0m 2021-10-20 15:57:36,646\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa10'. component=serve deployment=qa10\n",
      "\u001b[2m\u001b[36m(pid=8113)\u001b[0m 2021-10-20 15:57:36,658\tINFO backend_state.py:896 -- Adding 1 replicas to deployment 'qa11'. component=serve deployment=qa11\n"
     ]
    }
   ],
   "source": [
    "class ZeroCopyQAModel:\n",
    "    def __init__(self):\n",
    "        # TODO: Move this rewrite to the `zerocopy` library.\n",
    "        # Load the entire pipeline, then copy the model portion to Plasma.\n",
    "        self._qa = transformers.pipeline(\"question-answering\", model=model_name)\n",
    "        model_ref = ray.put(zerocopy.extract_tensors(self._qa.model))\n",
    "\n",
    "        # Replace the pipeline's model with a callback that farms out work to\n",
    "        # Ray tasks.\n",
    "        class _ModelCallback:\n",
    "            def __call__(self, *args, **kwargs):\n",
    "                return ray.get(call_model_zero_copy.remote(model_ref, args, kwargs))\n",
    "        self._qa.model = _ModelCallback()\n",
    "\n",
    "        # Use a threadpool because the model is called from pre/postprocessing code\n",
    "        # that is not asyncio-aware\n",
    "        self._threadpool = concurrent.futures.ThreadPoolExecutor()\n",
    "\n",
    "    async def __call__(self, request: starlette.requests.Request):\n",
    "        # Pull model inputs from URL query parameters.\n",
    "        # A production version of this code would sanitize these strings.\n",
    "        model_input = {\n",
    "            \"question\": request.query_params[\"question\"],\n",
    "            \"context\": request.query_params[\"context\"]\n",
    "        }\n",
    "        result = await asyncio.get_running_loop().run_in_executor(\n",
    "            self._threadpool, lambda: self._qa(model_input))\n",
    "        return result\n",
    "\n",
    "    def __del__(self):  # Ray Serve needs this callback\n",
    "        pass\n",
    "    \n",
    "\n",
    "# Define endpoints\n",
    "NUM_QA_MODELS = 12\n",
    "deployments = [\n",
    "    serve.deployment(ZeroCopyQAModel, f\"qa{model_num}\", \n",
    "    ray_actor_options={\n",
    "        \"num_cpus\": 0.1,  # Minimal CPU overhead for the top-level handler\n",
    "    })\n",
    "    for model_num in range(NUM_QA_MODELS)\n",
    "]\n",
    "\n",
    "for d in deployments:\n",
    "    d.deploy(_blocking = False)\n",
    "\n",
    "# Wait a moment so log output doesn't go to the next cell's output\n",
    "time.sleep(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 4.278851065464551e-06, 'start': 483, 'end': 484, 'answer': '5'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try out the new deployment.\n",
    "# This web service call blocks until the asychronous deployment has completed.\n",
    "params = urllib.parse.urlencode(qa_input)\n",
    "requests.get(f\"http://127.0.0.1:8000/qa0?{params}\").json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've deployed these models to the same URLs, so the benchmark code from before should work without\n",
    "any changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request_id</th>\n",
       "      <th>model_num</th>\n",
       "      <th>desired_start</th>\n",
       "      <th>actual_start</th>\n",
       "      <th>end</th>\n",
       "      <th>latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.402409</td>\n",
       "      <td>0.401659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.205194</td>\n",
       "      <td>0.718441</td>\n",
       "      <td>0.513247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.403449</td>\n",
       "      <td>0.796507</td>\n",
       "      <td>0.393058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.608202</td>\n",
       "      <td>1.188467</td>\n",
       "      <td>0.580265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.805189</td>\n",
       "      <td>1.230260</td>\n",
       "      <td>0.425071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.008236</td>\n",
       "      <td>2.762621</td>\n",
       "      <td>1.754385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.206047</td>\n",
       "      <td>1.730239</td>\n",
       "      <td>0.524192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.402445</td>\n",
       "      <td>2.107700</td>\n",
       "      <td>0.705255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.602188</td>\n",
       "      <td>2.465519</td>\n",
       "      <td>0.863331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.803775</td>\n",
       "      <td>2.210849</td>\n",
       "      <td>0.407074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.001090</td>\n",
       "      <td>2.615358</td>\n",
       "      <td>0.614268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.204942</td>\n",
       "      <td>2.625684</td>\n",
       "      <td>0.420742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.400531</td>\n",
       "      <td>4.206035</td>\n",
       "      <td>1.805504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.605264</td>\n",
       "      <td>3.007292</td>\n",
       "      <td>0.402028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.805524</td>\n",
       "      <td>3.492071</td>\n",
       "      <td>0.686547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.005715</td>\n",
       "      <td>3.408696</td>\n",
       "      <td>0.402981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.201999</td>\n",
       "      <td>3.613122</td>\n",
       "      <td>0.411123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.405982</td>\n",
       "      <td>3.874527</td>\n",
       "      <td>0.468545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.601741</td>\n",
       "      <td>4.196391</td>\n",
       "      <td>0.594650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.807513</td>\n",
       "      <td>4.261265</td>\n",
       "      <td>0.453752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.006458</td>\n",
       "      <td>4.421158</td>\n",
       "      <td>0.414700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.201355</td>\n",
       "      <td>4.729398</td>\n",
       "      <td>0.528043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.406813</td>\n",
       "      <td>4.836067</td>\n",
       "      <td>0.429254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.603943</td>\n",
       "      <td>5.009043</td>\n",
       "      <td>0.405100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.807195</td>\n",
       "      <td>5.212716</td>\n",
       "      <td>0.405521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.007721</td>\n",
       "      <td>5.424420</td>\n",
       "      <td>0.416699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.208126</td>\n",
       "      <td>5.647117</td>\n",
       "      <td>0.438991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5.401889</td>\n",
       "      <td>5.813400</td>\n",
       "      <td>0.411511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>5.601180</td>\n",
       "      <td>6.009897</td>\n",
       "      <td>0.408717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.802109</td>\n",
       "      <td>6.212974</td>\n",
       "      <td>0.410865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.003547</td>\n",
       "      <td>6.410441</td>\n",
       "      <td>0.406894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6.208462</td>\n",
       "      <td>6.614653</td>\n",
       "      <td>0.406191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.405907</td>\n",
       "      <td>6.830598</td>\n",
       "      <td>0.424691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>6.602084</td>\n",
       "      <td>7.027311</td>\n",
       "      <td>0.425227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>6.802849</td>\n",
       "      <td>7.206305</td>\n",
       "      <td>0.403456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.008865</td>\n",
       "      <td>7.416344</td>\n",
       "      <td>0.407479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>7.203445</td>\n",
       "      <td>7.607356</td>\n",
       "      <td>0.403911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.409199</td>\n",
       "      <td>7.816036</td>\n",
       "      <td>0.406837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.602084</td>\n",
       "      <td>8.004991</td>\n",
       "      <td>0.402907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>7.806868</td>\n",
       "      <td>8.222607</td>\n",
       "      <td>0.415739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.002196</td>\n",
       "      <td>8.438164</td>\n",
       "      <td>0.435968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>8.207134</td>\n",
       "      <td>8.650738</td>\n",
       "      <td>0.443604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>8.404522</td>\n",
       "      <td>8.847670</td>\n",
       "      <td>0.443148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.610239</td>\n",
       "      <td>10.385926</td>\n",
       "      <td>1.775687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>8.807564</td>\n",
       "      <td>10.205908</td>\n",
       "      <td>1.398344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.001638</td>\n",
       "      <td>9.595698</td>\n",
       "      <td>0.594060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>9.207977</td>\n",
       "      <td>10.084775</td>\n",
       "      <td>0.876798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>9.4</td>\n",
       "      <td>9.405083</td>\n",
       "      <td>9.829751</td>\n",
       "      <td>0.424668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.604488</td>\n",
       "      <td>10.032473</td>\n",
       "      <td>0.427985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8</td>\n",
       "      <td>9.808533</td>\n",
       "      <td>11.611833</td>\n",
       "      <td>1.803300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    request_id  model_num  desired_start  actual_start        end   latency\n",
       "0            0          0            0.0      0.000750   0.402409  0.401659\n",
       "1            1          1            0.2      0.205194   0.718441  0.513247\n",
       "2            2          0            0.4      0.403449   0.796507  0.393058\n",
       "3            3          0            0.6      0.608202   1.188467  0.580265\n",
       "4            4          1            0.8      0.805189   1.230260  0.425071\n",
       "5            5          0            1.0      1.008236   2.762621  1.754385\n",
       "6            6          1            1.2      1.206047   1.730239  0.524192\n",
       "7            7          0            1.4      1.402445   2.107700  0.705255\n",
       "8            8          0            1.6      1.602188   2.465519  0.863331\n",
       "9            9          0            1.8      1.803775   2.210849  0.407074\n",
       "10          10          0            2.0      2.001090   2.615358  0.614268\n",
       "11          11          0            2.2      2.204942   2.625684  0.420742\n",
       "12          12          1            2.4      2.400531   4.206035  1.805504\n",
       "13          13          0            2.6      2.605264   3.007292  0.402028\n",
       "14          14          1            2.8      2.805524   3.492071  0.686547\n",
       "15          15          0            3.0      3.005715   3.408696  0.402981\n",
       "16          16          0            3.2      3.201999   3.613122  0.411123\n",
       "17          17          0            3.4      3.405982   3.874527  0.468545\n",
       "18          18          2            3.6      3.601741   4.196391  0.594650\n",
       "19          19          0            3.8      3.807513   4.261265  0.453752\n",
       "20          20          0            4.0      4.006458   4.421158  0.414700\n",
       "21          21          0            4.2      4.201355   4.729398  0.528043\n",
       "22          22          1            4.4      4.406813   4.836067  0.429254\n",
       "23          23          0            4.6      4.603943   5.009043  0.405100\n",
       "24          24          0            4.8      4.807195   5.212716  0.405521\n",
       "25          25          0            5.0      5.007721   5.424420  0.416699\n",
       "26          26          0            5.2      5.208126   5.647117  0.438991\n",
       "27          27          0            5.4      5.401889   5.813400  0.411511\n",
       "28          28          0            5.6      5.601180   6.009897  0.408717\n",
       "29          29          1            5.8      5.802109   6.212974  0.410865\n",
       "30          30          1            6.0      6.003547   6.410441  0.406894\n",
       "31          31          1            6.2      6.208462   6.614653  0.406191\n",
       "32          32          1            6.4      6.405907   6.830598  0.424691\n",
       "33          33          0            6.6      6.602084   7.027311  0.425227\n",
       "34          34          0            6.8      6.802849   7.206305  0.403456\n",
       "35          35          0            7.0      7.008865   7.416344  0.407479\n",
       "36          36          0            7.2      7.203445   7.607356  0.403911\n",
       "37          37          0            7.4      7.409199   7.816036  0.406837\n",
       "38          38          0            7.6      7.602084   8.004991  0.402907\n",
       "39          39          0            7.8      7.806868   8.222607  0.415739\n",
       "40          40          0            8.0      8.002196   8.438164  0.435968\n",
       "41          41          0            8.2      8.207134   8.650738  0.443604\n",
       "42          42          0            8.4      8.404522   8.847670  0.443148\n",
       "43          43          0            8.6      8.610239  10.385926  1.775687\n",
       "44          44          0            8.8      8.807564  10.205908  1.398344\n",
       "45          45          0            9.0      9.001638   9.595698  0.594060\n",
       "46          46          0            9.2      9.207977  10.084775  0.876798\n",
       "47          47          1            9.4      9.405083   9.829751  0.424668\n",
       "48          48          1            9.6      9.604488  10.032473  0.427985\n",
       "49          49          0            9.8      9.808533  11.611833  1.803300"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick test run\n",
    "run_benchmark(call_model, 5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running at 2 requests/sec.\n",
      "Running at 3 requests/sec.\n",
      "Running at 4 requests/sec.\n",
      "Running at 5 requests/sec.\n",
      "Running at 6 requests/sec.\n",
      "Running at 8 requests/sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=8266)\u001b[0m E1020 16:03:46.859100000 4539309568 backup_poller.cc:119]              run_poller: {\"created\":\"@1634771026.859066000\",\"description\":\"Timer list shutdown\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/iomgr/timer_generic.cc\",\"file_line\":297}\n",
      "\u001b[2m\u001b[36m(pid=8262)\u001b[0m E1020 16:03:48.495268000 4618489344 backup_poller.cc:119]              run_poller: {\"created\":\"@1634771028.495240000\",\"description\":\"Timer list shutdown\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/iomgr/timer_generic.cc\",\"file_line\":297}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running at 10 requests/sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=8305)\u001b[0m E1020 16:04:21.767421000 4572802560 backup_poller.cc:119]              run_poller: {\"created\":\"@1634771061.767379000\",\"description\":\"Timer list shutdown\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/iomgr/timer_generic.cc\",\"file_line\":297}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running at 12 requests/sec.\n",
      "Running at 14 requests/sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=8364)\u001b[0m E1020 16:06:15.499541000 4752264704 backup_poller.cc:119]              run_poller: {\"created\":\"@1634771175.499495000\",\"description\":\"Timer list shutdown\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/iomgr/timer_generic.cc\",\"file_line\":297}\n"
     ]
    }
   ],
   "source": [
    "# Run the benchmark at multiple different request rates\n",
    "to_concat = []\n",
    "for request_rate in REQUEST_RATES:\n",
    "    print(f\"Running at {request_rate} requests/sec.\")\n",
    "    times = run_benchmark(call_model, request_rate, RUNNING_TIME_SEC)\n",
    "    times.insert(0, \"request_rate\", request_rate)\n",
    "    to_concat.append(times)\n",
    "\n",
    "results_zerocopy = pd.concat(to_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">latency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request_rate</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.384813</td>\n",
       "      <td>0.384591</td>\n",
       "      <td>0.513960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.386905</td>\n",
       "      <td>0.386993</td>\n",
       "      <td>0.522130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.401569</td>\n",
       "      <td>0.391649</td>\n",
       "      <td>1.693874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.497914</td>\n",
       "      <td>0.402894</td>\n",
       "      <td>1.811744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.424987</td>\n",
       "      <td>0.400613</td>\n",
       "      <td>1.609588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.955437</td>\n",
       "      <td>0.667040</td>\n",
       "      <td>4.984133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.743633</td>\n",
       "      <td>1.529724</td>\n",
       "      <td>5.623672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6.846877</td>\n",
       "      <td>7.157012</td>\n",
       "      <td>12.317863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8.440915</td>\n",
       "      <td>10.533431</td>\n",
       "      <td>13.232463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               latency                      \n",
       "                  mean     median        max\n",
       "request_rate                                \n",
       "2             0.384813   0.384591   0.513960\n",
       "3             0.386905   0.386993   0.522130\n",
       "4             0.401569   0.391649   1.693874\n",
       "5             0.497914   0.402894   1.811744\n",
       "6             0.424987   0.400613   1.609588\n",
       "8             0.955437   0.667040   4.984133\n",
       "10            1.743633   1.529724   5.623672\n",
       "12            6.846877   7.157012  12.317863\n",
       "14            8.440915  10.533431  13.232463"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_results_zerocopy = results_zerocopy.groupby(\"request_rate\").aggregate({\"latency\": [\"mean\", \"median\", \"max\"]})\n",
    "agg_results_zerocopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Average Latency (sec)')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(agg_results_zerocopy.index, agg_results_zerocopy[\"latency\", \"mean\"])\n",
    "plt.xlabel(\"Requests per Second\")\n",
    "plt.ylabel(\"Average Latency (sec)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Average Latency (sec)')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(agg_results.index, agg_results[\"latency\", \"mean\"])\n",
    "plt.scatter(agg_results_zerocopy.index, agg_results_zerocopy[\"latency\", \"mean\"])\n",
    "plt.xlabel(\"Requests per Second\")\n",
    "plt.ylabel(\"Average Latency (sec)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old code defined an actor\n",
    "\n",
    "# class ModelCallback:\n",
    "#     def __init__(self, model_ref: ray.ObjectRef):\n",
    "#         self._model_ref = model_ref\n",
    "\n",
    "#     def __call__(self, *args: Any, **kwargs: Any) -> Any:\n",
    "#         return ray.get(call_model.remote(self._model_ref, args, kwargs))\n",
    "\n",
    "# @ray.remote\n",
    "# class QAModelZeroCopyActor:\n",
    "#     def __init__(self):\n",
    "#         self._qa = transformers.pipeline(\"question-answering\", model=model_name)\n",
    "#         self._model_ref = ray.put(zerocopy.extract_tensors(self._qa.model))\n",
    "#         self._qa.model = ModelCallback(self._model_ref)\n",
    "\n",
    "#     def run_inference(self, input_: Dict[str, str]) -> Dict[str, Any]:\n",
    "#         return self._qa(input_)\n",
    "\n",
    "# zero_copy_actors = [QAModelZeroCopyActor.options(max_concurrency=8).remote() for _ in range(NUM_QA_MODELS)]\n",
    "#ray.get(zero_copy_actors[0].run_inference.remote(qa_input))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e4e339263d197c82df8e8908764177a8d8b296d0194ea84e74b56ff8a213e1eb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
